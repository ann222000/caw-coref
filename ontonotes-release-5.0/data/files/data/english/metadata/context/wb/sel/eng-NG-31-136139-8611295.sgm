<DOC>
<DOCID> eng-NG-31-136139-8611295 </DOCID>
<DOCTYPE SOURCE="usenet"> USENET TEXT </DOCTYPE>
<DATETIME> 2007-08-17T11:35:00 </DATETIME>
<BODY>
<HEADLINE>
GSC Sitemap Contains errors
</HEADLINE>
<TEXT>
<POST>
<POSTER> a-ok-site &lt;a.ok.s...@gmail.com&gt; </POSTER>
<POSTDATE> 2007-08-17T11:35:00 </POSTDATE>
I generated a new site map and when I uploaded it Google found 62 e404
errors, but there are no actual e404 errors on my site.  All of these
were caused by errors created by GSC.  The file type was cut off
like .jpg into .j, html into .ht, etc.  Is there a URL link length
requirement or is this just a freak error.  I reran GSC and I think
it's fixed now but I have a bunch of errors on Google.  Here are some
examples:

http://a-ok-site.com/factbook/factbook2000/factbook/flags/al-lgflag.j
http://a-ok-site.com/factbook/factbook2000/factbook/reference/JPEG_ve...
http://a-ok-site.com/factbook/factbook2002/factbook/covers/cover1989f...

Any ideas because it's a real pain to do all of the URL removals on
Google.

My site URL= http://a-ok-site.com , site map files= http://a-ok-site.com/
sitemap.xml http://a-ok-site.com/sitemap.xml.gz http://a-ok-site.com/urllist.txt

Thanks,

Dan
</POST>
<POST>
<POSTER> webado &lt;web...@gmail.com&gt; </POSTER>
<POSTDATE> 2007-08-17T12:13:00 </POSTDATE>
First off jpegs and other images and media files should not be in the
sitemap at all. You can exclude them from GSC using the filters.
The way images get into the Google image indexex is by their being
roesent on pages that are being indexed regularly.

Google's errors from the sitemap will disappear after 2-3 weeks.
Google indexes your site from a crawl starting at the root, the
sitemap is just a reference. If you have  bad links appearing in the
index maybe there's somehtign wrong with your site's navigation and
bad links get generated. have you used Xenu to crawl the site?

What I see there that's wrong is your robots.txt file shoudl disallow
the gallery since it generates url's with session ids.
I see the broken url's in your robtos.txt fle - that won't solve the
problem long term of broken url's if they are from your navigation.

It seems a crawl is getting bogged down by an explosion of url's from
somewhere, because after it had reached 45% it suddenly dropped to 14%
and it's slowly crept up to 17%  even while more url's are getting
crawled yet the total keeps moving higher - and this is after I
excldued the gallery too.
There's something producing  huge numbers of url's in the factbook
folder.
Whether that's OOK or not I don't knwo as I've not finished scanning.
At this rate it will take very long.

On Aug 17, 11:35 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; I generated a new site map and when I uploaded it Google found 62 e404
&gt; errors, but there are no actual e404 errors on my site.  All of these
&gt; were caused by errors created by GSC.  The file type was cut off
&gt; like .jpg into .j, html into .ht, etc.  Is there a URL link length
&gt; requirement or is this just a freak error.  I reran GSC and I think
&gt; it's fixed now but I have a bunch of errors on Google.  Here are some
&gt; examples:

&gt; http://a-ok-site.com/factbook/factbook2000/factbook/flags/al-lgflag.j... ...

&gt; Any ideas because it's a real pain to do all of the URL removals on
&gt; Google.

&gt; My site URL= http://a-ok-site.com , site map files= http://a-ok-site.com/
&gt; sitemap.xml http://a-ok-site.com/sitemap.xml.gzhttp://a-ok-site.com/urllist.txt

&gt; Thanks,

&gt; Dan
">
</POST>
<POST>
<POSTER> a-ok-site &lt;a.ok.s...@gmail.com&gt; </POSTER>
<POSTDATE> 2007-08-17T12:22:00 </POSTDATE>
Thanks Webado.

I will get rid of gallery in site map.  Should I limit the factbook
folders (about 10,000 links total) to the home page of each? Later.

On Aug 17, 11:13 am, webado &lt;web ... @gmail.com&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; First off jpegs and other images and media files should not be in the
&gt; sitemap at all. You can exclude them from GSC using the filters.
&gt; The way images get into the Google image indexex is by their being
&gt; roesent on pages that are being indexed regularly.

&gt; Google's errors from the sitemap will disappear after 2-3 weeks.
&gt; Google indexes your site from a crawl starting at the root, the
&gt; sitemap is just a reference. If you have  bad links appearing in the
&gt; index maybe there's somehtign wrong with your site's navigation and
&gt; bad links get generated. have you used Xenu to crawl the site?

&gt; What I see there that's wrong is your robots.txt file shoudl disallow
&gt; the gallery since it generates url's with session ids.
&gt; I see the broken url's in your robtos.txt fle - that won't solve the
&gt; problem long term of broken url's if they are from your navigation.

&gt; It seems a crawl is getting bogged down by an explosion of url's from
&gt; somewhere, because after it had reached 45% it suddenly dropped to 14%
&gt; and it's slowly crept up to 17%  even while more url's are getting
&gt; crawled yet the total keeps moving higher - and this is after I
&gt; excldued the gallery too.
&gt; There's something producing  huge numbers of url's in the factbook
&gt; folder.
&gt; Whether that's OOK or not I don't knwo as I've not finished scanning.
&gt; At this rate it will take very long.

&gt; On Aug 17, 11:35 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; I generated a new site map and when I uploaded it Google found 62 e404
&gt; &gt; errors, but there are no actual e404 errors on my site.  All of these
&gt; &gt; were caused by errors created by GSC.  The file type was cut off
&gt; &gt; like .jpg into .j, html into .ht, etc.  Is there a URL link length
&gt; &gt; requirement or is this just a freak error.  I reran GSC and I think
&gt; &gt; it's fixed now but I have a bunch of errors on Google.  Here are some
&gt; &gt; examples:

&gt; &gt; http://a-ok-site.com/factbook/factbook2000/factbook/flags/al-lgflag.j ......

&gt; &gt; Any ideas because it's a real pain to do all of the URL removals on
&gt; &gt; Google.

&gt; &gt; My site URL= http://a-ok-site.com , site map files= http://a-ok-site.com/
&gt; &gt; sitemap.xml http://a-ok-site.com/sitemap.xml.gzhttp://a-ok-site.com/urllist.txt

&gt; &gt; Thanks,

&gt; &gt; Dan
">
</POST>
<POST>
<POSTER> a-ok-site &lt;a.ok.s...@gmail.com&gt; </POSTER>
<POSTDATE> 2007-08-17T12:24:00 </POSTDATE>
ooops, Sorry for the double post but I removed all gif, jpg, etc files
after the errors.  All that I am currently crawling is html, htm, pdf,
txt, rtf.  Later.

On Aug 17, 11:13 am, webado &lt;web ... @gmail.com&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; First off jpegs and other images and media files should not be in the
&gt; sitemap at all. You can exclude them from GSC using the filters.
&gt; The way images get into the Google image indexex is by their being
&gt; roesent on pages that are being indexed regularly.

&gt; Google's errors from the sitemap will disappear after 2-3 weeks.
&gt; Google indexes your site from a crawl starting at the root, the
&gt; sitemap is just a reference. If you have  bad links appearing in the
&gt; index maybe there's somehtign wrong with your site's navigation and
&gt; bad links get generated. have you used Xenu to crawl the site?

&gt; What I see there that's wrong is your robots.txt file shoudl disallow
&gt; the gallery since it generates url's with session ids.
&gt; I see the broken url's in your robtos.txt fle - that won't solve the
&gt; problem long term of broken url's if they are from your navigation.

&gt; It seems a crawl is getting bogged down by an explosion of url's from
&gt; somewhere, because after it had reached 45% it suddenly dropped to 14%
&gt; and it's slowly crept up to 17%  even while more url's are getting
&gt; crawled yet the total keeps moving higher - and this is after I
&gt; excldued the gallery too.
&gt; There's something producing  huge numbers of url's in the factbook
&gt; folder.
&gt; Whether that's OOK or not I don't knwo as I've not finished scanning.
&gt; At this rate it will take very long.

&gt; On Aug 17, 11:35 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; I generated a new site map and when I uploaded it Google found 62 e404
&gt; &gt; errors, but there are no actual e404 errors on my site.  All of these
&gt; &gt; were caused by errors created by GSC.  The file type was cut off
&gt; &gt; like .jpg into .j, html into .ht, etc.  Is there a URL link length
&gt; &gt; requirement or is this just a freak error.  I reran GSC and I think
&gt; &gt; it's fixed now but I have a bunch of errors on Google.  Here are some
&gt; &gt; examples:

&gt; &gt; http://a-ok-site.com/factbook/factbook2000/factbook/flags/al-lgflag.j ......

&gt; &gt; Any ideas because it's a real pain to do all of the URL removals on
&gt; &gt; Google.

&gt; &gt; My site URL= http://a-ok-site.com , site map files= http://a-ok-site.com/
&gt; &gt; sitemap.xml http://a-ok-site.com/sitemap.xml.gzhttp://a-ok-site.com/urllist.txt

&gt; &gt; Thanks,

&gt; &gt; Dan
">
</POST>
<POST>
<POSTER> webado &lt;web...@gmail.com&gt; </POSTER>
<POSTDATE> 2007-08-17T12:30:00 </POSTDATE>
Ok I am still crawling, up at 40%. Slow.

Well your factbook is a problem. Based on the url structure it may be
hard or easy to limit to their homepages. But might be good.

On Aug 17, 12:24 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; ooops, Sorry for the double post but I removed all gif, jpg, etc files
&gt; after the errors.  All that I am currently crawling is html, htm, pdf,
&gt; txt, rtf.  Later.

&gt; On Aug 17, 11:13 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; First off jpegs and other images and media files should not be in the
&gt; &gt; sitemap at all. You can exclude them from GSC using the filters.
&gt; &gt; The way images get into the Google image indexex is by their being
&gt; &gt; roesent on pages that are being indexed regularly.

&gt; &gt; Google's errors from the sitemap will disappear after 2-3 weeks.
&gt; &gt; Google indexes your site from a crawl starting at the root, the
&gt; &gt; sitemap is just a reference. If you have  bad links appearing in the
&gt; &gt; index maybe there's somehtign wrong with your site's navigation and
&gt; &gt; bad links get generated. have you used Xenu to crawl the site?

&gt; &gt; What I see there that's wrong is your robots.txt file shoudl disallow
&gt; &gt; the gallery since it generates url's with session ids.
&gt; &gt; I see the broken url's in your robtos.txt fle - that won't solve the
&gt; &gt; problem long term of broken url's if they are from your navigation.

&gt; &gt; It seems a crawl is getting bogged down by an explosion of url's from
&gt; &gt; somewhere, because after it had reached 45% it suddenly dropped to 14%
&gt; &gt; and it's slowly crept up to 17%  even while more url's are getting
&gt; &gt; crawled yet the total keeps moving higher - and this is after I
&gt; &gt; excldued the gallery too.
&gt; &gt; There's something producing  huge numbers of url's in the factbook
&gt; &gt; folder.
&gt; &gt; Whether that's OOK or not I don't knwo as I've not finished scanning.
&gt; &gt; At this rate it will take very long.

&gt; &gt; On Aug 17, 11:35 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; I generated a new site map and when I uploaded it Google found 62 e404
&gt; &gt; &gt; errors, but there are no actual e404 errors on my site.  All of these
&gt; &gt; &gt; were caused by errors created by GSC.  The file type was cut off
&gt; &gt; &gt; like .jpg into .j, html into .ht, etc.  Is there a URL link length
&gt; &gt; &gt; requirement or is this just a freak error.  I reran GSC and I think
&gt; &gt; &gt; it's fixed now but I have a bunch of errors on Google.  Here are some
&gt; &gt; &gt; examples:

&gt; &gt; &gt; http://a-ok-site.com/factbook/factbook2000/factbook/flags/al-lgflag.j ......

&gt; &gt; &gt; Any ideas because it's a real pain to do all of the URL removals on
&gt; &gt; &gt; Google.

&gt; &gt; &gt; My site URL= http://a-ok-site.com , site map files= http://a-ok-site.com/
&gt; &gt; &gt; sitemap.xml http://a-ok-site.com/sitemap.xml.gzhttp://a-ok-site.com/urllist.txt

&gt; &gt; &gt; Thanks,

&gt; &gt; &gt; Dan- Hide quoted text -

&gt; - Show quoted text -
">
</POST>
<POST>
<POSTER> a-ok-site &lt;a.ok.s...@gmail.com&gt; </POSTER>
<POSTDATE> 2007-08-17T12:36:00 </POSTDATE>
Could I ban the factbook urls and do a manual entry.  Could this cause
a conflict the next time I crawl?  later.

On Aug 17, 11:30 am, webado &lt;web ... @gmail.com&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; Ok I am still crawling, up at 40%. Slow.

&gt; Well your factbook is a problem. Based on the url structure it may be
&gt; hard or easy to limit to their homepages. But might be good.

&gt; On Aug 17, 12:24 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; ooops, Sorry for the double post but I removed all gif, jpg, etc files
&gt; &gt; after the errors.  All that I am currently crawling is html, htm, pdf,
&gt; &gt; txt, rtf.  Later.

&gt; &gt; On Aug 17, 11:13 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; First off jpegs and other images and media files should not be in the
&gt; &gt; &gt; sitemap at all. You can exclude them from GSC using the filters.
&gt; &gt; &gt; The way images get into the Google image indexex is by their being
&gt; &gt; &gt; roesent on pages that are being indexed regularly.

&gt; &gt; &gt; Google's errors from the sitemap will disappear after 2-3 weeks.
&gt; &gt; &gt; Google indexes your site from a crawl starting at the root, the
&gt; &gt; &gt; sitemap is just a reference. If you have  bad links appearing in the
&gt; &gt; &gt; index maybe there's somehtign wrong with your site's navigation and
&gt; &gt; &gt; bad links get generated. have you used Xenu to crawl the site?

&gt; &gt; &gt; What I see there that's wrong is your robots.txt file shoudl disallow
&gt; &gt; &gt; the gallery since it generates url's with session ids.
&gt; &gt; &gt; I see the broken url's in your robtos.txt fle - that won't solve the
&gt; &gt; &gt; problem long term of broken url's if they are from your navigation.

&gt; &gt; &gt; It seems a crawl is getting bogged down by an explosion of url's from
&gt; &gt; &gt; somewhere, because after it had reached 45% it suddenly dropped to 14%
&gt; &gt; &gt; and it's slowly crept up to 17%  even while more url's are getting
&gt; &gt; &gt; crawled yet the total keeps moving higher - and this is after I
&gt; &gt; &gt; excldued the gallery too.
&gt; &gt; &gt; There's something producing  huge numbers of url's in the factbook
&gt; &gt; &gt; folder.
&gt; &gt; &gt; Whether that's OOK or not I don't knwo as I've not finished scanning.
&gt; &gt; &gt; At this rate it will take very long.

&gt; &gt; &gt; On Aug 17, 11:35 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; I generated a new site map and when I uploaded it Google found 62 e404
&gt; &gt; &gt; &gt; errors, but there are no actual e404 errors on my site.  All of these
&gt; &gt; &gt; &gt; were caused by errors created by GSC.  The file type was cut off
&gt; &gt; &gt; &gt; like .jpg into .j, html into .ht, etc.  Is there a URL link length
&gt; &gt; &gt; &gt; requirement or is this just a freak error.  I reran GSC and I think
&gt; &gt; &gt; &gt; it's fixed now but I have a bunch of errors on Google.  Here are some
&gt; &gt; &gt; &gt; examples:

&gt; &gt; &gt; &gt; http://a-ok-site.com/factbook/factbook2000/factbook/flags/al-lgflag.j ......

&gt; &gt; &gt; &gt; Any ideas because it's a real pain to do all of the URL removals on
&gt; &gt; &gt; &gt; Google.

&gt; &gt; &gt; &gt; My site URL= http://a-ok-site.com , site map files= http://a-ok-site.com/
&gt; &gt; &gt; &gt; sitemap.xml http://a-ok-site.com/sitemap.xml.gzhttp://a-ok-site.com/urllist.txt

&gt; &gt; &gt; &gt; Thanks,

&gt; &gt; &gt; &gt; Dan- Hide quoted text -

&gt; &gt; - Show quoted text -
">
</POST>
<POST>
<POSTER> a-ok-site &lt;a.ok.s...@gmail.com&gt; </POSTER>
<POSTDATE> 2007-08-17T12:43:00 </POSTDATE>
Sent gift via paypal, for your trouble.  I just wanted you to know you
are appreciated.  :-)

On Aug 17, 11:36 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; Could I ban the factbook urls and do a manual entry.  Could this cause
&gt; a conflict the next time I crawl?  later.

&gt; On Aug 17, 11:30 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; Ok I am still crawling, up at 40%. Slow.

&gt; &gt; Well your factbook is a problem. Based on the url structure it may be
&gt; &gt; hard or easy to limit to their homepages. But might be good.

&gt; &gt; On Aug 17, 12:24 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; ooops, Sorry for the double post but I removed all gif, jpg, etc files
&gt; &gt; &gt; after the errors.  All that I am currently crawling is html, htm, pdf,
&gt; &gt; &gt; txt, rtf.  Later.

&gt; &gt; &gt; On Aug 17, 11:13 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; First off jpegs and other images and media files should not be in the
&gt; &gt; &gt; &gt; sitemap at all. You can exclude them from GSC using the filters.
&gt; &gt; &gt; &gt; The way images get into the Google image indexex is by their being
&gt; &gt; &gt; &gt; roesent on pages that are being indexed regularly.

&gt; &gt; &gt; &gt; Google's errors from the sitemap will disappear after 2-3 weeks.
&gt; &gt; &gt; &gt; Google indexes your site from a crawl starting at the root, the
&gt; &gt; &gt; &gt; sitemap is just a reference. If you have  bad links appearing in the
&gt; &gt; &gt; &gt; index maybe there's somehtign wrong with your site's navigation and
&gt; &gt; &gt; &gt; bad links get generated. have you used Xenu to crawl the site?

&gt; &gt; &gt; &gt; What I see there that's wrong is your robots.txt file shoudl disallow
&gt; &gt; &gt; &gt; the gallery since it generates url's with session ids.
&gt; &gt; &gt; &gt; I see the broken url's in your robtos.txt fle - that won't solve the
&gt; &gt; &gt; &gt; problem long term of broken url's if they are from your navigation.

&gt; &gt; &gt; &gt; It seems a crawl is getting bogged down by an explosion of url's from
&gt; &gt; &gt; &gt; somewhere, because after it had reached 45% it suddenly dropped to 14%
&gt; &gt; &gt; &gt; and it's slowly crept up to 17%  even while more url's are getting
&gt; &gt; &gt; &gt; crawled yet the total keeps moving higher - and this is after I
&gt; &gt; &gt; &gt; excldued the gallery too.
&gt; &gt; &gt; &gt; There's something producing  huge numbers of url's in the factbook
&gt; &gt; &gt; &gt; folder.
&gt; &gt; &gt; &gt; Whether that's OOK or not I don't knwo as I've not finished scanning.
&gt; &gt; &gt; &gt; At this rate it will take very long.

&gt; &gt; &gt; &gt; On Aug 17, 11:35 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; I generated a new site map and when I uploaded it Google found 62 e404
&gt; &gt; &gt; &gt; &gt; errors, but there are no actual e404 errors on my site.  All of these
&gt; &gt; &gt; &gt; &gt; were caused by errors created by GSC.  The file type was cut off
&gt; &gt; &gt; &gt; &gt; like .jpg into .j, html into .ht, etc.  Is there a URL link length
&gt; &gt; &gt; &gt; &gt; requirement or is this just a freak error.  I reran GSC and I think
&gt; &gt; &gt; &gt; &gt; it's fixed now but I have a bunch of errors on Google.  Here are some
&gt; &gt; &gt; &gt; &gt; examples:

&gt; &gt; &gt; &gt; &gt; http://a-ok-site.com/factbook/factbook2000/factbook/flags/al-lgflag.j ......

&gt; &gt; &gt; &gt; &gt; Any ideas because it's a real pain to do all of the URL removals on
&gt; &gt; &gt; &gt; &gt; Google.

&gt; &gt; &gt; &gt; &gt; My site URL= http://a-ok-site.com , site map files= http://a-ok-site.com/
&gt; &gt; &gt; &gt; &gt; sitemap.xml http://a-ok-site.com/sitemap.xml.gzhttp://a-ok-site.com/urllist.txt

&gt; &gt; &gt; &gt; &gt; Thanks,

&gt; &gt; &gt; &gt; &gt; Dan- Hide quoted text -

&gt; &gt; &gt; - Show quoted text -
">
</POST>
<POST>
<POSTER> &quot;ms&quot; &lt;m...@eyespyli.com&gt; </POSTER>
<POSTDATE> 2007-08-17T13:57:00 </POSTDATE>
Webado, I want to send a gift as well but do not have a paypal account.
Anyway I can use Visa or MasterCard?

What a great program!

Michael
http://www.eyespyli.com

<QUOTE PREVIOUSPOST="
-----Original Message-----
From: gsitecrawler@googlegroups.com

[mailto:gsitecrawler@googlegroups.com]On Behalf Of webado
Sent: Friday, August 17, 2007 11:30 AM
To: SOFTplus GSiteCrawler
Subject: [GSiteCrawler] Re: GSC Sitemap Contains errors

Ok I am still crawling, up at 40%. Slow.

Well your factbook is a problem. Based on the url structure it may be
hard or easy to limit to their homepages. But might be good.

On Aug 17, 12:24 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:
&gt; ooops, Sorry for the double post but I removed all gif, jpg, etc files
&gt; after the errors.  All that I am currently crawling is html, htm, pdf,
&gt; txt, rtf.  Later.

&gt; On Aug 17, 11:13 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; First off jpegs and other images and media files should not be in the
&gt; &gt; sitemap at all. You can exclude them from GSC using the filters.
&gt; &gt; The way images get into the Google image indexex is by their being
&gt; &gt; roesent on pages that are being indexed regularly.

&gt; &gt; Google's errors from the sitemap will disappear after 2-3 weeks.
&gt; &gt; Google indexes your site from a crawl starting at the root, the
&gt; &gt; sitemap is just a reference. If you have  bad links appearing in the
&gt; &gt; index maybe there's somehtign wrong with your site's navigation and
&gt; &gt; bad links get generated. have you used Xenu to crawl the site?

&gt; &gt; What I see there that's wrong is your robots.txt file shoudl disallow
&gt; &gt; the gallery since it generates url's with session ids.
&gt; &gt; I see the broken url's in your robtos.txt fle - that won't solve the
&gt; &gt; problem long term of broken url's if they are from your navigation.

&gt; &gt; It seems a crawl is getting bogged down by an explosion of url's from
&gt; &gt; somewhere, because after it had reached 45% it suddenly dropped to 14%
&gt; &gt; and it's slowly crept up to 17%  even while more url's are getting
&gt; &gt; crawled yet the total keeps moving higher - and this is after I
&gt; &gt; excldued the gallery too.
&gt; &gt; There's something producing  huge numbers of url's in the factbook
&gt; &gt; folder.
&gt; &gt; Whether that's OOK or not I don't knwo as I've not finished scanning.
&gt; &gt; At this rate it will take very long.

&gt; &gt; On Aug 17, 11:35 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; I generated a new site map and when I uploaded it Google found 62 e404
&gt; &gt; &gt; errors, but there are no actual e404 errors on my site.  All of these
&gt; &gt; &gt; were caused by errors created by GSC.  The file type was cut off
&gt; &gt; &gt; like .jpg into .j, html into .ht, etc.  Is there a URL link length
&gt; &gt; &gt; requirement or is this just a freak error.  I reran GSC and I think
&gt; &gt; &gt; it's fixed now but I have a bunch of errors on Google.  Here are some
&gt; &gt; &gt; examples:

&gt; http://a-ok-site.com/factbook/factbook2000/factbook/flags/al-lgflag.j ......

&gt; &gt; &gt; Any ideas because it's a real pain to do all of the URL removals on
&gt; &gt; &gt; Google.

&gt; &gt; &gt; My site URL= http://a-ok-site.com , site map files= http://a-ok-site.com/

sitemap.xml http://a-ok-site.com/sitemap.xml.gzhttp://a-ok-site.com/urllist.t
xt

&gt; &gt; &gt; Thanks,

&gt; &gt; &gt; Dan- Hide quoted text -

&gt; - Show quoted text -
">
</POST>
<POST>
<POSTER> a-ok-site &lt;a.ok.s...@gmail.com&gt; </POSTER>
<POSTDATE> 2007-08-17T13:00:00 </POSTDATE>
Yes you can.  I had the same question.  Later.

On Aug 17, 12:57 pm, &quot;ms&quot; &lt;m ... @eyespyli.com&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; Webado, I want to send a gift as well but do not have a paypal account.
&gt; Anyway I can use Visa or MasterCard?

&gt; What a great program!

&gt; Michael http://www.eyespyli.com

&gt; -----Original Message-----
&gt; From: gsitecrawler@googlegroups.com

&gt; [mailto:gsitecrawler@googlegroups.com]On Behalf Of webado
&gt; Sent: Friday, August 17, 2007 11:30 AM
&gt; To: SOFTplus GSiteCrawler
&gt; Subject: [GSiteCrawler] Re: GSC Sitemap Contains errors

&gt; Ok I am still crawling, up at 40%. Slow.

&gt; Well your factbook is a problem. Based on the url structure it may be
&gt; hard or easy to limit to their homepages. But might be good.

&gt; On Aug 17, 12:24 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:
&gt; &gt; ooops, Sorry for the double post but I removed all gif, jpg, etc files
&gt; &gt; after the errors.  All that I am currently crawling is html, htm, pdf,
&gt; &gt; txt, rtf.  Later.

&gt; &gt; On Aug 17, 11:13 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; First off jpegs and other images and media files should not be in the
&gt; &gt; &gt; sitemap at all. You can exclude them from GSC using the filters.
&gt; &gt; &gt; The way images get into the Google image indexex is by their being
&gt; &gt; &gt; roesent on pages that are being indexed regularly.

&gt; &gt; &gt; Google's errors from the sitemap will disappear after 2-3 weeks.
&gt; &gt; &gt; Google indexes your site from a crawl starting at the root, the
&gt; &gt; &gt; sitemap is just a reference. If you have  bad links appearing in the
&gt; &gt; &gt; index maybe there's somehtign wrong with your site's navigation and
&gt; &gt; &gt; bad links get generated. have you used Xenu to crawl the site?

&gt; &gt; &gt; What I see there that's wrong is your robots.txt file shoudl disallow
&gt; &gt; &gt; the gallery since it generates url's with session ids.
&gt; &gt; &gt; I see the broken url's in your robtos.txt fle - that won't solve the
&gt; &gt; &gt; problem long term of broken url's if they are from your navigation.

&gt; &gt; &gt; It seems a crawl is getting bogged down by an explosion of url's from
&gt; &gt; &gt; somewhere, because after it had reached 45% it suddenly dropped to 14%
&gt; &gt; &gt; and it's slowly crept up to 17%  even while more url's are getting
&gt; &gt; &gt; crawled yet the total keeps moving higher - and this is after I
&gt; &gt; &gt; excldued the gallery too.
&gt; &gt; &gt; There's something producing  huge numbers of url's in the factbook
&gt; &gt; &gt; folder.
&gt; &gt; &gt; Whether that's OOK or not I don't knwo as I've not finished scanning.
&gt; &gt; &gt; At this rate it will take very long.

&gt; &gt; &gt; On Aug 17, 11:35 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; I generated a new site map and when I uploaded it Google found 62 e404
&gt; &gt; &gt; &gt; errors, but there are no actual e404 errors on my site.  All of these
&gt; &gt; &gt; &gt; were caused by errors created by GSC.  The file type was cut off
&gt; &gt; &gt; &gt; like .jpg into .j, html into .ht, etc.  Is there a URL link length
&gt; &gt; &gt; &gt; requirement or is this just a freak error.  I reran GSC and I think
&gt; &gt; &gt; &gt; it's fixed now but I have a bunch of errors on Google.  Here are some
&gt; &gt; &gt; &gt; examples:

&gt; &gt; http://a-ok-site.com/factbook/factbook2000/factbook/flags/al-lgflag.j ......

&gt; &gt; &gt; &gt; Any ideas because it's a real pain to do all of the URL removals on
&gt; &gt; &gt; &gt; Google.

&gt; &gt; &gt; &gt; My site URL= http://a-ok-site.com , site map files= http://a-ok-site.com/

&gt; sitemap.xml http://a-ok-site.com/sitemap.xml.gzhttp://a-ok-site.com/urllist.t
&gt; xt

&gt; &gt; &gt; &gt; Thanks,

&gt; &gt; &gt; &gt; Dan- Hide quoted text -

&gt; &gt; - Show quoted text -
">
</POST>
<POST>
<POSTER> webado &lt;web...@gmail.com&gt; </POSTER>
<POSTDATE> 2007-08-17T13:02:00 </POSTDATE>
Oh gosh, thank you so much!

The factbook could perhaps get a crawl by itself.

Let say in GSC you have 2 projects:
1) http://a-ok-site.com/ with a ban on the factbook folder (and
gallery)
2) htt://a-ok-site/factbook/   by itself

You  will get a sitemap from the first project with everythign but
fatcbook url's and a seprate sitemap from the second project with only
factbook urls.
You can submit 2 separate sitemaps  in Webmaster tools for the same
site.

If using the xml sitemaps, then you can also have a sitemap index
listing the 2 separate xml sitemaps. You'll have to make that one
manually according to the protocol described in the help in Webmaster
Tools.

On Aug 17, 12:43 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; Sent gift via paypal, for your trouble.  I just wanted you to know you
&gt; are appreciated.  :-)

&gt; On Aug 17, 11:36 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; Could I ban the factbook urls and do a manual entry.  Could this cause
&gt; &gt; a conflict the next time I crawl?  later.

&gt; &gt; On Aug 17, 11:30 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; Ok I am still crawling, up at 40%. Slow.

&gt; &gt; &gt; Well your factbook is a problem. Based on the url structure it may be
&gt; &gt; &gt; hard or easy to limit to their homepages. But might be good.

&gt; &gt; &gt; On Aug 17, 12:24 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; ooops, Sorry for the double post but I removed all gif, jpg, etc files
&gt; &gt; &gt; &gt; after the errors.  All that I am currently crawling is html, htm, pdf,
&gt; &gt; &gt; &gt; txt, rtf.  Later.

&gt; &gt; &gt; &gt; On Aug 17, 11:13 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; First off jpegs and other images and media files should not be in the
&gt; &gt; &gt; &gt; &gt; sitemap at all. You can exclude them from GSC using the filters.
&gt; &gt; &gt; &gt; &gt; The way images get into the Google image indexex is by their being
&gt; &gt; &gt; &gt; &gt; roesent on pages that are being indexed regularly.

&gt; &gt; &gt; &gt; &gt; Google's errors from the sitemap will disappear after 2-3 weeks.
&gt; &gt; &gt; &gt; &gt; Google indexes your site from a crawl starting at the root, the
&gt; &gt; &gt; &gt; &gt; sitemap is just a reference. If you have  bad links appearing in the
&gt; &gt; &gt; &gt; &gt; index maybe there's somehtign wrong with your site's navigation and
&gt; &gt; &gt; &gt; &gt; bad links get generated. have you used Xenu to crawl the site?

&gt; &gt; &gt; &gt; &gt; What I see there that's wrong is your robots.txt file shoudl disallow
&gt; &gt; &gt; &gt; &gt; the gallery since it generates url's with session ids.
&gt; &gt; &gt; &gt; &gt; I see the broken url's in your robtos.txt fle - that won't solve the
&gt; &gt; &gt; &gt; &gt; problem long term of broken url's if they are from your navigation.

&gt; &gt; &gt; &gt; &gt; It seems a crawl is getting bogged down by an explosion of url's from
&gt; &gt; &gt; &gt; &gt; somewhere, because after it had reached 45% it suddenly dropped to 14%
&gt; &gt; &gt; &gt; &gt; and it's slowly crept up to 17%  even while more url's are getting
&gt; &gt; &gt; &gt; &gt; crawled yet the total keeps moving higher - and this is after I
&gt; &gt; &gt; &gt; &gt; excldued the gallery too.
&gt; &gt; &gt; &gt; &gt; There's something producing  huge numbers of url's in the factbook
&gt; &gt; &gt; &gt; &gt; folder.
&gt; &gt; &gt; &gt; &gt; Whether that's OOK or not I don't knwo as I've not finished scanning.
&gt; &gt; &gt; &gt; &gt; At this rate it will take very long.

&gt; &gt; &gt; &gt; &gt; On Aug 17, 11:35 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; I generated a new site map and when I uploaded it Google found 62 e404
&gt; &gt; &gt; &gt; &gt; &gt; errors, but there are no actual e404 errors on my site.  All of these
&gt; &gt; &gt; &gt; &gt; &gt; were caused by errors created by GSC.  The file type was cut off
&gt; &gt; &gt; &gt; &gt; &gt; like .jpg into .j, html into .ht, etc.  Is there a URL link length
&gt; &gt; &gt; &gt; &gt; &gt; requirement or is this just a freak error.  I reran GSC and I think
&gt; &gt; &gt; &gt; &gt; &gt; it's fixed now but I have a bunch of errors on Google.  Here are some
&gt; &gt; &gt; &gt; &gt; &gt; examples:

&gt; &gt; &gt; &gt; &gt; &gt; http://a-ok-site.com/factbook/factbook2000/factbook/flags/al-lgflag.j ......

&gt; &gt; &gt; &gt; &gt; &gt; Any ideas because it's a real pain to do all of the URL removals on
&gt; &gt; &gt; &gt; &gt; &gt; Google.

&gt; &gt; &gt; &gt; &gt; &gt; My site URL= http://a-ok-site.com , site map files= http://a-ok-site.com/
&gt; &gt; &gt; &gt; &gt; &gt; sitemap.xml http://a-ok-site.com/sitemap.xml.gzhttp://a-ok-site.com/urllist.txt

&gt; &gt; &gt; &gt; &gt; &gt; Thanks,

&gt; &gt; &gt; &gt; &gt; &gt; Dan- Hide quoted text -

&gt; &gt; &gt; &gt; - Show quoted text -- Hide quoted text -

&gt; - Show quoted text -
">
</POST>
<POST>
<POSTER> a-ok-site &lt;a.ok.s...@gmail.com&gt; </POSTER>
<POSTDATE> 2007-08-17T13:02:00 </POSTDATE>
URL to DONATE http://gsitecrawler.com/en/donate/

On Aug 17, 12:57 pm, &quot;ms&quot; &lt;m ... @eyespyli.com&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; Webado, I want to send a gift as well but do not have a paypal account.
&gt; Anyway I can use Visa or MasterCard?

&gt; What a great program!

&gt; Michael http://www.eyespyli.com

&gt; -----Original Message-----
&gt; From: gsitecrawler@googlegroups.com

&gt; [mailto:gsitecrawler@googlegroups.com]On Behalf Of webado
&gt; Sent: Friday, August 17, 2007 11:30 AM
&gt; To: SOFTplus GSiteCrawler
&gt; Subject: [GSiteCrawler] Re: GSC Sitemap Contains errors

&gt; Ok I am still crawling, up at 40%. Slow.

&gt; Well your factbook is a problem. Based on the url structure it may be
&gt; hard or easy to limit to their homepages. But might be good.

&gt; On Aug 17, 12:24 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:
&gt; &gt; ooops, Sorry for the double post but I removed all gif, jpg, etc files
&gt; &gt; after the errors.  All that I am currently crawling is html, htm, pdf,
&gt; &gt; txt, rtf.  Later.

&gt; &gt; On Aug 17, 11:13 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; First off jpegs and other images and media files should not be in the
&gt; &gt; &gt; sitemap at all. You can exclude them from GSC using the filters.
&gt; &gt; &gt; The way images get into the Google image indexex is by their being
&gt; &gt; &gt; roesent on pages that are being indexed regularly.

&gt; &gt; &gt; Google's errors from the sitemap will disappear after 2-3 weeks.
&gt; &gt; &gt; Google indexes your site from a crawl starting at the root, the
&gt; &gt; &gt; sitemap is just a reference. If you have  bad links appearing in the
&gt; &gt; &gt; index maybe there's somehtign wrong with your site's navigation and
&gt; &gt; &gt; bad links get generated. have you used Xenu to crawl the site?

&gt; &gt; &gt; What I see there that's wrong is your robots.txt file shoudl disallow
&gt; &gt; &gt; the gallery since it generates url's with session ids.
&gt; &gt; &gt; I see the broken url's in your robtos.txt fle - that won't solve the
&gt; &gt; &gt; problem long term of broken url's if they are from your navigation.

&gt; &gt; &gt; It seems a crawl is getting bogged down by an explosion of url's from
&gt; &gt; &gt; somewhere, because after it had reached 45% it suddenly dropped to 14%
&gt; &gt; &gt; and it's slowly crept up to 17%  even while more url's are getting
&gt; &gt; &gt; crawled yet the total keeps moving higher - and this is after I
&gt; &gt; &gt; excldued the gallery too.
&gt; &gt; &gt; There's something producing  huge numbers of url's in the factbook
&gt; &gt; &gt; folder.
&gt; &gt; &gt; Whether that's OOK or not I don't knwo as I've not finished scanning.
&gt; &gt; &gt; At this rate it will take very long.

&gt; &gt; &gt; On Aug 17, 11:35 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; I generated a new site map and when I uploaded it Google found 62 e404
&gt; &gt; &gt; &gt; errors, but there are no actual e404 errors on my site.  All of these
&gt; &gt; &gt; &gt; were caused by errors created by GSC.  The file type was cut off
&gt; &gt; &gt; &gt; like .jpg into .j, html into .ht, etc.  Is there a URL link length
&gt; &gt; &gt; &gt; requirement or is this just a freak error.  I reran GSC and I think
&gt; &gt; &gt; &gt; it's fixed now but I have a bunch of errors on Google.  Here are some
&gt; &gt; &gt; &gt; examples:

&gt; &gt; http://a-ok-site.com/factbook/factbook2000/factbook/flags/al-lgflag.j ......

&gt; &gt; &gt; &gt; Any ideas because it's a real pain to do all of the URL removals on
&gt; &gt; &gt; &gt; Google.

&gt; &gt; &gt; &gt; My site URL= http://a-ok-site.com , site map files= http://a-ok-site.com/

&gt; sitemap.xml http://a-ok-site.com/sitemap.xml.gzhttp://a-ok-site.com/urllist.t
&gt; xt

&gt; &gt; &gt; &gt; Thanks,

&gt; &gt; &gt; &gt; Dan- Hide quoted text -

&gt; &gt; - Show quoted text -
">
</POST>
<POST>
<POSTER> a-ok-site &lt;a.ok.s...@gmail.com&gt; </POSTER>
<POSTDATE> 2007-08-17T13:04:00 </POSTDATE>
OK.  I started the one with no factbook, and will do some research and
make the other one soon.  Thanks for the help.  Later.

On Aug 17, 12:02 pm, webado &lt;web ... @gmail.com&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; Oh gosh, thank you so much!

&gt; The factbook could perhaps get a crawl by itself.

&gt; Let say in GSC you have 2 projects:
&gt; 1) http://a-ok-site.com/with a ban on the factbook folder (and
&gt; gallery)
&gt; 2) htt://a-ok-site/factbook/   by itself

&gt; You  will get a sitemap from the first project with everythign but
&gt; fatcbook url's and a seprate sitemap from the second project with only
&gt; factbook urls.
&gt; You can submit 2 separate sitemaps  in Webmaster tools for the same
&gt; site.

&gt; If using the xml sitemaps, then you can also have a sitemap index
&gt; listing the 2 separate xml sitemaps. You'll have to make that one
&gt; manually according to the protocol described in the help in Webmaster
&gt; Tools.

&gt; On Aug 17, 12:43 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; Sent gift via paypal, for your trouble.  I just wanted you to know you
&gt; &gt; are appreciated.  :-)

&gt; &gt; On Aug 17, 11:36 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; Could I ban the factbook urls and do a manual entry.  Could this cause
&gt; &gt; &gt; a conflict the next time I crawl?  later.

&gt; &gt; &gt; On Aug 17, 11:30 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; Ok I am still crawling, up at 40%. Slow.

&gt; &gt; &gt; &gt; Well your factbook is a problem. Based on the url structure it may be
&gt; &gt; &gt; &gt; hard or easy to limit to their homepages. But might be good.

&gt; &gt; &gt; &gt; On Aug 17, 12:24 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; ooops, Sorry for the double post but I removed all gif, jpg, etc files
&gt; &gt; &gt; &gt; &gt; after the errors.  All that I am currently crawling is html, htm, pdf,
&gt; &gt; &gt; &gt; &gt; txt, rtf.  Later.

&gt; &gt; &gt; &gt; &gt; On Aug 17, 11:13 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; First off jpegs and other images and media files should not be in the
&gt; &gt; &gt; &gt; &gt; &gt; sitemap at all. You can exclude them from GSC using the filters.
&gt; &gt; &gt; &gt; &gt; &gt; The way images get into the Google image indexex is by their being
&gt; &gt; &gt; &gt; &gt; &gt; roesent on pages that are being indexed regularly.

&gt; &gt; &gt; &gt; &gt; &gt; Google's errors from the sitemap will disappear after 2-3 weeks.
&gt; &gt; &gt; &gt; &gt; &gt; Google indexes your site from a crawl starting at the root, the
&gt; &gt; &gt; &gt; &gt; &gt; sitemap is just a reference. If you have  bad links appearing in the
&gt; &gt; &gt; &gt; &gt; &gt; index maybe there's somehtign wrong with your site's navigation and
&gt; &gt; &gt; &gt; &gt; &gt; bad links get generated. have you used Xenu to crawl the site?

&gt; &gt; &gt; &gt; &gt; &gt; What I see there that's wrong is your robots.txt file shoudl disallow
&gt; &gt; &gt; &gt; &gt; &gt; the gallery since it generates url's with session ids.
&gt; &gt; &gt; &gt; &gt; &gt; I see the broken url's in your robtos.txt fle - that won't solve the
&gt; &gt; &gt; &gt; &gt; &gt; problem long term of broken url's if they are from your navigation.

&gt; &gt; &gt; &gt; &gt; &gt; It seems a crawl is getting bogged down by an explosion of url's from
&gt; &gt; &gt; &gt; &gt; &gt; somewhere, because after it had reached 45% it suddenly dropped to 14%
&gt; &gt; &gt; &gt; &gt; &gt; and it's slowly crept up to 17%  even while more url's are getting
&gt; &gt; &gt; &gt; &gt; &gt; crawled yet the total keeps moving higher - and this is after I
&gt; &gt; &gt; &gt; &gt; &gt; excldued the gallery too.
&gt; &gt; &gt; &gt; &gt; &gt; There's something producing  huge numbers of url's in the factbook
&gt; &gt; &gt; &gt; &gt; &gt; folder.
&gt; &gt; &gt; &gt; &gt; &gt; Whether that's OOK or not I don't knwo as I've not finished scanning.
&gt; &gt; &gt; &gt; &gt; &gt; At this rate it will take very long.

&gt; &gt; &gt; &gt; &gt; &gt; On Aug 17, 11:35 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; I generated a new site map and when I uploaded it Google found 62 e404
&gt; &gt; &gt; &gt; &gt; &gt; &gt; errors, but there are no actual e404 errors on my site.  All of these
&gt; &gt; &gt; &gt; &gt; &gt; &gt; were caused by errors created by GSC.  The file type was cut off
&gt; &gt; &gt; &gt; &gt; &gt; &gt; like .jpg into .j, html into .ht, etc.  Is there a URL link length
&gt; &gt; &gt; &gt; &gt; &gt; &gt; requirement or is this just a freak error.  I reran GSC and I think
&gt; &gt; &gt; &gt; &gt; &gt; &gt; it's fixed now but I have a bunch of errors on Google.  Here are some
&gt; &gt; &gt; &gt; &gt; &gt; &gt; examples:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; http://a-ok-site.com/factbook/factbook2000/factbook/flags/al-lgflag.j ......

&gt; &gt; &gt; &gt; &gt; &gt; &gt; Any ideas because it's a real pain to do all of the URL removals on
&gt; &gt; &gt; &gt; &gt; &gt; &gt; Google.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; My site URL= http://a-ok-site.com , site map files= http://a-ok-site.com/
&gt; &gt; &gt; &gt; &gt; &gt; &gt; sitemap.xml http://a-ok-site.com/sitemap.xml.gzhttp://a-ok-site.com/urllist.txt

&gt; &gt; &gt; &gt; &gt; &gt; &gt; Thanks,

&gt; &gt; &gt; &gt; &gt; &gt; &gt; Dan- Hide quoted text -

&gt; &gt; &gt; &gt; &gt; - Show quoted text -- Hide quoted text -

&gt; &gt; - Show quoted text -
">
</POST>
<POST>
<POSTER> a-ok-site &lt;a.ok.s...@gmail.com&gt; </POSTER>
<POSTDATE> 2007-08-17T13:30:00 </POSTDATE>
Alright, I made the sitmap_index.xml file, but I couldn't find out if
I need to list it only in webmaster tools, or do I still least each
individual sitemap?

&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;sitemapindex xmlns=&quot; http://www.sitemaps.org/schemas/sitemap/0.9 &quot;&gt;
&lt;sitemap&gt;
&lt;loc&gt; http://a-ok-site.com/sitemap.xml.gz &lt;/loc&gt;
&lt;lastmod&gt;2004-10-01T18:23:17+00:00&lt;/lastmod&gt;
&lt;/sitemap&gt;
&lt;sitemap&gt;
&lt;loc&gt; http://a-ok-site.com/sitemap2.xml.gz &lt;/loc&gt;
&lt;lastmod&gt;2005-01-01&lt;/lastmod&gt;
&lt;/sitemap&gt;
&lt;/sitemapindex&gt;

On Aug 17, 12:02 pm, webado &lt;web ... @gmail.com&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; Oh gosh, thank you so much!

&gt; The factbook could perhaps get a crawl by itself.

&gt; Let say in GSC you have 2 projects:
&gt; 1) http://a-ok-site.com/with a ban on the factbook folder (and
&gt; gallery)
&gt; 2) htt://a-ok-site/factbook/   by itself

&gt; You  will get a sitemap from the first project with everythign but
&gt; fatcbook url's and a seprate sitemap from the second project with only
&gt; factbook urls.
&gt; You can submit 2 separate sitemaps  in Webmaster tools for the same
&gt; site.

&gt; If using the xml sitemaps, then you can also have a sitemap index
&gt; listing the 2 separate xml sitemaps. You'll have to make that one
&gt; manually according to the protocol described in the help in Webmaster
&gt; Tools.

&gt; On Aug 17, 12:43 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; Sent gift via paypal, for your trouble.  I just wanted you to know you
&gt; &gt; are appreciated.  :-)

&gt; &gt; On Aug 17, 11:36 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; Could I ban the factbook urls and do a manual entry.  Could this cause
&gt; &gt; &gt; a conflict the next time I crawl?  later.

&gt; &gt; &gt; On Aug 17, 11:30 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; Ok I am still crawling, up at 40%. Slow.

&gt; &gt; &gt; &gt; Well your factbook is a problem. Based on the url structure it may be
&gt; &gt; &gt; &gt; hard or easy to limit to their homepages. But might be good.

&gt; &gt; &gt; &gt; On Aug 17, 12:24 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; ooops, Sorry for the double post but I removed all gif, jpg, etc files
&gt; &gt; &gt; &gt; &gt; after the errors.  All that I am currently crawling is html, htm, pdf,
&gt; &gt; &gt; &gt; &gt; txt, rtf.  Later.

&gt; &gt; &gt; &gt; &gt; On Aug 17, 11:13 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; First off jpegs and other images and media files should not be in the
&gt; &gt; &gt; &gt; &gt; &gt; sitemap at all. You can exclude them from GSC using the filters.
&gt; &gt; &gt; &gt; &gt; &gt; The way images get into the Google image indexex is by their being
&gt; &gt; &gt; &gt; &gt; &gt; roesent on pages that are being indexed regularly.

&gt; &gt; &gt; &gt; &gt; &gt; Google's errors from the sitemap will disappear after 2-3 weeks.
&gt; &gt; &gt; &gt; &gt; &gt; Google indexes your site from a crawl starting at the root, the
&gt; &gt; &gt; &gt; &gt; &gt; sitemap is just a reference. If you have  bad links appearing in the
&gt; &gt; &gt; &gt; &gt; &gt; index maybe there's somehtign wrong with your site's navigation and
&gt; &gt; &gt; &gt; &gt; &gt; bad links get generated. have you used Xenu to crawl the site?

&gt; &gt; &gt; &gt; &gt; &gt; What I see there that's wrong is your robots.txt file shoudl disallow
&gt; &gt; &gt; &gt; &gt; &gt; the gallery since it generates url's with session ids.
&gt; &gt; &gt; &gt; &gt; &gt; I see the broken url's in your robtos.txt fle - that won't solve the
&gt; &gt; &gt; &gt; &gt; &gt; problem long term of broken url's if they are from your navigation.

&gt; &gt; &gt; &gt; &gt; &gt; It seems a crawl is getting bogged down by an explosion of url's from
&gt; &gt; &gt; &gt; &gt; &gt; somewhere, because after it had reached 45% it suddenly dropped to 14%
&gt; &gt; &gt; &gt; &gt; &gt; and it's slowly crept up to 17%  even while more url's are getting
&gt; &gt; &gt; &gt; &gt; &gt; crawled yet the total keeps moving higher - and this is after I
&gt; &gt; &gt; &gt; &gt; &gt; excldued the gallery too.
&gt; &gt; &gt; &gt; &gt; &gt; There's something producing  huge numbers of url's in the factbook
&gt; &gt; &gt; &gt; &gt; &gt; folder.
&gt; &gt; &gt; &gt; &gt; &gt; Whether that's OOK or not I don't knwo as I've not finished scanning.
&gt; &gt; &gt; &gt; &gt; &gt; At this rate it will take very long.

&gt; &gt; &gt; &gt; &gt; &gt; On Aug 17, 11:35 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; I generated a new site map and when I uploaded it Google found 62 e404
&gt; &gt; &gt; &gt; &gt; &gt; &gt; errors, but there are no actual e404 errors on my site.  All of these
&gt; &gt; &gt; &gt; &gt; &gt; &gt; were caused by errors created by GSC.  The file type was cut off
&gt; &gt; &gt; &gt; &gt; &gt; &gt; like .jpg into .j, html into .ht, etc.  Is there a URL link length
&gt; &gt; &gt; &gt; &gt; &gt; &gt; requirement or is this just a freak error.  I reran GSC and I think
&gt; &gt; &gt; &gt; &gt; &gt; &gt; it's fixed now but I have a bunch of errors on Google.  Here are some
&gt; &gt; &gt; &gt; &gt; &gt; &gt; examples:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; http://a-ok-site.com/factbook/factbook2000/factbook/flags/al-lgflag.j ......

&gt; &gt; &gt; &gt; &gt; &gt; &gt; Any ideas because it's a real pain to do all of the URL removals on
&gt; &gt; &gt; &gt; &gt; &gt; &gt; Google.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; My site URL= http://a-ok-site.com , site map files= http://a-ok-site.com/
&gt; &gt; &gt; &gt; &gt; &gt; &gt; sitemap.xml http://a-ok-site.com/sitemap.xml.gzhttp://a-ok-site.com/urllist.txt

&gt; &gt; &gt; &gt; &gt; &gt; &gt; Thanks,

&gt; &gt; &gt; &gt; &gt; &gt; &gt; Dan- Hide quoted text -

&gt; &gt; &gt; &gt; &gt; - Show quoted text -- Hide quoted text -

&gt; &gt; - Show quoted text -
">
</POST>
<POST>
<POSTER> webado &lt;web...@gmail.com&gt; </POSTER>
<POSTDATE> 2007-08-17T15:36:00 </POSTDATE>
As far as I know all you need is to give the url of the index file and
from it Google will find the 2 sitemaps.

I've never used a sitemap index myself so I don't know first hand.
It should be OK.

Oh the dates might need fixing?

On 17 août, 13:30, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; Alright, I made the sitmap_index.xml file, but I couldn't find out if
&gt; I need to list it only in webmaster tools, or do I still least each
&gt; individual sitemap?

&gt; &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&gt;    &lt;sitemapindex xmlns=&quot; http://www.sitemaps.org/schemas/sitemap/0.9 &quot;&gt;
&gt;    &lt;sitemap&gt;
&gt;       &lt;loc&gt; http://a-ok-site.com/sitemap.xml.gz &lt;/loc&gt;
&gt;       &lt;lastmod&gt;2004-10-01T18:23:17+00:00&lt;/lastmod&gt;
&gt;    &lt;/sitemap&gt;
&gt;    &lt;sitemap&gt;
&gt;       &lt;loc&gt; http://a-ok-site.com/sitemap2.xml.gz &lt;/loc&gt;
&gt;       &lt;lastmod&gt;2005-01-01&lt;/lastmod&gt;
&gt;    &lt;/sitemap&gt;
&gt;    &lt;/sitemapindex&gt;

&gt; On Aug 17, 12:02 pm, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; Oh gosh, thank you so much!

&gt; &gt; The factbook could perhaps get a crawl by itself.

&gt; &gt; Let say in GSC you have 2 projects:
&gt; &gt; 1) http://a-ok-site.com/witha ban on the factbook folder (and
&gt; &gt; gallery)
&gt; &gt; 2) htt://a-ok-site/factbook/   by itself

&gt; &gt; You  will get a sitemap from the first project with everythign but
&gt; &gt; fatcbook url's and a seprate sitemap from the second project with only
&gt; &gt; factbook urls.
&gt; &gt; You can submit 2 separate sitemaps  in Webmaster tools for the same
&gt; &gt; site.

&gt; &gt; If using the xml sitemaps, then you can also have a sitemap index
&gt; &gt; listing the 2 separate xml sitemaps. You'll have to make that one
&gt; &gt; manually according to the protocol described in the help in Webmaster
&gt; &gt; Tools.

&gt; &gt; On Aug 17, 12:43 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; Sent gift via paypal, for your trouble.  I just wanted you to know you
&gt; &gt; &gt; are appreciated.  :-)

&gt; &gt; &gt; On Aug 17, 11:36 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; Could I ban the factbook urls and do a manual entry.  Could this cause
&gt; &gt; &gt; &gt; a conflict the next time I crawl?  later.

&gt; &gt; &gt; &gt; On Aug 17, 11:30 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; Ok I am still crawling, up at 40%. Slow.

&gt; &gt; &gt; &gt; &gt; Well your factbook is a problem. Based on the url structure it may be
&gt; &gt; &gt; &gt; &gt; hard or easy to limit to their homepages. But might be good.

&gt; &gt; &gt; &gt; &gt; On Aug 17, 12:24 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; ooops, Sorry for the double post but I removed all gif, jpg, etc files
&gt; &gt; &gt; &gt; &gt; &gt; after the errors.  All that I am currently crawling is html, htm, pdf,
&gt; &gt; &gt; &gt; &gt; &gt; txt, rtf.  Later.

&gt; &gt; &gt; &gt; &gt; &gt; On Aug 17, 11:13 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; First off jpegs and other images and media files should not be in the
&gt; &gt; &gt; &gt; &gt; &gt; &gt; sitemap at all. You can exclude them from GSC using the filters.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; The way images get into the Google image indexex is by their being
&gt; &gt; &gt; &gt; &gt; &gt; &gt; roesent on pages that are being indexed regularly.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; Google's errors from the sitemap will disappear after 2-3 weeks.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; Google indexes your site from a crawl starting at the root, the
&gt; &gt; &gt; &gt; &gt; &gt; &gt; sitemap is just a reference. If you have  bad links appearing in the
&gt; &gt; &gt; &gt; &gt; &gt; &gt; index maybe there's somehtign wrong with your site's navigation and
&gt; &gt; &gt; &gt; &gt; &gt; &gt; bad links get generated. have you used Xenu to crawl the site?

&gt; &gt; &gt; &gt; &gt; &gt; &gt; What I see there that's wrong is your robots.txt file shoudl disallow
&gt; &gt; &gt; &gt; &gt; &gt; &gt; the gallery since it generates url's with session ids.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; I see the broken url's in your robtos.txt fle - that won't solve the
&gt; &gt; &gt; &gt; &gt; &gt; &gt; problem long term of broken url's if they are from your navigation.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; It seems a crawl is getting bogged down by an explosion of url's from
&gt; &gt; &gt; &gt; &gt; &gt; &gt; somewhere, because after it had reached 45% it suddenly dropped to 14%
&gt; &gt; &gt; &gt; &gt; &gt; &gt; and it's slowly crept up to 17%  even while more url's are getting
&gt; &gt; &gt; &gt; &gt; &gt; &gt; crawled yet the total keeps moving higher - and this is after I
&gt; &gt; &gt; &gt; &gt; &gt; &gt; excldued the gallery too.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; There's something producing  huge numbers of url's in the factbook
&gt; &gt; &gt; &gt; &gt; &gt; &gt; folder.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; Whether that's OOK or not I don't knwo as I've not finished scanning.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; At this rate it will take very long.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; On Aug 17, 11:35 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; I generated a new site map and when I uploaded it Google found 62 e404
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; errors, but there are no actual e404 errors on my site.  All of these
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; were caused by errors created by GSC.  The file type was cut off
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; like .jpg into .j, html into .ht, etc.  Is there a URL link length
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; requirement or is this just a freak error.  I reran GSC and I think
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; it's fixed now but I have a bunch of errors on Google.  Here are some
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; examples:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; http://a-ok-site.com/factbook/factbook2000/factbook/flags/al-lgflag.j ......

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Any ideas because it's a real pain to do all of the URL removals on
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Google.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; My site URL= http://a-ok-site.com , site map files= http://a-ok-site.com/
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; sitemap.xml http://a-ok-site.com/sitemap.xml.gzhttp://a-ok-site.com/urllist.txt

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Thanks,

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Dan- Hide quoted text -

&gt; &gt; &gt; &gt; &gt; &gt; - Show quoted text -- Hide quoted text -

&gt; &gt; &gt; - Show quoted text -- Masquer le texte des messages précédents -

&gt; - Afficher le texte des messages précédents -
">
</POST>
<POST>
<POSTER> webado &lt;web...@gmail.com&gt; </POSTER>
<POSTDATE> 2007-08-17T15:41:00 </POSTDATE>
Thanks for the thought, Michael.
This  GSiteCrawler program is John Mueller's creation. He's the one to
be rewarded.
I'm just another user of his program and the http://oyoy.eu tools.

FYI, you can use PayPal even without having a PayPal account.

On 17 août, 13:57, &quot;ms&quot; &lt;m ... @eyespyli.com&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; Webado, I want to send a gift as well but do not have a paypal account.
&gt; Anyway I can use Visa or MasterCard?

&gt; What a great program!

&gt; Michael http://www.eyespyli.com

&gt; -----Original Message-----
&gt; From: gsitecrawler@googlegroups.com

&gt; [mailto:gsitecrawler@googlegroups.com]On Behalf Of webado
&gt; Sent: Friday, August 17, 2007 11:30 AM
&gt; To: SOFTplus GSiteCrawler
&gt; Subject: [GSiteCrawler] Re: GSC Sitemap Contains errors

&gt; Ok I am still crawling, up at 40%. Slow.

&gt; Well your factbook is a problem. Based on the url structure it may be
&gt; hard or easy to limit to their homepages. But might be good.

&gt; On Aug 17, 12:24 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:
&gt; &gt; ooops, Sorry for the double post but I removed all gif, jpg, etc files
&gt; &gt; after the errors.  All that I am currently crawling is html, htm, pdf,
&gt; &gt; txt, rtf.  Later.

&gt; &gt; On Aug 17, 11:13 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; First off jpegs and other images and media files should not be in the
&gt; &gt; &gt; sitemap at all. You can exclude them from GSC using the filters.
&gt; &gt; &gt; The way images get into the Google image indexex is by their being
&gt; &gt; &gt; roesent on pages that are being indexed regularly.

&gt; &gt; &gt; Google's errors from the sitemap will disappear after 2-3 weeks.
&gt; &gt; &gt; Google indexes your site from a crawl starting at the root, the
&gt; &gt; &gt; sitemap is just a reference. If you have  bad links appearing in the
&gt; &gt; &gt; index maybe there's somehtign wrong with your site's navigation and
&gt; &gt; &gt; bad links get generated. have you used Xenu to crawl the site?

&gt; &gt; &gt; What I see there that's wrong is your robots.txt file shoudl disallow
&gt; &gt; &gt; the gallery since it generates url's with session ids.
&gt; &gt; &gt; I see the broken url's in your robtos.txt fle - that won't solve the
&gt; &gt; &gt; problem long term of broken url's if they are from your navigation.

&gt; &gt; &gt; It seems a crawl is getting bogged down by an explosion of url's from
&gt; &gt; &gt; somewhere, because after it had reached 45% it suddenly dropped to 14%
&gt; &gt; &gt; and it's slowly crept up to 17%  even while more url's are getting
&gt; &gt; &gt; crawled yet the total keeps moving higher - and this is after I
&gt; &gt; &gt; excldued the gallery too.
&gt; &gt; &gt; There's something producing  huge numbers of url's in the factbook
&gt; &gt; &gt; folder.
&gt; &gt; &gt; Whether that's OOK or not I don't knwo as I've not finished scanning.
&gt; &gt; &gt; At this rate it will take very long.

&gt; &gt; &gt; On Aug 17, 11:35 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; I generated a new site map and when I uploaded it Google found 62 e404
&gt; &gt; &gt; &gt; errors, but there are no actual e404 errors on my site.  All of these
&gt; &gt; &gt; &gt; were caused by errors created by GSC.  The file type was cut off
&gt; &gt; &gt; &gt; like .jpg into .j, html into .ht, etc.  Is there a URL link length
&gt; &gt; &gt; &gt; requirement or is this just a freak error.  I reran GSC and I think
&gt; &gt; &gt; &gt; it's fixed now but I have a bunch of errors on Google.  Here are some
&gt; &gt; &gt; &gt; examples:

&gt; &gt; http://a-ok-site.com/factbook/factbook2000/factbook/flags/al-lgflag.j ......

&gt; &gt; &gt; &gt; Any ideas because it's a real pain to do all of the URL removals on
&gt; &gt; &gt; &gt; Google.

&gt; &gt; &gt; &gt; My site URL= http://a-ok-site.com , site map files= http://a-ok-site.com/

&gt; sitemap.xml http://a-ok-site.com/sitemap.xml.gzhttp://a-ok-site.com/urllist.t
&gt; xt

&gt; &gt; &gt; &gt; Thanks,

&gt; &gt; &gt; &gt; Dan- Hide quoted text -

&gt; &gt; - Show quoted text -- Masquer le texte des messages précédents -

&gt; - Afficher le texte des messages précédents -
">
</POST>
<POST>
<POSTER> &quot;ms&quot; &lt;m...@eyespyli.com&gt; </POSTER>
<POSTDATE> 2007-08-17T16:47:00 </POSTDATE>
Thank you, I will.

For just another user U sure know a lot about it.

Thanks again for the info.

Michael

<QUOTE PREVIOUSPOST="
-----Original Message-----
From: gsitecrawler@googlegroups.com

[mailto:gsitecrawler@googlegroups.com]On Behalf Of webado
Sent: Friday, August 17, 2007 2:41 PM
To: SOFTplus GSiteCrawler
Subject: [GSiteCrawler] Re: GSC Sitemap Contains errors

Thanks for the thought, Michael.
This  GSiteCrawler program is John Mueller's creation. He's the one to
be rewarded.
I'm just another user of his program and the http://oyoy.eu tools.

FYI, you can use PayPal even without having a PayPal account.

On 17 août, 13:57, &quot;ms&quot; &lt;m ... @eyespyli.com&gt; wrote:
&gt; Webado, I want to send a gift as well but do not have a paypal account.
&gt; Anyway I can use Visa or MasterCard?

&gt; What a great program!

&gt; Michael http://www.eyespyli.com

&gt; -----Original Message-----
&gt; From: gsitecrawler@googlegroups.com

&gt; [mailto:gsitecrawler@googlegroups.com]On Behalf Of webado
&gt; Sent: Friday, August 17, 2007 11:30 AM
&gt; To: SOFTplus GSiteCrawler
&gt; Subject: [GSiteCrawler] Re: GSC Sitemap Contains errors

&gt; Ok I am still crawling, up at 40%. Slow.

&gt; Well your factbook is a problem. Based on the url structure it may be
&gt; hard or easy to limit to their homepages. But might be good.

&gt; On Aug 17, 12:24 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:
&gt; &gt; ooops, Sorry for the double post but I removed all gif, jpg, etc files
&gt; &gt; after the errors.  All that I am currently crawling is html, htm, pdf,
&gt; &gt; txt, rtf.  Later.

&gt; &gt; On Aug 17, 11:13 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; First off jpegs and other images and media files should not be in the
&gt; &gt; &gt; sitemap at all. You can exclude them from GSC using the filters.
&gt; &gt; &gt; The way images get into the Google image indexex is by their being
&gt; &gt; &gt; roesent on pages that are being indexed regularly.

&gt; &gt; &gt; Google's errors from the sitemap will disappear after 2-3 weeks.
&gt; &gt; &gt; Google indexes your site from a crawl starting at the root, the
&gt; &gt; &gt; sitemap is just a reference. If you have  bad links appearing in the
&gt; &gt; &gt; index maybe there's somehtign wrong with your site's navigation and
&gt; &gt; &gt; bad links get generated. have you used Xenu to crawl the site?

&gt; &gt; &gt; What I see there that's wrong is your robots.txt file shoudl disallow
&gt; &gt; &gt; the gallery since it generates url's with session ids.
&gt; &gt; &gt; I see the broken url's in your robtos.txt fle - that won't solve the
&gt; &gt; &gt; problem long term of broken url's if they are from your navigation.

&gt; &gt; &gt; It seems a crawl is getting bogged down by an explosion of url's from
&gt; &gt; &gt; somewhere, because after it had reached 45% it suddenly dropped to 14%
&gt; &gt; &gt; and it's slowly crept up to 17%  even while more url's are getting
&gt; &gt; &gt; crawled yet the total keeps moving higher - and this is after I
&gt; &gt; &gt; excldued the gallery too.
&gt; &gt; &gt; There's something producing  huge numbers of url's in the factbook
&gt; &gt; &gt; folder.
&gt; &gt; &gt; Whether that's OOK or not I don't knwo as I've not finished scanning.
&gt; &gt; &gt; At this rate it will take very long.

&gt; &gt; &gt; On Aug 17, 11:35 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; I generated a new site map and when I uploaded it Google found 62
e404
&gt; &gt; &gt; &gt; errors, but there are no actual e404 errors on my site.  All of
these
&gt; &gt; &gt; &gt; were caused by errors created by GSC.  The file type was cut off
&gt; &gt; &gt; &gt; like .jpg into .j, html into .ht, etc.  Is there a URL link length
&gt; &gt; &gt; &gt; requirement or is this just a freak error.  I reran GSC and I think
&gt; &gt; &gt; &gt; it's fixed now but I have a bunch of errors on Google.  Here are
some
&gt; &gt; &gt; &gt; examples:

&gt; http://a-ok-site.com/factbook/factbook2000/factbook/flags/al-lgflag.j ......

&gt; &gt; &gt; &gt; Any ideas because it's a real pain to do all of the URL removals on
&gt; &gt; &gt; &gt; Google.

&gt; &gt; &gt; &gt; My site URL= http://a-ok-site.com , site map
files= http://a-ok-site.com/

sitemap.xml http://a-ok-site.com/sitemap.xml.gzhttp://a-ok-site.com/urllist.t
&gt; xt

&gt; &gt; &gt; &gt; Thanks,

&gt; &gt; &gt; &gt; Dan- Hide quoted text -

&gt; &gt; - Show quoted text -- Masquer le texte des messages précédents -

&gt; - Afficher le texte des messages précédents -
">
</POST>
<POST>
<POSTER> a-ok-site &lt;a.ok.s...@gmail.com&gt; </POSTER>
<POSTDATE> 2007-08-17T18:54:00 </POSTDATE>
Just to close the conversation about 2 site maps with an index file.
I uploaded the sitemap_index.xml and google approved it.  The dates
are a little tricky, a little different format.  Later.

On Aug 17, 2:36 pm, webado &lt;web ... @gmail.com&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; As far as I know all you need is to give the url of the index file and
&gt; from it Google will find the 2 sitemaps.

&gt; I've never used a sitemap index myself so I don't know first hand.
&gt; It should be OK.

&gt; Oh the dates might need fixing?

&gt; On 17 août, 13:30, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; Alright, I made the sitmap_index.xml file, but I couldn't find out if
&gt; &gt; I need to list it only in webmaster tools, or do I still least each
&gt; &gt; individual sitemap?

&gt; &gt; &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&gt; &gt;    &lt;sitemapindex xmlns=&quot; http://www.sitemaps.org/schemas/sitemap/0.9 &quot;&gt;
&gt; &gt;    &lt;sitemap&gt;
&gt; &gt;       &lt;loc&gt; http://a-ok-site.com/sitemap.xml.gz &lt;/loc&gt;
&gt; &gt;       &lt;lastmod&gt;2004-10-01T18:23:17+00:00&lt;/lastmod&gt;
&gt; &gt;    &lt;/sitemap&gt;
&gt; &gt;    &lt;sitemap&gt;
&gt; &gt;       &lt;loc&gt; http://a-ok-site.com/sitemap2.xml.gz &lt;/loc&gt;
&gt; &gt;       &lt;lastmod&gt;2005-01-01&lt;/lastmod&gt;
&gt; &gt;    &lt;/sitemap&gt;
&gt; &gt;    &lt;/sitemapindex&gt;

&gt; &gt; On Aug 17, 12:02 pm, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; Oh gosh, thank you so much!

&gt; &gt; &gt; The factbook could perhaps get a crawl by itself.

&gt; &gt; &gt; Let say in GSC you have 2 projects:
&gt; &gt; &gt; 1) http://a-ok-site.com/withaban on the factbook folder (and
&gt; &gt; &gt; gallery)
&gt; &gt; &gt; 2) htt://a-ok-site/factbook/   by itself

&gt; &gt; &gt; You  will get a sitemap from the first project with everythign but
&gt; &gt; &gt; fatcbook url's and a seprate sitemap from the second project with only
&gt; &gt; &gt; factbook urls.
&gt; &gt; &gt; You can submit 2 separate sitemaps  in Webmaster tools for the same
&gt; &gt; &gt; site.

&gt; &gt; &gt; If using the xml sitemaps, then you can also have a sitemap index
&gt; &gt; &gt; listing the 2 separate xml sitemaps. You'll have to make that one
&gt; &gt; &gt; manually according to the protocol described in the help in Webmaster
&gt; &gt; &gt; Tools.

&gt; &gt; &gt; On Aug 17, 12:43 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; Sent gift via paypal, for your trouble.  I just wanted you to know you
&gt; &gt; &gt; &gt; are appreciated.  :-)

&gt; &gt; &gt; &gt; On Aug 17, 11:36 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; Could I ban the factbook urls and do a manual entry.  Could this cause
&gt; &gt; &gt; &gt; &gt; a conflict the next time I crawl?  later.

&gt; &gt; &gt; &gt; &gt; On Aug 17, 11:30 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; Ok I am still crawling, up at 40%. Slow.

&gt; &gt; &gt; &gt; &gt; &gt; Well your factbook is a problem. Based on the url structure it may be
&gt; &gt; &gt; &gt; &gt; &gt; hard or easy to limit to their homepages. But might be good.

&gt; &gt; &gt; &gt; &gt; &gt; On Aug 17, 12:24 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; ooops, Sorry for the double post but I removed all gif, jpg, etc files
&gt; &gt; &gt; &gt; &gt; &gt; &gt; after the errors.  All that I am currently crawling is html, htm, pdf,
&gt; &gt; &gt; &gt; &gt; &gt; &gt; txt, rtf.  Later.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; On Aug 17, 11:13 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; First off jpegs and other images and media files should not be in the
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; sitemap at all. You can exclude them from GSC using the filters.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; The way images get into the Google image indexex is by their being
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; roesent on pages that are being indexed regularly.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Google's errors from the sitemap will disappear after 2-3 weeks.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Google indexes your site from a crawl starting at the root, the
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; sitemap is just a reference. If you have  bad links appearing in the
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; index maybe there's somehtign wrong with your site's navigation and
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; bad links get generated. have you used Xenu to crawl the site?

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; What I see there that's wrong is your robots.txt file shoudl disallow
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; the gallery since it generates url's with session ids.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; I see the broken url's in your robtos.txt fle - that won't solve the
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; problem long term of broken url's if they are from your navigation.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; It seems a crawl is getting bogged down by an explosion of url's from
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; somewhere, because after it had reached 45% it suddenly dropped to 14%
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; and it's slowly crept up to 17%  even while more url's are getting
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; crawled yet the total keeps moving higher - and this is after I
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; excldued the gallery too.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; There's something producing  huge numbers of url's in the factbook
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; folder.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Whether that's OOK or not I don't knwo as I've not finished scanning.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; At this rate it will take very long.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; On Aug 17, 11:35 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; I generated a new site map and when I uploaded it Google found 62 e404
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; errors, but there are no actual e404 errors on my site.  All of these
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; were caused by errors created by GSC.  The file type was cut off
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; like .jpg into .j, html into .ht, etc.  Is there a URL link length
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; requirement or is this just a freak error.  I reran GSC and I think
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; it's fixed now but I have a bunch of errors on Google.  Here are some
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; examples:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; http://a-ok-site.com/factbook/factbook2000/factbook/flags/al-lgflag.j ......

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Any ideas because it's a real pain to do all of the URL removals on
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Google.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; My site URL= http://a-ok-site.com , site map files= http://a-ok-site.com/
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; sitemap.xml http://a-ok-site.com/sitemap.xml.gzhttp://a-ok-site.com/urllist.txt

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Thanks,

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Dan- Hide quoted text -

&gt; &gt; &gt; &gt; &gt; &gt; &gt; - Show quoted text -- Hide quoted text -

&gt; &gt; &gt; &gt; - Show quoted text -- Masquer le texte des messages précédents -

&gt; &gt; - Afficher le texte des messages précédents -
">
</POST>
<POST>
<POSTER> webado &lt;web...@gmail.com&gt; </POSTER>
<POSTDATE> 2007-08-18T02:30:00 </POSTDATE>
Actually I was referring to the actuall dates you'd shown here. They
were a bit ... past their shelf life ;)

You can have the dates as 2007-08-17 , you dont' need the full date
format.

On Aug 17, 6:54 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; Just to close the conversation about 2 site maps with an index file.
&gt; I uploaded the sitemap_index.xml and google approved it.  The dates
&gt; are a little tricky, a little different format.  Later.

&gt; On Aug 17, 2:36 pm, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; As far as I know all you need is to give the url of the index file and
&gt; &gt; from it Google will find the 2 sitemaps.

&gt; &gt; I've never used a sitemap index myself so I don't know first hand.
&gt; &gt; It should be OK.

&gt; &gt; Oh the dates might need fixing?

&gt; &gt; On 17 août, 13:30, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; Alright, I made the sitmap_index.xml file, but I couldn't find out if
&gt; &gt; &gt; I need to list it only in webmaster tools, or do I still least each
&gt; &gt; &gt; individual sitemap?

&gt; &gt; &gt; &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&gt; &gt; &gt;    &lt;sitemapindex xmlns=&quot; http://www.sitemaps.org/schemas/sitemap/0.9 &quot;&gt;
&gt; &gt; &gt;    &lt;sitemap&gt;
&gt; &gt; &gt;       &lt;loc&gt; http://a-ok-site.com/sitemap.xml.gz &lt;/loc&gt;
&gt; &gt; &gt;       &lt;lastmod&gt;2004-10-01T18:23:17+00:00&lt;/lastmod&gt;
&gt; &gt; &gt;    &lt;/sitemap&gt;
&gt; &gt; &gt;    &lt;sitemap&gt;
&gt; &gt; &gt;       &lt;loc&gt; http://a-ok-site.com/sitemap2.xml.gz &lt;/loc&gt;
&gt; &gt; &gt;       &lt;lastmod&gt;2005-01-01&lt;/lastmod&gt;
&gt; &gt; &gt;    &lt;/sitemap&gt;
&gt; &gt; &gt;    &lt;/sitemapindex&gt;

&gt; &gt; &gt; On Aug 17, 12:02 pm, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; Oh gosh, thank you so much!

&gt; &gt; &gt; &gt; The factbook could perhaps get a crawl by itself.

&gt; &gt; &gt; &gt; Let say in GSC you have 2 projects:
&gt; &gt; &gt; &gt; 1) http://a-ok-site.com/withabanon the factbook folder (and
&gt; &gt; &gt; &gt; gallery)
&gt; &gt; &gt; &gt; 2) htt://a-ok-site/factbook/   by itself

&gt; &gt; &gt; &gt; You  will get a sitemap from the first project with everythign but
&gt; &gt; &gt; &gt; fatcbook url's and a seprate sitemap from the second project with only
&gt; &gt; &gt; &gt; factbook urls.
&gt; &gt; &gt; &gt; You can submit 2 separate sitemaps  in Webmaster tools for the same
&gt; &gt; &gt; &gt; site.

&gt; &gt; &gt; &gt; If using the xml sitemaps, then you can also have a sitemap index
&gt; &gt; &gt; &gt; listing the 2 separate xml sitemaps. You'll have to make that one
&gt; &gt; &gt; &gt; manually according to the protocol described in the help in Webmaster
&gt; &gt; &gt; &gt; Tools.

&gt; &gt; &gt; &gt; On Aug 17, 12:43 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; Sent gift via paypal, for your trouble.  I just wanted you to know you
&gt; &gt; &gt; &gt; &gt; are appreciated.  :-)

&gt; &gt; &gt; &gt; &gt; On Aug 17, 11:36 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; Could I ban the factbook urls and do a manual entry.  Could this cause
&gt; &gt; &gt; &gt; &gt; &gt; a conflict the next time I crawl?  later.

&gt; &gt; &gt; &gt; &gt; &gt; On Aug 17, 11:30 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; Ok I am still crawling, up at 40%. Slow.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; Well your factbook is a problem. Based on the url structure it may be
&gt; &gt; &gt; &gt; &gt; &gt; &gt; hard or easy to limit to their homepages. But might be good.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; On Aug 17, 12:24 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; ooops, Sorry for the double post but I removed all gif, jpg, etc files
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; after the errors.  All that I am currently crawling is html, htm, pdf,
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; txt, rtf.  Later.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; On Aug 17, 11:13 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; First off jpegs and other images and media files should not be in the
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; sitemap at all. You can exclude them from GSC using the filters.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; The way images get into the Google image indexex is by their being
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; roesent on pages that are being indexed regularly.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Google's errors from the sitemap will disappear after 2-3 weeks.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Google indexes your site from a crawl starting at the root, the
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; sitemap is just a reference. If you have  bad links appearing in the
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; index maybe there's somehtign wrong with your site's navigation and
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; bad links get generated. have you used Xenu to crawl the site?

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; What I see there that's wrong is your robots.txt file shoudl disallow
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; the gallery since it generates url's with session ids.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; I see the broken url's in your robtos.txt fle - that won't solve the
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; problem long term of broken url's if they are from your navigation.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; It seems a crawl is getting bogged down by an explosion of url's from
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; somewhere, because after it had reached 45% it suddenly dropped to 14%
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; and it's slowly crept up to 17%  even while more url's are getting
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; crawled yet the total keeps moving higher - and this is after I
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; excldued the gallery too.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; There's something producing  huge numbers of url's in the factbook
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; folder.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Whether that's OOK or not I don't knwo as I've not finished scanning.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; At this rate it will take very long.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; On Aug 17, 11:35 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; I generated a new site map and when I uploaded it Google found 62 e404
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; errors, but there are no actual e404 errors on my site.  All of these
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; were caused by errors created by GSC.  The file type was cut off
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; like .jpg into .j, html into .ht, etc.  Is there a URL link length
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; requirement or is this just a freak error.  I reran GSC and I think
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; it's fixed now but I have a bunch of errors on Google.  Here are some
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; examples:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; http://a-ok-site.com/factbook/factbook2000/factbook/flags/al-lgflag.j ......

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Any ideas because it's a real pain to do all of the URL removals on
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Google.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; My site URL= http://a-ok-site.com , site map files= http://a-ok-site.com/
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; sitemap.xml http://a-ok-site.com/sitemap.xml.gzhttp://a-ok-site.com/urllist.txt

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Thanks,

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Dan- Hide quoted text -

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; - Show quoted text -- Hide quoted text -

&gt; &gt; &gt; &gt; &gt; - Show quoted text -- Masquer le texte des messages précédents -

&gt; &gt; &gt; - Afficher le texte des messages précédents -- Hide quoted text -

&gt; - Show quoted text -
">
</POST>
<POST>
<POSTER> a-ok-site &lt;a.ok.s...@gmail.com&gt; </POSTER>
<POSTDATE> 2007-08-18T12:58:00 </POSTDATE>
LOL, I know but when I tried to change them I had to figure out the
different format.  There is another little problem I need to work on.
Google didn't like the links back to the first sitemap in the second.
Still approved but had warnings.  This project will have to wait until
I have time to figure out how not to include back links in second site
map.  Later.

On Aug 18, 1:30 am, webado &lt;web ... @gmail.com&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; Actually I was referring to the actuall dates you'd shown here. They
&gt; were a bit ... past their shelf life ;)

&gt; You can have the dates as 2007-08-17 , you dont' need the full date
&gt; format.

&gt; On Aug 17, 6:54 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; Just to close the conversation about 2 site maps with an index file.
&gt; &gt; I uploaded the sitemap_index.xml and google approved it.  The dates
&gt; &gt; are a little tricky, a little different format.  Later.

&gt; &gt; On Aug 17, 2:36 pm, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; As far as I know all you need is to give the url of the index file and
&gt; &gt; &gt; from it Google will find the 2 sitemaps.

&gt; &gt; &gt; I've never used a sitemap index myself so I don't know first hand.
&gt; &gt; &gt; It should be OK.

&gt; &gt; &gt; Oh the dates might need fixing?

&gt; &gt; &gt; On 17 août, 13:30, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; Alright, I made the sitmap_index.xml file, but I couldn't find out if
&gt; &gt; &gt; &gt; I need to list it only in webmaster tools, or do I still least each
&gt; &gt; &gt; &gt; individual sitemap?

&gt; &gt; &gt; &gt; &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&gt; &gt; &gt; &gt;    &lt;sitemapindex xmlns=&quot; http://www.sitemaps.org/schemas/sitemap/0.9 &quot;&gt;
&gt; &gt; &gt; &gt;    &lt;sitemap&gt;
&gt; &gt; &gt; &gt;       &lt;loc&gt; http://a-ok-site.com/sitemap.xml.gz &lt;/loc&gt;
&gt; &gt; &gt; &gt;       &lt;lastmod&gt;2004-10-01T18:23:17+00:00&lt;/lastmod&gt;
&gt; &gt; &gt; &gt;    &lt;/sitemap&gt;
&gt; &gt; &gt; &gt;    &lt;sitemap&gt;
&gt; &gt; &gt; &gt;       &lt;loc&gt; http://a-ok-site.com/sitemap2.xml.gz &lt;/loc&gt;
&gt; &gt; &gt; &gt;       &lt;lastmod&gt;2005-01-01&lt;/lastmod&gt;
&gt; &gt; &gt; &gt;    &lt;/sitemap&gt;
&gt; &gt; &gt; &gt;    &lt;/sitemapindex&gt;

&gt; &gt; &gt; &gt; On Aug 17, 12:02 pm, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; Oh gosh, thank you so much!

&gt; &gt; &gt; &gt; &gt; The factbook could perhaps get a crawl by itself.

&gt; &gt; &gt; &gt; &gt; Let say in GSC you have 2 projects:
&gt; &gt; &gt; &gt; &gt; 1) http://a-ok-site.com/withabanonthe factbook folder (and
&gt; &gt; &gt; &gt; &gt; gallery)
&gt; &gt; &gt; &gt; &gt; 2) htt://a-ok-site/factbook/   by itself

&gt; &gt; &gt; &gt; &gt; You  will get a sitemap from the first project with everythign but
&gt; &gt; &gt; &gt; &gt; fatcbook url's and a seprate sitemap from the second project with only
&gt; &gt; &gt; &gt; &gt; factbook urls.
&gt; &gt; &gt; &gt; &gt; You can submit 2 separate sitemaps  in Webmaster tools for the same
&gt; &gt; &gt; &gt; &gt; site.

&gt; &gt; &gt; &gt; &gt; If using the xml sitemaps, then you can also have a sitemap index
&gt; &gt; &gt; &gt; &gt; listing the 2 separate xml sitemaps. You'll have to make that one
&gt; &gt; &gt; &gt; &gt; manually according to the protocol described in the help in Webmaster
&gt; &gt; &gt; &gt; &gt; Tools.

&gt; &gt; &gt; &gt; &gt; On Aug 17, 12:43 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; Sent gift via paypal, for your trouble.  I just wanted you to know you
&gt; &gt; &gt; &gt; &gt; &gt; are appreciated.  :-)

&gt; &gt; &gt; &gt; &gt; &gt; On Aug 17, 11:36 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; Could I ban the factbook urls and do a manual entry.  Could this cause
&gt; &gt; &gt; &gt; &gt; &gt; &gt; a conflict the next time I crawl?  later.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; On Aug 17, 11:30 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Ok I am still crawling, up at 40%. Slow.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Well your factbook is a problem. Based on the url structure it may be
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; hard or easy to limit to their homepages. But might be good.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; On Aug 17, 12:24 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; ooops, Sorry for the double post but I removed all gif, jpg, etc files
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; after the errors.  All that I am currently crawling is html, htm, pdf,
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; txt, rtf.  Later.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; On Aug 17, 11:13 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; First off jpegs and other images and media files should not be in the
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; sitemap at all. You can exclude them from GSC using the filters.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; The way images get into the Google image indexex is by their being
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; roesent on pages that are being indexed regularly.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Google's errors from the sitemap will disappear after 2-3 weeks.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Google indexes your site from a crawl starting at the root, the
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; sitemap is just a reference. If you have  bad links appearing in the
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; index maybe there's somehtign wrong with your site's navigation and
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; bad links get generated. have you used Xenu to crawl the site?

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; What I see there that's wrong is your robots.txt file shoudl disallow
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; the gallery since it generates url's with session ids.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; I see the broken url's in your robtos.txt fle - that won't solve the
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; problem long term of broken url's if they are from your navigation.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; It seems a crawl is getting bogged down by an explosion of url's from
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; somewhere, because after it had reached 45% it suddenly dropped to 14%
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; and it's slowly crept up to 17%  even while more url's are getting
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; crawled yet the total keeps moving higher - and this is after I
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; excldued the gallery too.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; There's something producing  huge numbers of url's in the factbook
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; folder.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Whether that's OOK or not I don't knwo as I've not finished scanning.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; At this rate it will take very long.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; On Aug 17, 11:35 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; I generated a new site map and when I uploaded it Google found 62 e404
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; errors, but there are no actual e404 errors on my site.  All of these
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; were caused by errors created by GSC.  The file type was cut off
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; like .jpg into .j, html into .ht, etc.  Is there a URL link length
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; requirement or is this just a freak error.  I reran GSC and I think
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; it's fixed now but I have a bunch of errors on Google.  Here are some
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; examples:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; http://a-ok-site.com/factbook/factbook2000/factbook/flags/al-lgflag.j ......

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Any ideas because it's a real pain to do all of the URL removals on
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Google.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; My site URL= http://a-ok-site.com , site map files= http://a-ok-site.com/
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; sitemap.xml http://a-ok-site.com/sitemap.xml.gzhttp://a-ok-site.com/urllist.txt

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Thanks,

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Dan- Hide quoted text -

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; - Show quoted text -- Hide quoted text -

&gt; &gt; &gt; &gt; &gt; &gt; - Show quoted text -- Masquer le texte des messages précédents -

&gt; &gt; &gt; &gt; - Afficher le texte des messages précédents -- Hide quoted text -

&gt; &gt; - Show quoted text -
">
</POST>
<POST>
<POSTER> webado &lt;web...@gmail.com&gt; </POSTER>
<POSTDATE> 2007-08-18T17:48:00 </POSTDATE>
You don't have to use the full date format.
Just something like 2007-08-18 is enough.

On Aug 18, 12:58 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; LOL, I know but when I tried to change them I had to figure out the
&gt; different format.  There is another little problem I need to work on.
&gt; Google didn't like the links back to the first sitemap in the second.
&gt; Still approved but had warnings.  This project will have to wait until
&gt; I have time to figure out how not to include back links in second site
&gt; map.  Later.

&gt; On Aug 18, 1:30 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; Actually I was referring to the actuall dates you'd shown here. They
&gt; &gt; were a bit ... past their shelf life ;)

&gt; &gt; You can have the dates as 2007-08-17 , you dont' need the full date
&gt; &gt; format.

&gt; &gt; On Aug 17, 6:54 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; Just to close the conversation about 2 site maps with an index file.
&gt; &gt; &gt; I uploaded the sitemap_index.xml and google approved it.  The dates
&gt; &gt; &gt; are a little tricky, a little different format.  Later.

&gt; &gt; &gt; On Aug 17, 2:36 pm, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; As far as I know all you need is to give the url of the index file and
&gt; &gt; &gt; &gt; from it Google will find the 2 sitemaps.

&gt; &gt; &gt; &gt; I've never used a sitemap index myself so I don't know first hand.
&gt; &gt; &gt; &gt; It should be OK.

&gt; &gt; &gt; &gt; Oh the dates might need fixing?

&gt; &gt; &gt; &gt; On 17 août, 13:30, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; Alright, I made the sitmap_index.xml file, but I couldn't find out if
&gt; &gt; &gt; &gt; &gt; I need to list it only in webmaster tools, or do I still least each
&gt; &gt; &gt; &gt; &gt; individual sitemap?

&gt; &gt; &gt; &gt; &gt; &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&gt; &gt; &gt; &gt; &gt;    &lt;sitemapindex xmlns=&quot; http://www.sitemaps.org/schemas/sitemap/0.9 &quot;&gt;
&gt; &gt; &gt; &gt; &gt;    &lt;sitemap&gt;
&gt; &gt; &gt; &gt; &gt;       &lt;loc&gt; http://a-ok-site.com/sitemap.xml.gz &lt;/loc&gt;
&gt; &gt; &gt; &gt; &gt;       &lt;lastmod&gt;2004-10-01T18:23:17+00:00&lt;/lastmod&gt;
&gt; &gt; &gt; &gt; &gt;    &lt;/sitemap&gt;
&gt; &gt; &gt; &gt; &gt;    &lt;sitemap&gt;
&gt; &gt; &gt; &gt; &gt;       &lt;loc&gt; http://a-ok-site.com/sitemap2.xml.gz &lt;/loc&gt;
&gt; &gt; &gt; &gt; &gt;       &lt;lastmod&gt;2005-01-01&lt;/lastmod&gt;
&gt; &gt; &gt; &gt; &gt;    &lt;/sitemap&gt;
&gt; &gt; &gt; &gt; &gt;    &lt;/sitemapindex&gt;

&gt; &gt; &gt; &gt; &gt; On Aug 17, 12:02 pm, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; Oh gosh, thank you so much!

&gt; &gt; &gt; &gt; &gt; &gt; The factbook could perhaps get a crawl by itself.

&gt; &gt; &gt; &gt; &gt; &gt; Let say in GSC you have 2 projects:
&gt; &gt; &gt; &gt; &gt; &gt; 1) http://a-ok-site.com/withabanonthefactbook folder (and
&gt; &gt; &gt; &gt; &gt; &gt; gallery)
&gt; &gt; &gt; &gt; &gt; &gt; 2) htt://a-ok-site/factbook/   by itself

&gt; &gt; &gt; &gt; &gt; &gt; You  will get a sitemap from the first project with everythign but
&gt; &gt; &gt; &gt; &gt; &gt; fatcbook url's and a seprate sitemap from the second project with only
&gt; &gt; &gt; &gt; &gt; &gt; factbook urls.
&gt; &gt; &gt; &gt; &gt; &gt; You can submit 2 separate sitemaps  in Webmaster tools for the same
&gt; &gt; &gt; &gt; &gt; &gt; site.

&gt; &gt; &gt; &gt; &gt; &gt; If using the xml sitemaps, then you can also have a sitemap index
&gt; &gt; &gt; &gt; &gt; &gt; listing the 2 separate xml sitemaps. You'll have to make that one
&gt; &gt; &gt; &gt; &gt; &gt; manually according to the protocol described in the help in Webmaster
&gt; &gt; &gt; &gt; &gt; &gt; Tools.

&gt; &gt; &gt; &gt; &gt; &gt; On Aug 17, 12:43 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; Sent gift via paypal, for your trouble.  I just wanted you to know you
&gt; &gt; &gt; &gt; &gt; &gt; &gt; are appreciated.  :-)

&gt; &gt; &gt; &gt; &gt; &gt; &gt; On Aug 17, 11:36 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Could I ban the factbook urls and do a manual entry.  Could this cause
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; a conflict the next time I crawl?  later.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; On Aug 17, 11:30 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Ok I am still crawling, up at 40%. Slow.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Well your factbook is a problem. Based on the url structure it may be
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; hard or easy to limit to their homepages. But might be good.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; On Aug 17, 12:24 pm, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; ooops, Sorry for the double post but I removed all gif, jpg, etc files
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; after the errors.  All that I am currently crawling is html, htm, pdf,
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; txt, rtf.  Later.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; On Aug 17, 11:13 am, webado &lt;web ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; First off jpegs and other images and media files should not be in the
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; sitemap at all. You can exclude them from GSC using the filters.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; The way images get into the Google image indexex is by their being
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; roesent on pages that are being indexed regularly.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Google's errors from the sitemap will disappear after 2-3 weeks.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Google indexes your site from a crawl starting at the root, the
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; sitemap is just a reference. If you have  bad links appearing in the
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; index maybe there's somehtign wrong with your site's navigation and
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; bad links get generated. have you used Xenu to crawl the site?

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; What I see there that's wrong is your robots.txt file shoudl disallow
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; the gallery since it generates url's with session ids.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; I see the broken url's in your robtos.txt fle - that won't solve the
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; problem long term of broken url's if they are from your navigation.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; It seems a crawl is getting bogged down by an explosion of url's from
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; somewhere, because after it had reached 45% it suddenly dropped to 14%
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; and it's slowly crept up to 17%  even while more url's are getting
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; crawled yet the total keeps moving higher - and this is after I
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; excldued the gallery too.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; There's something producing  huge numbers of url's in the factbook
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; folder.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Whether that's OOK or not I don't knwo as I've not finished scanning.
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; At this rate it will take very long.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; On Aug 17, 11:35 am, a-ok-site &lt;a.ok.s ... @gmail.com&gt; wrote:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; I generated a new site map and when I uploaded it Google found 62 e404
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; errors, but there are no actual e404 errors on my site.  All of these
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; were caused by errors created by GSC.  The file type was cut off
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; like .jpg into .j, html into .ht, etc.  Is there a URL link length
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; requirement or is this just a freak error.  I reran GSC and I think
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; it's fixed now but I have a bunch of errors on Google.  Here are some
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; examples:

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; http://a-ok-site.com/factbook/factbook2000/factbook/flags/al-lgflag.j ......

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Any ideas because it's a real pain to do all of the URL removals on
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Google.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; My site URL= http://a-ok-site.com , site map files= http://a-ok-site.com/
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; sitemap.xml http://a-ok-site.com/sitemap.xml.gzhttp://a-ok-site.com/urllist.txt

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Thanks,

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; Dan- Hide quoted text -

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; - Show quoted text -- Hide quoted text -

&gt; &gt; &gt; &gt; &gt; &gt; &gt; - Show quoted text -- Masquer le texte des messages précédents -

&gt; &gt; &gt; &gt; &gt; - Afficher le texte des messages précédents -- Hide quoted text -

&gt; &gt; &gt; - Show quoted text -- Hide quoted text -

&gt; - Show quoted text -
">
</POST>
<POST>
<POSTER> &quot;Darla Atkison&quot; &lt;darl...@suddenlink.net&gt; </POSTER>
<POSTDATE> 2007-08-18T22:59:00 </POSTDATE>
Hi,

My question is, do you have to update your sitemap if you make no changes on
your website, and if yes, how often do you suggest?

Thank you Webado!
</POST>
<POST>
<POSTER> webado &lt;web...@gmail.com&gt; </POSTER>
<POSTDATE> 2007-08-18T23:45:00 </POSTDATE>
No, if no changes to the website have been made, then no changes to
the sitemap are needed either. You can resubmit the sitemap
periodically but it likely won't make any difference. Goglebot checks
it periodiclaly even if you don't submit it.

If you see all your pages in a site: query then it's as good as you
can hope. All other things (maning ranking for specific terms) require
changing the website's strcture and content to improve its
optimization and of course getting more and better backlinks.

On Aug 18, 10:59 pm, &quot;Darla Atkison&quot; &lt;darl ... @suddenlink.net&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; Hi,

&gt; My question is, do you have to update your sitemap if you make no changes on
&gt; your website, and if yes, how often do you suggest?

&gt; Thank you Webado!
">
</POST>
</TEXT>
</BODY>
</DOC>
