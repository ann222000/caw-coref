<DOC>
<DOCID> eng-NG-31-107895-6430799 </DOCID>
<DOCTYPE SOURCE="usenet"> USENET TEXT </DOCTYPE>
<DATETIME> 2007-03-28T18:24:00 </DATETIME>
<BODY>
<HEADLINE>
New psudo ABX ?
</HEADLINE>
<TEXT>
<POST>
<POSTER> William Eckle &lt;a...@wmeckle.com&gt; </POSTER>
<POSTDATE> 2007-03-28T18:24:00 </POSTDATE>
The classic abx listening test is a chore to setup and perform.  Its
clear strength is the ability to determine if a difference, any
difference, can be shown to exist by listening alone in a
scientifically valid way. Substitute some element for another which
is thought to possibly make an audible difference and if no
difference can be heard then the claim of amp or wire etc.
differences are moot and any subjective claims highly questionable.

Here is a new way to perform the same kind of test with greatly
simplified methods that create the context where a possible
difference can be shown to exist by listening alone and also
scientifically valid.

http://theaudiocritic.com/blog/index.php?op=ViewArticle&amp;articleId=35&amp;...

Don't miss the link at the end of this short article that describes
the software and methods used.

-=Bill Eckle=-
a ... @wmeckle.com
Vanity Web Page at:
http://www.wmeckle.com
</POST>
<POST>
<POSTER> "Harry Lavo" &lt;h...@hotmail.com&gt; </POSTER>
<POSTDATE> 2007-03-28T23:21:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;William Eckle&quot; &lt;a ... @wmeckle.com&gt; wrote in message
">

news:epadnWEps7qydpfbnZ2dnUVZ_sWdnZ2d@pghconnect.com ...

<QUOTE PREVIOUSPOST="
&gt; The classic abx listening test is a chore to setup and perform.  Its
&gt; clear strength is the ability to determine if a difference, any
&gt; difference, can be shown to exist by listening alone in a
&gt; scientifically valid way. Substitute some element for another which
&gt; is thought to possibly make an audible difference and if no
&gt; difference can be heard then the claim of amp or wire etc.
&gt; differences are moot and any subjective claims highly questionable.
">

Unfortunately, this is not true.  The researchers at Harman Kardon have
found that over 40% of people, even with careful training, cannot reliably
distinquish even known differences in their training, and have to be dropped
from any testing.  The test is as much a test of the listener as it is of
the items under test.  Moreover, both ABX and ABC/hr were developed and
optimized specifically for codec testing, where easily identifiable
distortions can be used at various levels of impact to "train" listeners,
who then listen to the blind samples but "knowing" what they are listening
for.

Open-end evaluation of audio gear does not work this way.  The human brain
tries to relate the sound to a real sound, and doesn't even know "what" to
listen for...timbre, soundspace, subtles distortions, etc.  That seems to be
why the result of open-ended listening via ABX results in almost immediate
listening fatique...it is a total unnatural use of the technique for this
purpose.  Put simply it violates the first cardinal principal of test
design...that is to prevent any aspect of the test from intervening as a
variable.

ABX can be used for crude audio measures....volume, frequency shifts in
white noise, etc.  As soon as it comes to listening to music, sensitivity
decreases or disappears.  This isn't just speculation....review the
Greenhill tests in Stereo Review (search index at their site).

<QUOTE PREVIOUSPOST="
&gt; Here is a new way to perform the same kind of test with greatly
&gt; simplified methods that create the context where a possible
&gt; difference can be shown to exist by listening alone and also
&gt; scientifically valid.

&gt; http://theaudiocritic.com/blog/index.php?op=ViewArticle&amp;articleId=35&amp;...

&gt; Don't miss the link at the end of this short article that describes
&gt; the software and methods used.
">

I think others will argue that it is likely you will be able to meausure
some difference, but you won't be able to hear it.  And others will claim
they can hear it.  Perhaps an ABX test under this circumstance with some
training might be of some value.  But to do all this in a well controlled
test is, again, a research project and not an amateur, home-oriented test.
</POST>
<POST>
<POSTER> Steven Sullivan &lt;ssu...@panix.com&gt; </POSTER>
<POSTDATE> 2007-03-29T16:44:00 </POSTDATE>
It's certainly not a new method, but it's nice to have new software that
automates the process.

___
-S
"As human beings, we understand the world through simile, analogy,
metaphor, narrative and, sometimes, claymation." - B. Mason
</POST>
<POST>
<POSTER> "bob" &lt;nabo...@hotmail.com&gt; </POSTER>
<POSTDATE> 2007-03-29T16:45:00 </POSTDATE>
On Mar 28, 11:21 pm, "Harry Lavo" &lt;h ... @hotmail.com&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; Unfortunately, this is not true.  The researchers at Harman Kardon have
&gt; found that over 40% of people, even with careful training, cannot reliably
&gt; distinquish even known differences in their training, and have to be dropped
&gt; from any testing.
">

This is false. Harmon wasn't even training people to "distinguish
differences." All of its subjects could *distinguish* the differences;
what they couldn't do was correlate those differences to specific
variations in frequency response. That is a much harder task, which is
why the failure rate, even after training, was so high. Anyone who's
read Sean Olive's work would understand this (assuming they wanted to
understand it).

<QUOTE PREVIOUSPOST="
&gt; The test is as much a test of the listener as it is of
&gt; the items under test.  Moreover, both ABX and ABC/hr were developed and
&gt; optimized specifically for codec testing,
">

This is also false.

<QUOTE PREVIOUSPOST="
&gt; where easily identifiable
&gt; distortions can be used at various levels of impact to &quot;train&quot; listeners,
&gt; who then listen to the blind samples but &quot;knowing&quot; what they are listening
&gt; for.

&gt; Open-end evaluation of audio gear does not work this way.  The human brain
&gt; tries to relate the sound to a real sound, and doesn't even know &quot;what&quot; to
&gt; listen for...timbre, soundspace, subtles distortions, etc.  That seems to be
&gt; why the result of open-ended listening via ABX results in almost immediate
&gt; listening fatique...it is a total unnatural use of the technique for this
&gt; purpose.
">

This is idle speculation by someone who knows nothing about the
subject he's talking about. There isn't a shred of real evidence for
any of it. It's pseudoscience.

<QUOTE PREVIOUSPOST="
&gt;  Put simply it violates the first cardinal principal of test
&gt; design...that is to prevent any aspect of the test from intervening as a
&gt; variable.
">

Again, you haven't a shred of evidence that ABX or ABC/hr tests
interfere with perception in any way.

<QUOTE PREVIOUSPOST="
&gt; ABX can be used for crude audio measures....volume, frequency shifts in
&gt; white noise, etc.  As soon as it comes to listening to music, sensitivity
&gt; decreases or disappears.
">

It is certainly true that it is easier to hear differences in level
and FR using test tones than using music. This has nothing to do with
any particular test. It has to do with the way the human hearing
mechanism works, and it is true no matter what listening method you
use.

<QUOTE PREVIOUSPOST="
&gt; This isn't just speculation....review the
&gt; Greenhill tests in Stereo Review (search index at their site).
">

Where you won't find it. But if anyone wants to read what Greenhill
actually found (rather than someone's re-invention of it), e-mail me
and I can send you the article.

Harry is peddling pure pseudoscience here.

bob
</POST>
<POST>
<POSTER> Steven Sullivan &lt;ssu...@panix.com&gt; </POSTER>
<POSTDATE> 2007-03-29T16:46:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
Harry Lavo &lt;h ... @hotmail.com&gt; wrote:
&gt; &quot;William Eckle&quot; &lt;a ... @wmeckle.com&gt; wrote in message
&gt; news:epadnWEps7qydpfbnZ2dnUVZ_sWdnZ2d@pghconnect.com ...
&gt; &gt; The classic abx listening test is a chore to setup and perform.  Its
&gt; &gt; clear strength is the ability to determine if a difference, any
&gt; &gt; difference, can be shown to exist by listening alone in a
&gt; &gt; scientifically valid way. Substitute some element for another which
&gt; &gt; is thought to possibly make an audible difference and if no
&gt; &gt; difference can be heard then the claim of amp or wire etc.
&gt; &gt; differences are moot and any subjective claims highly questionable.
&gt; Unfortunately, this is not true.  The researchers at Harman Kardon have
&gt; found that over 40% of people, even with careful training, cannot reliably
&gt; distinquish even known differences in their training, and have to be dropped
&gt; from any testing.  The test is as much a test of the listener as it is of
&gt; the items under test.  Moreover, both ABX and ABC/hr were developed and
&gt; optimized specifically for codec testing, where easily identifiable
&gt; distortions can be used at various levels of impact to &quot;train&quot; listeners,
&gt; who then listen to the blind samples but &quot;knowing&quot; what they are listening
&gt; for.
&gt; Open-end evaluation of audio gear does not work this way.  The human brain
&gt; tries to relate the sound to a real sound, and doesn't even know &quot;what&quot; to
&gt; listen for...timbre, soundspace, subtles distortions, etc.  That seems to be
&gt; why the result of open-ended listening via ABX results in almost immediate
&gt; listening fatique...it is a total unnatural use of the technique for this
&gt; purpose.  Put simply it violates the first cardinal principal of test
&gt; design...that is to prevent any aspect of the test from intervening as a
&gt; variable.
">

....and then,once these 'differences' have been 'heard' to the
listener's satisfaction, it's time to see if they're real...via a
blind comparison.  You just can't get around that.

<QUOTE PREVIOUSPOST="
&gt; ABX can be used for crude audio measures....volume, frequency shifts in
&gt; white noise, etc.  As soon as it comes to listening to music, sensitivity
&gt; decreases or disappears.  This isn't just speculation....review the
&gt; Greenhill tests in Stereo Review (search index at their site).
">

Nonsense, Harry.  ABX has been used to detect the difference between .wav source and 320 kbps
mp3s -- which are *extremely* difficult to tell apart. Sensitivity is certainly reduced for
comparisons (sighted or blind) when music is used RATHER THAN TEST TONES. This is not a
function of sighted versus blind, and the Greenhill tests do not say otherwise.

<QUOTE PREVIOUSPOST="
&gt; &gt; Here is a new way to perform the same kind of test with greatly
&gt; &gt; simplified methods that create the context where a possible
&gt; &gt; difference can be shown to exist by listening alone and also
&gt; &gt; scientifically valid.

&gt; &gt; http://theaudiocritic.com/blog/index.php?op=ViewArticle&amp;articleId=35&amp;...

&gt; &gt; Don't miss the link at the end of this short article that describes
&gt; &gt; the software and methods used.

&gt; I think others will argue that it is likely you will be able to meausure
&gt; some difference, but you won't be able to hear it.  And others will claim
&gt; they can hear it.  Perhaps an ABX test under this circumstance with some
&gt; training might be of some value.  But to do all this in a well controlled
&gt; test is, again, a research project and not an amateur, home-oriented test.
">

The main value of a difference test is where it produces a null (and by null,
it must mean residual levels below the practical or theoretical limits of human
hearing).  There, subjectivists would have to invoke some new sort of audible effect,
akin to homeopathy, where vanishingly small amounts of 'medicine' are said to
effect cures.  I wouldn't put it past them.

___
-S
"As human beings, we understand the world through simile, analogy,
metaphor, narrative and, sometimes, claymation." - B. Mason
</POST>
<POST>
<POSTER> "Arny Krueger" &lt;a...@hotpop.com&gt; </POSTER>
<POSTDATE> 2007-03-29T16:50:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;Harry Lavo&quot; &lt;h ... @hotmail.com&gt; wrote in message
">

news:eufbat0jo7@news1.newsguy.com

<QUOTE PREVIOUSPOST="
&gt; &quot;William Eckle&quot; &lt;a ... @wmeckle.com&gt; wrote in message
&gt; news:epadnWEps7qydpfbnZ2dnUVZ_sWdnZ2d@pghconnect.com ...
&gt;&gt; The classic abx listening test is a chore to setup and
&gt;&gt; perform.
">

Depends.  PCABX is an exact test for many kinds of listening tests that
people are interested in today, and a useful approximation for a wide
variety of tests.  It's easier than going to a store and doing a careful job
of comparing components using one of the house's systems.

<QUOTE PREVIOUSPOST="
&gt;&gt;  Its clear strength is the ability to determine
&gt;&gt; if a difference, any difference, can be shown to exist
&gt;&gt; by listening alone in a scientifically valid way.
">

There ain't no such thing. The world is full of differences that are
measurable but not audible at all. So, one caveat is that the difference has
to be audible, and not all differences are audible. Secondly, the audibility
of many differences are contingent on a wide variety of influences, two of
the stronger ones being  the sensitivity of the listener, and some
properties of the music being used for the comparison that may be
non-obvioius.

<QUOTE PREVIOUSPOST="
&gt;&gt; Substitute some element for another which is thought to
&gt;&gt; possibly make an audible difference and if no difference
&gt;&gt; can be heard then the claim of amp or wire etc.
&gt;&gt; differences are moot and any subjective claims highly
&gt;&gt; questionable.
">

Or, you picked the wrong music or associated components. Or, the listener's
sensitivity was atypically poor for any number of different reasons.

<QUOTE PREVIOUSPOST="
&gt; Unfortunately, this is not true.
">

So far so good.

<QUOTE PREVIOUSPOST="
&gt;  The researchers at
&gt; Harman Kardon have found that over 40% of people, even
&gt; with careful training, cannot reliably distinquish even
&gt; known differences in their training, and have to be
&gt; dropped from any testing.
">

Ironically, these same listeners would no doubt report a plethora of audible
differences in a sighted evaluation. ;-)

<QUOTE PREVIOUSPOST="
&gt;  The test is as much a test of
&gt; the listener as it is of the items under test.
">

Name a subjective test methodology where this *isn't* true.  Some people
like to play a silly game where they assert that a certain general problem
that afflicts just about any test is a problem of just their least favorite
kind of listening evaluation.

<QUOTE PREVIOUSPOST="
&gt; Moreover,
&gt; both ABX and ABC/hr were developed and optimized
&gt; specifically for codec testing,
">

Simply not true of ABX, since ABX was developed and popularized before the
audio world even knew what a codec in the modern sense was.

<QUOTE PREVIOUSPOST="
&gt;  where easily identifiable
&gt; distortions can be used at various levels of impact to
&gt; &quot;train&quot; listeners,
">

Surely true for more than just codecs, so this is also a false claim.

<QUOTE PREVIOUSPOST="
&gt;  who then listen to the blind samples
&gt; but &quot;knowing&quot; what they are listening for.
">

Which opens yet another general problem with subjective tests. Differences
are very often easier to detect if you know what to listen for, so how do
you know what to listen for until someone has first actually heard it?

<QUOTE PREVIOUSPOST="
&gt; Open-end evaluation of audio gear does not work this way.
">

Actually, open-end evaluation doesn't work at all. It is open-ended all
right - it contains poor-to-non-existent safeguards against false positives.

<QUOTE PREVIOUSPOST="
&gt; The human brain tries to relate the sound to a real
&gt; sound, and doesn't even know &quot;what&quot; to listen
&gt; for...timbre, soundspace, subtles distortions, etc.
">

A truism that all by itself can't support any particular viewpoint.

<QUOTE PREVIOUSPOST="
&gt; That
&gt; seems to be why the result of open-ended listening via
&gt; ABX results in almost immediate listening fatique...it is
&gt; a total unnatural use of the technique for this purpose.
">

Fact is that lots of people report fatigue while listening by *any* means
that efficiently rejects false positives. The reason is pretty obvious, most
of their former experiences were all about false positives. Take those away
and they suddenly have to produce more than fond wishes that they heard a
difference.

<QUOTE PREVIOUSPOST="
&gt; Put simply it violates the first cardinal principal of
&gt; test design...that is to prevent any aspect of the test
&gt; from intervening as a variable.
">

There ain't no such rule.

<QUOTE PREVIOUSPOST="
&gt; ABX can be used for crude audio measures....volume,
&gt; frequency shifts in white noise, etc.
">

This is one of those statements that immediatly raises a red flag. Broadband
white noise, being an unweighted varying and random combination of all
frequencies, is very much immune audible effects due to frequency shifts.
Theresfore it is a nonsense statement because it is contingent on something
that doesn't ever happen.

<QUOTE PREVIOUSPOST="
&gt;  As soon as it
&gt; comes to listening to music, sensitivity decreases or
&gt; disappears.
">

Name a subjective test methodology where this *isn't* true.

<QUOTE PREVIOUSPOST="
&gt;  This isn't just speculation
">

No, its mostly false and mistleading claims, that shouldn't even qualify as
reasonable speculation.

<QUOTE PREVIOUSPOST="
&gt; ....review the
&gt; Greenhill tests in Stereo Review (search index at their
&gt; site).
">

Greenhill was an advocate of ABX at the time those tests were written and
published. I spoke with him personally for hours in those days.

<QUOTE PREVIOUSPOST="
&gt;&gt; Here is a new way to perform the same kind of test with
&gt;&gt; greatly simplified methods that create the context where
&gt;&gt; a possible difference can be shown to exist by listening
&gt;&gt; alone and also scientifically valid.
&gt;&gt; http://theaudiocritic.com/blog/index.php?op=ViewArticle&amp;articleId=35&amp;...

&gt;&gt; Don't miss the link at the end of this short article
&gt;&gt; that describes the software and methods used.
">

Been there, done that many times. The problem with this methodology is that
it is easily overwhelmed by trivial differences such as phase shift of any
kind but linear phase.  You end up with two waves that sound very much
alike, but generate relatively large difference signals. The irrelevant
information in the difference signal masks the difference that was being
listened for.

<QUOTE PREVIOUSPOST="
&gt; I think others will argue that it is likely you will be
&gt; able to meausure some difference, but you won't be able
&gt; to hear it.
">

This can easily happen, because test equipment has become very, very
sensitive.

<QUOTE PREVIOUSPOST="
&gt;  And others will claim they can hear it.
">

You may hear a large difference signal, but is it all that relevant?

<QUOTE PREVIOUSPOST="
&gt; Perhaps an ABX test under this circumstance with some
&gt; training might be of some value.
">

You can learn how to do that at www.pcabx.com .

<QUOTE PREVIOUSPOST="
&gt; But to do all this in a
&gt; well controlled test is, again, a research project and
&gt; not an amateur, home-oriented test.
">

www.pcabx.com has links to everything you need to do high quality listening
tests as easily as possible, given the inherent problems with listening
tests in general, such as the ones I mentioned above.
</POST>
<POST>
<POSTER> Steven Sullivan &lt;ssu...@panix.com&gt; </POSTER>
<POSTDATE> 2007-03-29T18:57:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
Arny Krueger &lt;a ... @hotpop.com&gt; wrote:
&gt; &quot;Harry Lavo&quot; &lt;h ... @hotmail.com&gt; wrote in message
&gt; news:eufbat0jo7@news1.newsguy.com
&gt; &gt; &quot;William Eckle&quot; &lt;a ... @wmeckle.com&gt; wrote in message
&gt; &gt; news:epadnWEps7qydpfbnZ2dnUVZ_sWdnZ2d@pghconnect.com ...
&gt; &gt;&gt; The classic abx listening test is a chore to setup and
&gt; &gt;&gt; perform.
&gt; Depends.  PCABX is an exact test for many kinds of listening tests that
&gt; people are interested in today, and a useful approximation for a wide
&gt; variety of tests.  It's easier than going to a store and doing a careful job
&gt; of comparing components using one of the house's systems.
&gt; &gt;&gt;  Its clear strength is the ability to determine
&gt; &gt;&gt; if a difference, any difference, can be shown to exist
&gt; &gt;&gt; by listening alone in a scientifically valid way.
&gt; There ain't no such thing. The world is full of differences that are
&gt; measurable but not audible at all. So, one caveat is that the difference has
&gt; to be audible, and not all differences are audible. Secondly, the audibility
&gt; of many differences are contingent on a wide variety of influences, two of
&gt; the stronger ones being  the sensitivity of the listener, and some
&gt; properties of the music being used for the comparison that may be
&gt; non-obvioius.
">

However, it only takes one positive ABX test run to demonstrate that
the person who took the test could differentiate the sound of A and B.
(Assuming of course that the test was set up properly.)  And it only takes
one person demonstrably hearing a difference, to 'prove' that the two things sound
different.  That's not the same as saying 'anyone' will be able to hear
the difference, of course.

___
-S
"As human beings, we understand the world through simile, analogy,
metaphor, narrative and, sometimes, claymation." - B. Mason
</POST>
<POST>
<POSTER> "Harry Lavo" &lt;h...@hotmail.com&gt; </POSTER>
<POSTDATE> 2007-03-30T11:28:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;bob&quot; &lt;nabo ... @hotmail.com&gt; wrote in message
">

news:euh8i102336@news5.newsguy.com ...

<QUOTE PREVIOUSPOST="
&gt; On Mar 28, 11:21 pm, &quot;Harry Lavo&quot; &lt;h ... @hotmail.com&gt; wrote:
&gt;&gt; Unfortunately, this is not true.  The researchers at Harman Kardon have
&gt;&gt; found that over 40% of people, even with careful training, cannot
&gt;&gt; reliably
&gt;&gt; distinquish even known differences in their training, and have to be
&gt;&gt; dropped
&gt;&gt; from any testing.

&gt; This is false. Harmon wasn't even training people to &quot;distinguish
&gt; differences.&quot; All of its subjects could *distinguish* the differences;
&gt; what they couldn't do was correlate those differences to specific
&gt; variations in frequency response. That is a much harder task, which is
&gt; why the failure rate, even after training, was so high. Anyone who's
&gt; read Sean Olive's work would understand this (assuming they wanted to
&gt; understand it).
">

So what does this say about the average music listeners ability to use ABX
with NO training?

<QUOTE PREVIOUSPOST="
&gt;&gt; The test is as much a test of the listener as it is of
&gt;&gt; the items under test.  Moreover, both ABX and ABC/hr were developed and
&gt;&gt; optimized specifically for codec testing,

&gt; .This is also false
">

Wishful thinking.

<QUOTE PREVIOUSPOST="
&gt;&gt; where easily identifiable
&gt;&gt; distortions can be used at various levels of impact to &quot;train&quot; listeners,
&gt;&gt; who then listen to the blind samples but &quot;knowing&quot; what they are
&gt;&gt; listening
&gt;&gt; for.

&gt;&gt; Open-end evaluation of audio gear does not work this way.  The human
&gt;&gt; brain
&gt;&gt; tries to relate the sound to a real sound, and doesn't even know &quot;what&quot;
&gt;&gt; to
&gt;&gt; listen for...timbre, soundspace, subtles distortions, etc.  That seems to
&gt;&gt; be
&gt;&gt; why the result of open-ended listening via ABX results in almost
&gt;&gt; immediate
&gt;&gt; listening fatique...it is a total unnatural use of the technique for this
&gt;&gt; purpose.

&gt; This is idle speculation by someone who knows nothing about the
&gt; subject he's talking about. There isn't a shred of real evidence for
&gt; any of it. It's pseudoscience.
">

This is reality, as even people who desire to take the test often drop out
before even 15 samples for this very reason.

<QUOTE PREVIOUSPOST="
&gt;&gt;  Put simply it violates the first cardinal principal of test
&gt;&gt; design...that is to prevent any aspect of the test from intervening as a
&gt;&gt; variable.

&gt; Again, you haven't a shred of evidence that ABX or ABC/hr tests
&gt; interfere with perception in any way.
">

More evidence (admittedly anecdotal)  than has been presented to validate
that it works for open-ended evaluation of audio components.

<QUOTE PREVIOUSPOST="
&gt;&gt; ABX can be used for crude audio measures....volume, frequency shifts in
&gt;&gt; white noise, etc.  As soon as it comes to listening to music, sensitivity
&gt;&gt; decreases or disappears.

&gt; It is certainly true that it is easier to hear differences in level
&gt; and FR using test tones than using music. This has nothing to do with
&gt; any particular test. It has to do with the way the human hearing
&gt; mechanism works, and it is true no matter what listening method you
&gt; use.
">

To paraphrase, you haven't a shred of evidence that long term, exploratory
tests
paired with short term comparisons doesn't overcome this limitation.  We are
talking MUSIC, after all...not white noise.

<QUOTE PREVIOUSPOST="
&gt;&gt; This isn't just speculation....review the
&gt;&gt; Greenhill tests in Stereo Review (search index at their site).

&gt; Where you won't find it. But if anyone wants to read what Greenhill
&gt; actually found (rather than someone's re-invention of it), e-mail me
&gt; and I can send you the article.
">

And if you wish to email me I can send you an accurate and complete Excel
table of the results.

<QUOTE PREVIOUSPOST="
&gt; Harry is peddling pure pseudoscience here.
">

You've heard from a true ABX believer.  Ask for the validation test that
this technique, developed very specifically for codec distortions, works as
the best tool for open-ended evaluation of audio components.
</POST>
<POST>
<POSTER> "Harry Lavo" &lt;h...@hotmail.com&gt; </POSTER>
<POSTDATE> 2007-03-30T11:32:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;Steven Sullivan&quot; &lt;ssu ... @panix.com&gt; wrote in message
">

news:euh8ji0234l@news5.newsguy.com ...

<QUOTE PREVIOUSPOST="
&gt; Harry Lavo &lt;h ... @hotmail.com&gt; wrote:
&gt;&gt; &quot;William Eckle&quot; &lt;a ... @wmeckle.com&gt; wrote in message
&gt;&gt; news:epadnWEps7qydpfbnZ2dnUVZ_sWdnZ2d@pghconnect.com ...
&gt;&gt; &gt; The classic abx listening test is a chore to setup and perform.  Its
&gt;&gt; &gt; clear strength is the ability to determine if a difference, any
&gt;&gt; &gt; difference, can be shown to exist by listening alone in a
&gt;&gt; &gt; scientifically valid way. Substitute some element for another which
&gt;&gt; &gt; is thought to possibly make an audible difference and if no
&gt;&gt; &gt; difference can be heard then the claim of amp or wire etc.
&gt;&gt; &gt; differences are moot and any subjective claims highly questionable.

&gt;&gt; Unfortunately, this is not true.  The researchers at Harman Kardon have
&gt;&gt; found that over 40% of people, even with careful training, cannot
&gt;&gt; reliably
&gt;&gt; distinquish even known differences in their training, and have to be
&gt;&gt; dropped
&gt;&gt; from any testing.  The test is as much a test of the listener as it is of
&gt;&gt; the items under test.  Moreover, both ABX and ABC/hr were developed and
&gt;&gt; optimized specifically for codec testing, where easily identifiable
&gt;&gt; distortions can be used at various levels of impact to &quot;train&quot; listeners,
&gt;&gt; who then listen to the blind samples but &quot;knowing&quot; what they are
&gt;&gt; listening
&gt;&gt; for.

&gt;&gt; Open-end evaluation of audio gear does not work this way.  The human
&gt;&gt; brain
&gt;&gt; tries to relate the sound to a real sound, and doesn't even know &quot;what&quot;
&gt;&gt; to
&gt;&gt; listen for...timbre, soundspace, subtles distortions, etc.  That seems to
&gt;&gt; be
&gt;&gt; why the result of open-ended listening via ABX results in almost
&gt;&gt; immediate
&gt;&gt; listening fatique...it is a total unnatural use of the technique for this
&gt;&gt; purpose.  Put simply it violates the first cardinal principal of test
&gt;&gt; design...that is to prevent any aspect of the test from intervening as a
&gt;&gt; variable.

&gt; ....and then,once these 'differences' have been 'heard' to the
&gt; listener's satisfaction, it's time to see if they're real...via a
&gt; blind comparison.  You just can't get around that.
">

Sure you can.  You simply don't have to require 100% "proof" to make an
audio purchase.

<QUOTE PREVIOUSPOST="
&gt;&gt; ABX can be used for crude audio measures....volume, frequency shifts in
&gt;&gt; white noise, etc.  As soon as it comes to listening to music, sensitivity
&gt;&gt; decreases or disappears.  This isn't just speculation....review the
&gt;&gt; Greenhill tests in Stereo Review (search index at their site).

&gt; Nonsense, Harry.  ABX has been used to detect the difference between .wav
&gt; source and 320 kbps
&gt; mp3s -- which are *extremely* difficult to tell apart. Sensitivity is
&gt; certainly reduced for
&gt; comparisons (sighted or blind) when music is used RATHER THAN TEST TONES.
&gt; This is not a
&gt; function of sighted versus blind, and the Greenhill tests do not say
&gt; otherwise.
">

I didn't say it did.  What I said was that the Greenhill test clearly shows
that the test is sensitive to differences in levels and in white noise,
while remaining insensitve with choral music as the source.  It says nothing
about other tests, pro or con.  But it does have relevance for ABX.

<QUOTE PREVIOUSPOST="
- Hide quoted text - - Show quoted text -
">

<QUOTE PREVIOUSPOST="
&gt;&gt; &gt; Here is a new way to perform the same kind of test with greatly
&gt;&gt; &gt; simplified methods that create the context where a possible
&gt;&gt; &gt; difference can be shown to exist by listening alone and also
&gt;&gt; &gt; scientifically valid.

&gt;&gt; &gt; http://theaudiocritic.com/blog/index.php?op=ViewArticle&amp;articleId=35&amp;...

&gt;&gt; &gt; Don't miss the link at the end of this short article that describes
&gt;&gt; &gt; the software and methods used.

&gt;&gt; I think others will argue that it is likely you will be able to meausure
&gt;&gt; some difference, but you won't be able to hear it.  And others will claim
&gt;&gt; they can hear it.  Perhaps an ABX test under this circumstance with some
&gt;&gt; training might be of some value.  But to do all this in a well controlled
&gt;&gt; test is, again, a research project and not an amateur, home-oriented
&gt;&gt; test.

&gt; The main value of a difference test is where it produces a null (and by
&gt; null,
&gt; it must mean residual levels below the practical or theoretical limits of
&gt; human
&gt; hearing).  There, subjectivists would have to invoke some new sort of
&gt; audible effect,
&gt; akin to homeopathy, where vanishingly small amounts of 'medicine' are said
&gt; to
&gt; effect cures.  I wouldn't put it past them.
">

It must be nice to be so certain.  In the Pro Audio Digest thread of March
that I read at J. Junes suggestion last night, one of the correspondents
(screened for participation by highly regarded practical professional
engineers) antecdotally told of a blind test whereby a friend with a very
high level of success could pick out two identical samples (that met the
null test and proved bit-identical) on two different brands of gold-plated
CD disks.  He wasn't challenged.

Moreover, the general consensus of the group (which included Jim Johnson and
Dan Lavry) was that the CD cutoff was too low and artifacts were often
audible as a result, including pre-ringing and/or phase shift, and that 64K
was the necessary minimum to avoid even the possibility of problems.  Please
note that this directly contradicts Arny's recent assertions here that CD's
are audibly at the level of ultimate transparency(1), and that the
66khz/20bit recommendation of the Japanese hi-rez group in the mid-90's was
nothing but marketing-driven propoganda(2).

What I took away after following the discussion, which was one of two major
topics for the month, was that real engineers are very aware of what is NOT
known (including standards of audibility and a means of simulating what the
ear really can hear)...and that the folks here and elsewhere who are so sure
they know the truth are not real scientists or engineers.   On the other
hand, some of us having been saying that for years and shouldn't be
surprised.  But it is nice to have the real pros reinforce the opinion.

Footnotes:

(1) A. Krueger, RAHE, "Cable Upgrade Solutions", March 26:  "The CD format
has always
and continues to prvoide sonically transparent recording and reproduction of
music....a format that is far from perfect can
be sonically transparent."

(2) A. Krueger, RAHE, "Need Vinyl to Digital Advice", March 8 (in reply to
HL):

"HL:&gt;The Japanese

<QUOTE PREVIOUSPOST="
&gt; consortium that investigated hi-rez in the mid '90's
&gt; concluded that 66khz/20 bits was the minimum beyond which
&gt; differences could not be heard.
">

"AK: Poor quality tests by advocates of a now-failed technology does not
establish a scientific fact. "
</POST>
<POST>
<POSTER> "Harry Lavo" &lt;h...@hotmail.com&gt; </POSTER>
<POSTDATE> 2007-03-30T11:38:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;Arny Krueger&quot; &lt;a ... @hotpop.com&gt; wrote in message
">

news:euh8r2023d5@news5.newsguy.com ...

<QUOTE PREVIOUSPOST="
&gt; &quot;Harry Lavo&quot; &lt;h ... @hotmail.com&gt; wrote in message
&gt; news:eufbat0jo7@news1.newsguy.com
&gt;&gt; &quot;William Eckle&quot; &lt;a ... @wmeckle.com&gt; wrote in message
&gt;&gt; news:epadnWEps7qydpfbnZ2dnUVZ_sWdnZ2d@pghconnect.com ...

&gt;&gt;&gt; The classic abx listening test is a chore to setup and
&gt;&gt;&gt; perform.

&gt; Depends.  PCABX is an exact test for many kinds of listening tests that
&gt; people are interested in today,
">

* This means to determine which bit-rate of MP3 or other codec to choose.
Very hi-fi.

and a useful approximation for a wide

<QUOTE PREVIOUSPOST="
&gt; variety of tests.  It's easier than going to a store and doing a careful
&gt; job
&gt; of comparing components using one of the house's systems.
">

*  Yeah, take that amplifier and shove it into your PC.  Ditto the tuner.
Maybe the CD player.  Wonderful way to listen to components.

<QUOTE PREVIOUSPOST="
&gt;&gt;&gt;  Its clear strength is the ability to determine
&gt;&gt;&gt; if a difference, any difference, can be shown to exist
&gt;&gt;&gt; by listening alone in a scientifically valid way.
">

* If such difference is strong enough to overcome PC digitalization.

<QUOTE PREVIOUSPOST="
&gt; There ain't no such thing. The world is full of differences that are
&gt; measurable but not audible at all. So, one caveat is that the difference
&gt; has
&gt; to be audible, and not all differences are audible. Secondly, the
&gt; audibility
&gt; of many differences are contingent on a wide variety of influences, two of
&gt; the stronger ones being  the sensitivity of the listener, and some
&gt; properties of the music being used for the comparison that may be
&gt; non-obvioius.
">

* Who are you speaking to?  Not me.

<QUOTE PREVIOUSPOST="
&gt;&gt;&gt; Substitute some element for another which is thought to
&gt;&gt;&gt; possibly make an audible difference and if no difference
&gt;&gt;&gt; can be heard then the claim of amp or wire etc.
&gt;&gt;&gt; differences are moot and any subjective claims highly
&gt;&gt;&gt; questionable.

&gt; Or, you picked the wrong music or associated components. Or, the
&gt; listener's
&gt; sensitivity was atypically poor for any number of different reasons.
">

* Who are you speaking to?  Not me.

<QUOTE PREVIOUSPOST="
&gt;&gt; Unfortunately, this is not true.

&gt; So far so good.

&gt;&gt;  The researchers at
&gt;&gt; Harman Kardon have found that over 40% of people, even
&gt;&gt; with careful training, cannot reliably distinquish even
&gt;&gt; known differences in their training, and have to be
&gt;&gt; dropped from any testing.

&gt; Ironically, these same listeners would no doubt report a plethora of
&gt; audible
&gt; differences in a sighted evaluation. ;-)
">

* Straw man supposition, at best.  Flame at worst.

<QUOTE PREVIOUSPOST="
&gt;&gt;  The test is as much a test of
&gt;&gt; the listener as it is of the items under test.

&gt; Name a subjective test methodology where this *isn't* true.  Some people
&gt; like to play a silly game where they assert that a certain general problem
&gt; that afflicts just about any test is a problem of just their least
&gt; favorite
&gt; kind of listening evaluation.
">

*  The point is: if you want to choose hi-fi, you listen yourself.  If you
want a scientific test, you prescreen people for sensitivity.  You don't use
ABX willy-nilly at random....you do a carefully constructed, controlled
scientific test, or you just use your ears and do your best.

<QUOTE PREVIOUSPOST="
&gt;&gt; Moreover,
&gt;&gt; both ABX and ABC/hr were developed and optimized
&gt;&gt; specifically for codec testing,

&gt; Simply not true of ABX, since ABX was developed and popularized before the
&gt; audio world even knew what a codec in the modern sense was.
">

Tell that to the ITU standards committee who state otherwise.

<QUOTE PREVIOUSPOST="
&gt;&gt;  where easily identifiable
&gt;&gt; distortions can be used at various levels of impact to
&gt;&gt; &quot;train&quot; listeners,

&gt; Surely true for more than just codecs, so this is also a false claim.
">

Okay.....train for "natural timbre" across a wide variety of instruments.

<QUOTE PREVIOUSPOST="
&gt;&gt;  who then listen to the blind samples
&gt;&gt; but &quot;knowing&quot; what they are listening for.

&gt; Which opens yet another general problem with subjective tests. Differences
&gt; are very often easier to detect if you know what to listen for, so how do
&gt; you know what to listen for until someone has first actually heard it?
">

You don't ... that's partly the point.  Open-ended evaluation is called that
because you don't start with preconceptions or "knowing" differences...you
listen for some time on a wide variety of music, form some hypothesis viz a
viz differences when those differences crystalize via your ear/brain
synthesis, and then switch to synched A-B comparisons across some sections
of music that get at it, and then move on to another audio manifestation
that has revealed itself to you.  When you are done, you've concluded an
audio profile of the component you are switching.  Such a profile may be
(usually is) somewhat multi-dimensional.

<QUOTE PREVIOUSPOST="
&gt;&gt; Open-end evaluation of audio gear does not work this way.

&gt; Actually, open-end evaluation doesn't work at all. It is open-ended all
&gt; right - it contains poor-to-non-existent safeguards against false
&gt; positives.
">

Yes, but it also doesn not result in false negatives.

<QUOTE PREVIOUSPOST="
&gt;&gt; The human brain tries to relate the sound to a real
&gt;&gt; sound, and doesn't even know &quot;what&quot; to listen
&gt;&gt; for...timbre, soundspace, subtles distortions, etc.

&gt; A truism that all by itself can't support any particular viewpoint.
">

Wrong...it works directly against ABX and it's need for "known distortion or
flaw" and "staged training".

<QUOTE PREVIOUSPOST="
&gt;&gt; That
&gt;&gt; seems to be why the result of open-ended listening via
&gt;&gt; ABX results in almost immediate listening fatique...it is
&gt;&gt; a total unnatural use of the technique for this purpose.

&gt; Fact is that lots of people report fatigue while listening by *any* means
&gt; that efficiently rejects false positives. The reason is pretty obvious,
&gt; most
&gt; of their former experiences were all about false positives. Take those
&gt; away
&gt; and they suddenly have to produce more than fond wishes that they heard a
&gt; difference.
">

Well, that is the objectivist hypothesis.  Proof that it is correct?

<QUOTE PREVIOUSPOST="
&gt;&gt; Put simply it violates the first cardinal principal of
&gt;&gt; test design...that is to prevent any aspect of the test
&gt;&gt; from intervening as a variable.

&gt; There ain't no such rule.
">

Evidence that you don't really know that much about test design.  Absolutely
there is such a rule.

<QUOTE PREVIOUSPOST="
&gt;&gt; ABX can be used for crude audio measures....volume,
&gt;&gt; frequency shifts in white noise, etc.

&gt; This is one of those statements that immediatly raises a red flag.
&gt; Broadband
&gt; white noise, being an unweighted varying and random combination of all
&gt; frequencies, is very much immune audible effects due to frequency shifts.
&gt; Theresfore it is a nonsense statement because it is contingent on
&gt; something
&gt; that doesn't ever happen.
">

Okay, I should have said "frequency shifts in white noise reproduction".  We
are (or at least I am) talking about open-ended evaluation of audio
components, you know.

<QUOTE PREVIOUSPOST="
&gt;&gt;  As soon as it
&gt;&gt; comes to listening to music, sensitivity decreases or
&gt;&gt; disappears.

&gt; Name a subjective test methodology where this *isn't* true.
">

Long term listening.

<QUOTE PREVIOUSPOST="
&gt;&gt;  This isn't just speculation

&gt; No, its mostly false and mistleading claims, that shouldn't even qualify
&gt; as
&gt; reasonable speculation.
">

Where is your "IMO".  Hardly a fact.

<QUOTE PREVIOUSPOST="
&gt;&gt; ....review the
&gt;&gt; Greenhill tests in Stereo Review (search index at their
&gt;&gt; site).

&gt; Greenhill was an advocate of ABX at the time those tests were written and
&gt; published. I spoke with him personally for hours in those days.
">

Great for you.  Your point?

<QUOTE PREVIOUSPOST="
&gt;&gt;&gt; Here is a new way to perform the same kind of test with
&gt;&gt;&gt; greatly simplified methods that create the context where
&gt;&gt;&gt; a possible difference can be shown to exist by listening
&gt;&gt;&gt; alone and also scientifically valid.

&gt;&gt;&gt; http://theaudiocritic.com/blog/index.php?op=ViewArticle&amp;articleId=35&amp;...

&gt;&gt;&gt; Don't miss the link at the end of this short article
&gt;&gt;&gt; that describes the software and methods used.

&gt; Been there, done that many times. The problem with this methodology is
&gt; that
&gt; it is easily overwhelmed by trivial differences such as phase shift of any
&gt; kind but linear phase.  You end up with two waves that sound very much
&gt; alike, but generate relatively large difference signals. The irrelevant
&gt; information in the difference signal masks the difference that was being
&gt; listened for.
">

Well, maybe Acel just listens to sine waves.

<QUOTE PREVIOUSPOST="
- Hide quoted text - - Show quoted text -
">

<QUOTE PREVIOUSPOST="
&gt;&gt; I think others will argue that it is likely you will be
&gt;&gt; able to meausure some difference, but you won't be able
&gt;&gt; to hear it.

&gt; This can easily happen, because test equipment has become very, very
&gt; sensitive.

&gt;&gt;  And others will claim they can hear it.

&gt; You may hear a large difference signal, but is it all that relevant?

&gt;&gt; Perhaps an ABX test under this circumstance with some
&gt;&gt; training might be of some value.

&gt; You can learn how to do that at www.pcabx.com .

&gt;&gt; But to do all this in a
&gt;&gt; well controlled test is, again, a research project and
&gt;&gt; not an amateur, home-oriented test.

&gt; www.pcabx.com has links to everything you need to do high quality
&gt; listening
&gt; tests as easily as possible, given the inherent problems with listening
&gt; tests in general, such as the ones I mentioned above.
">

It would have helped very much if you had responded either to me or to Bill
Eckle, but not both at once.
</POST>
<POST>
<POSTER> "Arny Krueger" &lt;a...@hotpop.com&gt; </POSTER>
<POSTDATE> 2007-03-30T11:41:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;Steven Sullivan&quot; &lt;ssu ... @panix.com&gt; wrote in message
">

news:euhg8501c5c@news2.newsguy.com

<QUOTE PREVIOUSPOST="
&gt; Arny Krueger &lt;a ... @hotpop.com&gt; wrote:
&gt;&gt; &quot;Harry Lavo&quot; &lt;h ... @hotmail.com&gt; wrote in message
&gt;&gt; news:eufbat0jo7@news1.newsguy.com
&gt;&gt;&gt; &quot;William Eckle&quot; &lt;a ... @wmeckle.com&gt; wrote in message
&gt;&gt;&gt; news:epadnWEps7qydpfbnZ2dnUVZ_sWdnZ2d@pghconnect.com ...

&gt;&gt;&gt;&gt; The classic abx listening test is a chore to setup and
&gt;&gt;&gt;&gt; perform.

&gt;&gt; Depends.  PCABX is an exact test for many kinds of
&gt;&gt; listening tests that people are interested in today, and
&gt;&gt; a useful approximation for a wide variety of tests.
&gt;&gt; It's easier than going to a store and doing a careful
&gt;&gt; job of comparing components using one of the house's
&gt;&gt; systems.

&gt;&gt;&gt;&gt;  Its clear strength is the ability to determine
&gt;&gt;&gt;&gt; if a difference, any difference, can be shown to exist
&gt;&gt;&gt;&gt; by listening alone in a scientifically valid way.

&gt;&gt; There ain't no such thing. The world is full of
&gt;&gt; differences that are measurable but not audible at all.
&gt;&gt; So, one caveat is that the difference has to be audible,
&gt;&gt; and not all differences are audible. Secondly, the
&gt;&gt; audibility of many differences are contingent on a wide
&gt;&gt; variety of influences, two of the stronger ones being
&gt;&gt; the sensitivity of the listener, and some properties of
&gt;&gt; the music being used for the comparison that may be
&gt;&gt; non-obvioius.
&gt; However, it only takes one positive ABX test run to
&gt; demonstrate that
&gt; the person who took the test could differentiate the
&gt; sound of A and B. (Assuming of course that the test was
&gt; set up properly.)
">

You have to be careful. Every once in a while people win on 100:1 shots.

<QUOTE PREVIOUSPOST="
&gt; And it only takes
&gt; one person demonstrably hearing a difference, to 'prove'
&gt; that the two things sound different.  That's not the same
&gt; as saying 'anyone' will be able to hear
&gt; the difference, of course.
">

We never found any "golden ears" with ABX. We did find tin ears. We did find
people who got lucky, but couldn't duplicate their short-run results with
longer runs.
</POST>
<POST>
<POSTER> Steven Sullivan &lt;ssu...@panix.com&gt; </POSTER>
<POSTDATE> 2007-03-30T12:22:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
Harry Lavo &lt;h ... @hotmail.com&gt; wrote:
&gt; &quot;bob&quot; &lt;nabo ... @hotmail.com&gt; wrote in message
&gt; news:euh8i102336@news5.newsguy.com ...
&gt; &gt; On Mar 28, 11:21 pm, &quot;Harry Lavo&quot; &lt;h ... @hotmail.com&gt; wrote:
&gt; &gt;&gt; Unfortunately, this is not true.  The researchers at Harman Kardon have
&gt; &gt;&gt; found that over 40% of people, even with careful training, cannot
&gt; &gt;&gt; reliably
&gt; &gt;&gt; distinquish even known differences in their training, and have to be
&gt; &gt;&gt; dropped
&gt; &gt;&gt; from any testing.

&gt; &gt; This is false. Harmon wasn't even training people to &quot;distinguish
&gt; &gt; differences.&quot; All of its subjects could *distinguish* the differences;
&gt; &gt; what they couldn't do was correlate those differences to specific
&gt; &gt; variations in frequency response. That is a much harder task, which is
&gt; &gt; why the failure rate, even after training, was so high. Anyone who's
&gt; &gt; read Sean Olive's work would understand this (assuming they wanted to
&gt; &gt; understand it).
&gt; So what does this say about the average music listeners ability to use ABX
&gt; with NO training?
">

What does it say about the average music listener's ability to correctly
identify difference in a sighted comparison?  There, one is compounding
a lack of training, with a surfeit of bias.

Yet that's the regimen used most commonly in audio equipment 'reviewing'.

Any wonder that the 'audiophile' is something of a joke?
</POST>
<POST>
<POSTER> "bob" &lt;nabo...@hotmail.com&gt; </POSTER>
<POSTDATE> 2007-03-30T12:25:00 </POSTDATE>
On Mar 30, 11:28 am, "Harry Lavo" &lt;h ... @hotmail.com&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; &quot;bob&quot; &lt;nabo ... @hotmail.com&gt; wrote in message

&gt; news:euh8i102336@news5.newsguy.com ...

&gt; &gt; On Mar 28, 11:21 pm, &quot;Harry Lavo&quot; &lt;h ... @hotmail.com&gt; wrote:
&gt; &gt;&gt; Unfortunately, this is not true.  The researchers at Harman Kardon have
&gt; &gt;&gt; found that over 40% of people, even with careful training, cannot
&gt; &gt;&gt; reliably
&gt; &gt;&gt; distinquish even known differences in their training, and have to be
&gt; &gt;&gt; dropped
&gt; &gt;&gt; from any testing.

&gt; &gt; This is false. Harmon wasn't even training people to &quot;distinguish
&gt; &gt; differences.&quot; All of its subjects could *distinguish* the differences;
&gt; &gt; what they couldn't do was correlate those differences to specific
&gt; &gt; variations in frequency response. That is a much harder task, which is
&gt; &gt; why the failure rate, even after training, was so high. Anyone who's
&gt; &gt; read Sean Olive's work would understand this (assuming they wanted to
&gt; &gt; understand it).

&gt; So what does this say about the average music listeners ability to use ABX
&gt; with NO training?
">

Nobody *needs* training to take an ABX test. The purpose of training
is to heighten the subject's ability to hear the difference being
tested. An ABX test tells you what you can hear right now, whether
you've had training or not. In particular, if someone claims he can
hear a difference between A and B, then he should need no training at
all in order to demonstrate that ability in a blind test. That he
usually can't do so merely proves he's a phony.

<QUOTE PREVIOUSPOST="
&gt; &gt;&gt; The test is as much a test of the listener as it is of
&gt; &gt;&gt; the items under test.  Moreover, both ABX and ABC/hr were developed and
&gt; &gt;&gt; optimized specifically for codec testing,

&gt; &gt; .This is also false

&gt; Wishful thinking.
">

That ABX was developed to test codecs?

<QUOTE PREVIOUSPOST="
- Hide quoted text - - Show quoted text -
">

<QUOTE PREVIOUSPOST="
&gt; &gt;&gt; where easily identifiable
&gt; &gt;&gt; distortions can be used at various levels of impact to &quot;train&quot; listeners,
&gt; &gt;&gt; who then listen to the blind samples but &quot;knowing&quot; what they are
&gt; &gt;&gt; listening
&gt; &gt;&gt; for.

&gt; &gt;&gt; Open-end evaluation of audio gear does not work this way.  The human
&gt; &gt;&gt; brain
&gt; &gt;&gt; tries to relate the sound to a real sound, and doesn't even know &quot;what&quot;
&gt; &gt;&gt; to
&gt; &gt;&gt; listen for...timbre, soundspace, subtles distortions, etc.  That seems to
&gt; &gt;&gt; be
&gt; &gt;&gt; why the result of open-ended listening via ABX results in almost
&gt; &gt;&gt; immediate
&gt; &gt;&gt; listening fatique...it is a total unnatural use of the technique for this
&gt; &gt;&gt; purpose.

&gt; &gt; This is idle speculation by someone who knows nothing about the
&gt; &gt; subject he's talking about. There isn't a shred of real evidence for
&gt; &gt; any of it. It's pseudoscience.

&gt; This is reality, as even people who desire to take the test often drop out
&gt; before even 15 samples for this very reason.
">

Your whole paragraph was pseudoscience, not just the last bit of
nonsense. You're making everything up as you go along, Harry. As for
subjects dropping out from "listening fatigue," I can cite you
numerous published studies where this did not happen. Can you cite any
where it did?

<QUOTE PREVIOUSPOST="
&gt; &gt;&gt;  Put simply it violates the first cardinal principal of test
&gt; &gt;&gt; design...that is to prevent any aspect of the test from intervening as a
&gt; &gt;&gt; variable.

&gt; &gt; Again, you haven't a shred of evidence that ABX or ABC/hr tests
&gt; &gt; interfere with perception in any way.

&gt; More evidence (admittedly anecdotal)  than has been presented to validate
&gt; that it works for open-ended evaluation of audio components.
">

You don't even know what "open-ended evaluation of audio components"
means. It's just a nonsense phrase you throw into every post because
you haven't any real arguments.

<QUOTE PREVIOUSPOST="
&gt; &gt;&gt; ABX can be used for crude audio measures....volume, frequency shifts in
&gt; &gt;&gt; white noise, etc.  As soon as it comes to listening to music, sensitivity
&gt; &gt;&gt; decreases or disappears.

&gt; &gt; It is certainly true that it is easier to hear differences in level
&gt; &gt; and FR using test tones than using music. This has nothing to do with
&gt; &gt; any particular test. It has to do with the way the human hearing
&gt; &gt; mechanism works, and it is true no matter what listening method you
&gt; &gt; use.

&gt; To paraphrase, you haven't a shred of evidence that long term, exploratory
&gt; tests
&gt; paired with short term comparisons doesn't overcome this limitation.  We are
&gt; talking MUSIC, after all...not white noise.
">

We are talking masking. Something else you appear to know nothing
about. Do you honestly believe that masking doesn't happen when you
listen to music, Harry? Yes, I believe you do.

bob
</POST>
<POST>
<POSTER> Steven Sullivan &lt;ssu...@panix.com&gt; </POSTER>
<POSTDATE> 2007-03-30T13:26:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
Harry Lavo &lt;h ... @hotmail.com&gt; wrote:
&gt; &quot;Steven Sullivan&quot; &lt;ssu ... @panix.com&gt; wrote in message
&gt; news:euh8ji0234l@news5.newsguy.com ...
&gt; &gt; Harry Lavo &lt;h ... @hotmail.com&gt; wrote:
&gt; &gt;&gt; &quot;William Eckle&quot; &lt;a ... @wmeckle.com&gt; wrote in message
&gt; &gt;&gt; news:epadnWEps7qydpfbnZ2dnUVZ_sWdnZ2d@pghconnect.com ...
&gt; &gt;&gt; &gt; The classic abx listening test is a chore to setup and perform.  Its
&gt; &gt;&gt; &gt; clear strength is the ability to determine if a difference, any
&gt; &gt;&gt; &gt; difference, can be shown to exist by listening alone in a
&gt; &gt;&gt; &gt; scientifically valid way. Substitute some element for another which
&gt; &gt;&gt; &gt; is thought to possibly make an audible difference and if no
&gt; &gt;&gt; &gt; difference can be heard then the claim of amp or wire etc.
&gt; &gt;&gt; &gt; differences are moot and any subjective claims highly questionable.

&gt; &gt;&gt; Unfortunately, this is not true.  The researchers at Harman Kardon have
&gt; &gt;&gt; found that over 40% of people, even with careful training, cannot
&gt; &gt;&gt; reliably
&gt; &gt;&gt; distinquish even known differences in their training, and have to be
&gt; &gt;&gt; dropped
&gt; &gt;&gt; from any testing.  The test is as much a test of the listener as it is of
&gt; &gt;&gt; the items under test.  Moreover, both ABX and ABC/hr were developed and
&gt; &gt;&gt; optimized specifically for codec testing, where easily identifiable
&gt; &gt;&gt; distortions can be used at various levels of impact to &quot;train&quot; listeners,
&gt; &gt;&gt; who then listen to the blind samples but &quot;knowing&quot; what they are
&gt; &gt;&gt; listening
&gt; &gt;&gt; for.

&gt; &gt;&gt; Open-end evaluation of audio gear does not work this way.  The human
&gt; &gt;&gt; brain
&gt; &gt;&gt; tries to relate the sound to a real sound, and doesn't even know &quot;what&quot;
&gt; &gt;&gt; to
&gt; &gt;&gt; listen for...timbre, soundspace, subtles distortions, etc.  That seems to
&gt; &gt;&gt; be
&gt; &gt;&gt; why the result of open-ended listening via ABX results in almost
&gt; &gt;&gt; immediate
&gt; &gt;&gt; listening fatique...it is a total unnatural use of the technique for this
&gt; &gt;&gt; purpose.  Put simply it violates the first cardinal principal of test
&gt; &gt;&gt; design...that is to prevent any aspect of the test from intervening as a
&gt; &gt;&gt; variable.

&gt; &gt; ....and then,once these 'differences' have been 'heard' to the
&gt; &gt; listener's satisfaction, it's time to see if they're real...via a
&gt; &gt; blind comparison.  You just can't get around that.
&gt; Sure you can.  You simply don't have to require 100% &quot;proof&quot; to make an
&gt; audio purchase.
">

Now you're moving the goalposts. I'm talking about establishing audible difference, period,
not making purchasing decisions.  There was nothing about 'purchases' in the stuff you quoted.
For the 10,000th time, no one says anyone 'has' to have 100% proof of audible difference *to
make a purchase*.  But when people ask (perhaps in relation to a purchase, perhaps not)
whether one piece of gear SOUNDS 'better' than another (implying difference), or assert same,
they are making an assumption that either stands or falls based on evidence.  And 'evidence'
from sighted comparison is inevitably prone to bias, whether the comparison is 'open-ended' or
not.  If you're happy with that, fine, jsut don't act like  you've got more than '50%' proof
for your claim.  If you do want to determine if *you've* heard a *real* difference, then
you cannot get around the need for a blind comparison.

<QUOTE PREVIOUSPOST="
- Hide quoted text - - Show quoted text -
">

<QUOTE PREVIOUSPOST="
&gt; &gt;&gt; ABX can be used for crude audio measures....volume, frequency shifts in
&gt; &gt;&gt; white noise, etc.  As soon as it comes to listening to music, sensitivity
&gt; &gt;&gt; decreases or disappears.  This isn't just speculation....review the
&gt; &gt;&gt; Greenhill tests in Stereo Review (search index at their site).

&gt; &gt; Nonsense, Harry.  ABX has been used to detect the difference between .wav
&gt; &gt; source and 320 kbps
&gt; &gt; mp3s -- which are *extremely* difficult to tell apart. Sensitivity is
&gt; &gt; certainly reduced for
&gt; &gt; comparisons (sighted or blind) when music is used RATHER THAN TEST TONES.
&gt; &gt; This is not a
&gt; &gt; function of sighted versus blind, and the Greenhill tests do not say
&gt; &gt; otherwise.
&gt; I didn't say it did.  What I said was that the Greenhill test clearly shows
&gt; that the test is sensitive to differences in levels and in white noise,
&gt; while remaining insensitve with choral music as the source.  It says nothing
&gt; about other tests, pro or con.  But it does have relevance for ABX.
">

All audio comparisons, sighted or not, are affected by significant changes in level.
And it is well-known from psychoacoustics that test signals can reveal differences that are
masked by more complex signals.  So why single out ABX?  These effects operate generally and
are well-known to people who advocate scientific standards of 'audio reviewing'.  If there is
ignorance of these factors, it's more likely to be on the part of the sighted-paradigm
advocates.

<QUOTE PREVIOUSPOST="
- Hide quoted text - - Show quoted text -
">

<QUOTE PREVIOUSPOST="
&gt; &gt;&gt; &gt; Here is a new way to perform the same kind of test with greatly
&gt; &gt;&gt; &gt; simplified methods that create the context where a possible
&gt; &gt;&gt; &gt; difference can be shown to exist by listening alone and also
&gt; &gt;&gt; &gt; scientifically valid.

&gt; &gt;&gt; &gt; http://theaudiocritic.com/blog/index.php?op=ViewArticle&amp;articleId=35&amp;...

&gt; &gt;&gt; &gt; Don't miss the link at the end of this short article that describes
&gt; &gt;&gt; &gt; the software and methods used.

&gt; &gt;&gt; I think others will argue that it is likely you will be able to meausure
&gt; &gt;&gt; some difference, but you won't be able to hear it.  And others will claim
&gt; &gt;&gt; they can hear it.  Perhaps an ABX test under this circumstance with some
&gt; &gt;&gt; training might be of some value.  But to do all this in a well controlled
&gt; &gt;&gt; test is, again, a research project and not an amateur, home-oriented
&gt; &gt;&gt; test.

&gt; &gt; The main value of a difference test is where it produces a null (and by
&gt; &gt; null,
&gt; &gt; it must mean residual levels below the practical or theoretical limits of
&gt; &gt; human
&gt; &gt; hearing).  There, subjectivists would have to invoke some new sort of
&gt; &gt; audible effect,
&gt; &gt; akin to homeopathy, where vanishingly small amounts of 'medicine' are said
&gt; &gt; to
&gt; &gt; effect cures.  I wouldn't put it past them.
&gt; It must be nice to be so certain.  In the Pro Audio Digest thread of March
&gt; that I read at J. Junes suggestion last night, one of the correspondents
&gt; (screened for participation by highly regarded practical professional
&gt; engineers) antecdotally told of a blind test whereby a friend with a very
&gt; high level of success could pick out two identical samples (that met the
&gt; null test and proved bit-identical) on two different brands of gold-plated
&gt; CD disks.  He wasn't challenged.
">

Perhaps he should have been.  But then again, what's one more anecdotal report, no doubt
lacking details of test conditions, number of trials, statistics?  I've seen 'trained
professionals' in audio and in engineering (as well as 'audio engineers) make some outright
nonsensical claims before.

<QUOTE PREVIOUSPOST="
&gt; Moreover, the general consensus of the group (which included Jim Johnson and
&gt; Dan Lavry) was that the CD cutoff was too low and artifacts were often
&gt; audible as a result, including pre-ringing and/or phase shift, and that 64K
&gt; was the necessary minimum to avoid even the possibility of problems.
">

Doesn't sound like an *inherently* audible result of the technology to me.
I'm sure both Lavry and JJ are aware that technology can be implemented
well, or suboptimally.

<QUOTE PREVIOUSPOST="
&gt; Please
&gt; note that this directly contradicts Arny's recent assertions here that CD's
&gt; are audibly at the level of ultimate transparency(1), and that the
&gt; 66khz/20bit recommendation of the Japanese hi-rez group in the mid-90's was
&gt; nothing but marketing-driven propoganda(2).
">

No, it doesn't contradict (1), as long as JJ and Lavry used a qualifier like 'often' and Arny
didn't use the qualifier 'always' to mean that 'a CD is always transparent to its
source'.  Which it appears he didn't.

Do Lavry and JJ claim that 16/44 simply *cannot* be transparent to source?

<QUOTE PREVIOUSPOST="
&gt; What I took away after following the discussion, which was one of two major
&gt; topics for the month, was that real engineers are very aware of what is NOT
&gt; known (including standards of audibility and a means of simulating what the
&gt; ear really can hear)...and that the folks here and elsewhere who are so sure
&gt; they know the truth are not real scientists or engineers.   On the other
&gt; hand, some of us having been saying that for years and shouldn't be
&gt; surprised.  But it is nice to have the real pros reinforce the opinion.
">

Hilarious that you're now becoming a fan of Lavry and JJ.   I've been reading their stuff for
some years now.

Btw, how did you access the Pro list?  I couldn't find it.

___
-S
"As human beings, we understand the world through simile, analogy,
metaphor, narrative and, sometimes, claymation." - B. Mason
</POST>
<POST>
<POSTER> Steven Sullivan &lt;ssu...@panix.com&gt; </POSTER>
<POSTDATE> 2007-03-30T13:27:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
Harry Lavo &lt;h ... @hotmail.com&gt; wrote:
&gt; &quot;Arny Krueger&quot; &lt;a ... @hotpop.com&gt; wrote in message
&gt; news:euh8r2023d5@news5.newsguy.com ...
&gt; &gt; &quot;Harry Lavo&quot; &lt;h ... @hotmail.com&gt; wrote in message
&gt; &gt; news:eufbat0jo7@news1.newsguy.com
&gt; &gt;&gt; &quot;William Eckle&quot; &lt;a ... @wmeckle.com&gt; wrote in message
&gt; &gt;&gt; news:epadnWEps7qydpfbnZ2dnUVZ_sWdnZ2d@pghconnect.com ...

&gt; &gt;&gt;&gt; The classic abx listening test is a chore to setup and
&gt; &gt;&gt;&gt; perform.

&gt; &gt; Depends.  PCABX is an exact test for many kinds of listening tests that
&gt; &gt; people are interested in today,
&gt; * This means to determine which bit-rate of MP3 or other codec to choose.
&gt; Very hi-fi.
">

Have you ever tried to tell a well-encoded high-bitrate MP3 from source?

<QUOTE PREVIOUSPOST="
&gt;  and a useful approximation for a wide
&gt; &gt; variety of tests.  It's easier than going to a store and doing a careful
&gt; &gt; job
&gt; &gt; of comparing components using one of the house's systems.
&gt; *  Yeah, take that amplifier and shove it into your PC.  Ditto the tuner.
&gt; Maybe the CD player.  Wonderful way to listen to components.
">

I suspect Arny is referring to ABX tests generally, not ABX software -- the latter
is a tool for comparing sound files.

<QUOTE PREVIOUSPOST="
&gt; &gt;&gt;&gt;  Its clear strength is the ability to determine
&gt; &gt;&gt;&gt; if a difference, any difference, can be shown to exist
&gt; &gt;&gt;&gt; by listening alone in a scientifically valid way.
&gt; * If such difference is strong enough to overcome PC digitalization.
">

'PC digitalization' being different from 'digitalization' exactly how?

<QUOTE PREVIOUSPOST="
&gt; &gt; Simply not true of ABX, since ABX was developed and popularized before the
&gt; &gt; audio world even knew what a codec in the modern sense was.
&gt; Tell that to the ITU standards committee who state otherwise.
">

ITU claims ABX was developed to test audio codecs?? How are they
defining 'codec'?

<QUOTE PREVIOUSPOST="
&gt; You don't ... that's partly the point.  Open-ended evaluation is called that
&gt; because you don't start with preconceptions or &quot;knowing&quot; differences...
">

Of course you do, Harry -- that's what bias is. These 'preconceptions' maybe
be conscious, or not. But they're there.  Just seeing that two piece of gear
*look* different, can be enough to induce 'preconceptions' of audible difference.
Just 'knowing' that you are going to listen to more than one thing, is enough.

And around and around we go....

___
-S
"As human beings, we understand the world through simile, analogy,
metaphor, narrative and, sometimes, claymation." - B. Mason
</POST>
<POST>
<POSTER> Steven Sullivan &lt;ssu...@panix.com&gt; </POSTER>
<POSTDATE> 2007-03-30T13:28:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
Arny Krueger &lt;a ... @hotpop.com&gt; wrote:
&gt; &quot;Steven Sullivan&quot; &lt;ssu ... @panix.com&gt; wrote in message
&gt; news:euhg8501c5c@news2.newsguy.com
&gt; &gt; Arny Krueger &lt;a ... @hotpop.com&gt; wrote:
&gt; &gt;&gt; &quot;Harry Lavo&quot; &lt;h ... @hotmail.com&gt; wrote in message
&gt; &gt;&gt; news:eufbat0jo7@news1.newsguy.com
&gt; &gt;&gt;&gt; &quot;William Eckle&quot; &lt;a ... @wmeckle.com&gt; wrote in message
&gt; &gt;&gt;&gt; news:epadnWEps7qydpfbnZ2dnUVZ_sWdnZ2d@pghconnect.com ...

&gt; &gt;&gt;&gt;&gt; The classic abx listening test is a chore to setup and
&gt; &gt;&gt;&gt;&gt; perform.

&gt; &gt;&gt; Depends.  PCABX is an exact test for many kinds of
&gt; &gt;&gt; listening tests that people are interested in today, and
&gt; &gt;&gt; a useful approximation for a wide variety of tests.
&gt; &gt;&gt; It's easier than going to a store and doing a careful
&gt; &gt;&gt; job of comparing components using one of the house's
&gt; &gt;&gt; systems.

&gt; &gt;&gt;&gt;&gt;  Its clear strength is the ability to determine
&gt; &gt;&gt;&gt;&gt; if a difference, any difference, can be shown to exist
&gt; &gt;&gt;&gt;&gt; by listening alone in a scientifically valid way.

&gt; &gt;&gt; There ain't no such thing. The world is full of
&gt; &gt;&gt; differences that are measurable but not audible at all.
&gt; &gt;&gt; So, one caveat is that the difference has to be audible,
&gt; &gt;&gt; and not all differences are audible. Secondly, the
&gt; &gt;&gt; audibility of many differences are contingent on a wide
&gt; &gt;&gt; variety of influences, two of the stronger ones being
&gt; &gt;&gt; the sensitivity of the listener, and some properties of
&gt; &gt;&gt; the music being used for the comparison that may be
&gt; &gt;&gt; non-obvioius.
&gt; &gt; However, it only takes one positive ABX test run to
&gt; &gt; demonstrate that
&gt; &gt; the person who took the test could differentiate the
&gt; &gt; sound of A and B. (Assuming of course that the test was
&gt; &gt; set up properly.)
&gt; You have to be careful. Every once in a while people win on 100:1 shots.
">

True.  There's no 'absolute' proof.  But if the one person did enough
trials, the chance of a 'miracle' is thereby reduced.  I include
a large trial number in 'proper set up', if we're going to put all
our bets on one person.

<QUOTE PREVIOUSPOST="
&gt; &gt; And it only takes
&gt; &gt; one person demonstrably hearing a difference, to 'prove'
&gt; &gt; that the two things sound different.  That's not the same
&gt; &gt; as saying 'anyone' will be able to hear
&gt; &gt; the difference, of course.
&gt; We never found any &quot;golden ears&quot; with ABX. We did find tin ears. We did find
&gt; people who got lucky, but couldn't duplicate their short-run results with
&gt; longer runs.
">

Ah, probability....

___
-S
"As human beings, we understand the world through simile, analogy,
metaphor, narrative and, sometimes, claymation." - B. Mason
</POST>
<POST>
<POSTER> Steven Sullivan &lt;ssu...@panix.com&gt; </POSTER>
<POSTDATE> 2007-03-30T13:29:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
bob &lt;nabo ... @hotmail.com&gt; wrote:
&gt; On Mar 30, 11:28 am, &quot;Harry Lavo&quot; &lt;h ... @hotmail.com&gt; wrote:
&gt; &gt; &quot;bob&quot; &lt;nabo ... @hotmail.com&gt; wrote in message

&gt; &gt; news:euh8i102336@news5.newsguy.com ...

&gt; &gt; &gt; On Mar 28, 11:21 pm, &quot;Harry Lavo&quot; &lt;h ... @hotmail.com&gt; wrote:
&gt; &gt; &gt;&gt; Unfortunately, this is not true.  The researchers at Harman Kardon have
&gt; &gt; &gt;&gt; found that over 40% of people, even with careful training, cannot
&gt; &gt; &gt;&gt; reliably
&gt; &gt; &gt;&gt; distinquish even known differences in their training, and have to be
&gt; &gt; &gt;&gt; dropped
&gt; &gt; &gt;&gt; from any testing.

&gt; &gt; &gt; This is false. Harmon wasn't even training people to &quot;distinguish
&gt; &gt; &gt; differences.&quot; All of its subjects could *distinguish* the differences;
&gt; &gt; &gt; what they couldn't do was correlate those differences to specific
&gt; &gt; &gt; variations in frequency response. That is a much harder task, which is
&gt; &gt; &gt; why the failure rate, even after training, was so high. Anyone who's
&gt; &gt; &gt; read Sean Olive's work would understand this (assuming they wanted to
&gt; &gt; &gt; understand it).

&gt; &gt; So what does this say about the average music listeners ability to use ABX
&gt; &gt; with NO training?
&gt; Nobody *needs* training to take an ABX test. The purpose of training
&gt; is to heighten the subject's ability to hear the difference being
&gt; tested. An ABX test tells you what you can hear right now, whether
&gt; you've had training or not. In particular, if someone claims he can
&gt; hear a difference between A and B, then he should need no training at
&gt; all in order to demonstrate that ability in a blind test. That he
&gt; usually can't do so merely proves he's a phony.
">

Well, a phony knows he's lying.  Assuming sincerity, I'd say it proves he's 'probably wrong'
at best, or 'probably deluded' at worst.

___
-S
"As human beings, we understand the world through simile, analogy,
metaphor, narrative and, sometimes, claymation." - B. Mason
</POST>
<POST>
<POSTER> "mpres...@earthlink.net" &lt;mpres...@earthlink.net&gt; </POSTER>
<POSTDATE> 2007-03-30T15:36:00 </POSTDATE>
Getting back to the original article, isn't this similar to the Bob
Carver "trick" he used a long time ago when he attempted to match
the "sound" of his solid state amplifier to a C-J tube amp for the boys at
Stereophile, and then a Levinson ML-2 in a production run of one model of
his amplifiers?  I'd have to investigate, but it kind of seems similar in a
way.

mp
</POST>
<POST>
<POSTER> Steven Sullivan &lt;ssu...@panix.com&gt; </POSTER>
<POSTDATE> 2007-03-30T16:18:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
mpres ... @earthlink.net &lt;mpres ... @earthlink.net&gt; wrote:
&gt; Getting back to the original article, isn't this similar to the Bob
&gt; Carver &quot;trick&quot; he used a long time ago when he attempted to match
&gt; the &quot;sound&quot; of his solid state amplifier to a C-J tube amp for the boys at
&gt; Stereophile, and then a Levinson ML-2 in a production run of one model of
&gt; his amplifiers?  I'd have to investigate, but it kind of seems similar in a
&gt; way.
&gt; mp
">

Yes, it is.  The innovation here is that it's implemented and automated in software.

___
-S
"As human beings, we understand the world through simile, analogy,
metaphor, narrative and, sometimes, claymation." - B. Mason
</POST>
<POST>
<POSTER> "bob" &lt;nabo...@hotmail.com&gt; </POSTER>
<POSTDATE> 2007-03-30T16:18:00 </POSTDATE>
On Mar 30, 11:32 am, "Harry Lavo" &lt;h ... @hotmail.com&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; I didn't say it did.  What I said was that the Greenhill test clearly shows
&gt; that the test is sensitive to differences in levels and in white noise,
&gt; while remaining insensitve with choral music as the source.  It says nothing
&gt; about other tests, pro or con.  But it does have relevance for ABX.
">

Denial of the existence of masking noted.

&lt;snip&gt;

<QUOTE PREVIOUSPOST="
&gt; It must be nice to be so certain.  In the Pro Audio Digest thread of March
&gt; that I read at J. Junes suggestion last night, one of the correspondents
&gt; (screened for participation by highly regarded practical professional
&gt; engineers) antecdotally told of a blind test whereby a friend with a very
&gt; high level of success could pick out two identical samples (that met the
&gt; null test and proved bit-identical) on two different brands of gold-plated
&gt; CD disks.  He wasn't challenged.
">

And I notice you're not challenging him, either.

<QUOTE PREVIOUSPOST="
&gt; Moreover, the general consensus of the group (which included Jim Johnson and
&gt; Dan Lavry) was that the CD cutoff was too low and artifacts were often
&gt; audible as a result, including pre-ringing and/or phase shift, and that 64K
&gt; was the necessary minimum to avoid even the possibility of problems.  Please
&gt; note that this directly contradicts Arny's recent assertions here that CD's
&gt; are audibly at the level of ultimate transparency(1), and that the
&gt; 66khz/20bit recommendation of the Japanese hi-rez group in the mid-90's was
&gt; nothing but marketing-driven propoganda(2).
">

Yes, it's long been recognized by a lot of technical types that
16/44.1 might not be quite enough for perfect transparency. And how
did they figure this out? Blind tests, Harry.

<QUOTE PREVIOUSPOST="
&gt; What I took away after following the discussion, which was one of two major
&gt; topics for the month, was that real engineers are very aware of what is NOT
&gt; known (including standards of audibility and a means of simulating what the
&gt; ear really can hear)...and that the folks here and elsewhere who are so sure
&gt; they know the truth are not real scientists or engineers.   On the other
&gt; hand, some of us having been saying that for years and shouldn't be
&gt; surprised.  But it is nice to have the real pros reinforce the opinion.
">

Harry slays his straw man. Well, not really. Harry slays his straw man
while citing the same tests he claims his straw men are erroneously
citing. Harry really ought to try to get his story straight.

bob
</POST>
<POST>
<POSTER> Gary Eickmeier &lt;geick...@tampabay.rr.com&gt; </POSTER>
<POSTDATE> 2007-03-31T10:20:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
William Eckle wrote:
&gt; The classic abx listening test is a chore to setup and perform.  Its
&gt; clear strength is the ability to determine if a difference, any
&gt; difference, can be shown to exist by listening alone in a
&gt; scientifically valid way. Substitute some element for another which
&gt; is thought to possibly make an audible difference and if no
&gt; difference can be heard then the claim of amp or wire etc.
&gt; differences are moot and any subjective claims highly questionable.

&gt; Here is a new way to perform the same kind of test with greatly
&gt; simplified methods that create the context where a possible
&gt; difference can be shown to exist by listening alone and also
&gt; scientifically valid.

&gt; http://theaudiocritic.com/blog/index.php?op=ViewArticle&amp;articleId=35&amp;...

&gt; Don't miss the link at the end of this short article that describes
&gt; the software and methods used.
">

This is in no way a substitute for a valid listening test. It is a
measurement, a technical curiosity and no more. A given result in this
test may or may not be audible, the answer to which can only be
determined by... a listening test!

Gary Eickmeier
</POST>
<POST>
<POSTER> "Harry Lavo" &lt;h...@hotmail.com&gt; </POSTER>
<POSTDATE> 2007-03-31T10:22:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;Steven Sullivan&quot; &lt;ssu ... @panix.com&gt; wrote in message
">

news:eujh9q031e0@news3.newsguy.com ...

<QUOTE PREVIOUSPOST="
&gt; Harry Lavo &lt;h ... @hotmail.com&gt; wrote:
&gt;&gt; &quot;Arny Krueger&quot; &lt;a ... @hotpop.com&gt; wrote in message
&gt;&gt; news:euh8r2023d5@news5.newsguy.com ...
&gt;&gt; &gt; &quot;Harry Lavo&quot; &lt;h ... @hotmail.com&gt; wrote in message
&gt;&gt; &gt; news:eufbat0jo7@news1.newsguy.com
&gt;&gt; &gt;&gt; &quot;William Eckle&quot; &lt;a ... @wmeckle.com&gt; wrote in message
&gt;&gt; &gt;&gt; news:epadnWEps7qydpfbnZ2dnUVZ_sWdnZ2d@pghconnect.com ...

&gt;&gt; &gt;&gt;&gt; The classic abx listening test is a chore to setup and
&gt;&gt; &gt;&gt;&gt; perform.

&gt;&gt; &gt; Depends.  PCABX is an exact test for many kinds of listening tests that
&gt;&gt; &gt; people are interested in today,

&gt;&gt; * This means to determine which bit-rate of MP3 or other codec to choose.
&gt;&gt; Very hi-fi.

&gt; Have you ever tried to tell a well-encoded high-bitrate MP3 from source?
">

I have listened to 192k MP3 on the main system  on which I normally play the
CD's, and after five minutes my ears bled.

<QUOTE PREVIOUSPOST="
&gt;&gt;  and a useful approximation for a wide
&gt;&gt; &gt; variety of tests.  It's easier than going to a store and doing a
&gt;&gt; &gt; careful
&gt;&gt; &gt; job
&gt;&gt; &gt; of comparing components using one of the house's systems.

&gt;&gt; *  Yeah, take that amplifier and shove it into your PC.  Ditto the tuner.
&gt;&gt; Maybe the CD player.  Wonderful way to listen to components.

&gt; I suspect Arny is referring to ABX tests generally, not ABX software --
&gt; the latter
&gt; is a tool for comparing sound files.
">

His exact quote in it's totality, as above:

AK:&gt;&gt; Depends.  PCABX is an exact test for many kinds of

<QUOTE PREVIOUSPOST="
&gt;&gt; listening tests that people are interested in today, and
&gt;&gt; a useful approximation for a wide variety of tests.
&gt;&gt; It's easier than going to a store and doing a careful
&gt;&gt; job of comparing components using one of the house's
&gt;&gt; systems.
">

Sounds like a PC test to me.

<QUOTE PREVIOUSPOST="
- Hide quoted text - - Show quoted text -
">

<QUOTE PREVIOUSPOST="
&gt;&gt; &gt;&gt;&gt;  Its clear strength is the ability to determine
&gt;&gt; &gt;&gt;&gt; if a difference, any difference, can be shown to exist
&gt;&gt; &gt;&gt;&gt; by listening alone in a scientifically valid way.

&gt;&gt; * If such difference is strong enough to overcome PC digitalization.

&gt; 'PC digitalization' being different from 'digitalization' exactly how?

&gt;&gt; &gt; Simply not true of ABX, since ABX was developed and popularized before
&gt;&gt; &gt; the
&gt;&gt; &gt; audio world even knew what a codec in the modern sense was.

&gt;&gt; Tell that to the ITU standards committee who state otherwise.

&gt; ITU claims ABX was developed to test audio codecs?? How are they
&gt; defining 'codec'?
">

It was developed to help test telephone transmission techniques, which were
early forerunners of what we nowadays call audio codecs.

<QUOTE PREVIOUSPOST="
&gt;&gt; You don't ... that's partly the point.  Open-ended evaluation is called
&gt;&gt; that
&gt;&gt; because you don't start with preconceptions or &quot;knowing&quot; differences...

&gt; Of course you do, Harry -- that's what bias is. These 'preconceptions'
&gt; maybe
&gt; be conscious, or not. But they're there.  Just seeing that two piece of
&gt; gear
&gt; *look* different, can be enough to induce 'preconceptions' of audible
&gt; difference.
&gt; Just 'knowing' that you are going to listen to more than one thing, is
&gt; enough.
">

You miss my point completely.  Whether deliberately or not I do not know.
Perhaps if you hadn't cut two-thirds of it out.....

<QUOTE PREVIOUSPOST="
&gt; And around and around we go....
">

And up and down go the horses....
</POST>
<POST>
<POSTER> "Harry Lavo" &lt;h...@hotmail.com&gt; </POSTER>
<POSTDATE> 2007-03-31T10:23:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;bob&quot; &lt;nabo ... @hotmail.com&gt; wrote in message
">

news:eujdm90v8p@news5.newsguy.com ...

<QUOTE PREVIOUSPOST="
&gt; On Mar 30, 11:28 am, &quot;Harry Lavo&quot; &lt;h ... @hotmail.com&gt; wrote:
&gt;&gt; &quot;bob&quot; &lt;nabo ... @hotmail.com&gt; wrote in message

&gt;&gt; news:euh8i102336@news5.newsguy.com ...

&gt;&gt; &gt; On Mar 28, 11:21 pm, &quot;Harry Lavo&quot; &lt;h ... @hotmail.com&gt; wrote:
&gt;&gt; &gt;&gt; Unfortunately, this is not true.  The researchers at Harman Kardon
&gt;&gt; &gt;&gt; have
&gt;&gt; &gt;&gt; found that over 40% of people, even with careful training, cannot
&gt;&gt; &gt;&gt; reliably
&gt;&gt; &gt;&gt; distinquish even known differences in their training, and have to be
&gt;&gt; &gt;&gt; dropped
&gt;&gt; &gt;&gt; from any testing.

&gt;&gt; &gt; This is false. Harmon wasn't even training people to &quot;distinguish
&gt;&gt; &gt; differences.&quot; All of its subjects could *distinguish* the differences;
&gt;&gt; &gt; what they couldn't do was correlate those differences to specific
&gt;&gt; &gt; variations in frequency response. That is a much harder task, which is
&gt;&gt; &gt; why the failure rate, even after training, was so high. Anyone who's
&gt;&gt; &gt; read Sean Olive's work would understand this (assuming they wanted to
&gt;&gt; &gt; understand it).

&gt;&gt; So what does this say about the average music listeners ability to use
&gt;&gt; ABX
&gt;&gt; with NO training?

&gt; Nobody *needs* training to take an ABX test. The purpose of training
&gt; is to heighten the subject's ability to hear the difference being
&gt; tested. An ABX test tells you what you can hear right now, whether
&gt; you've had training or not. In particular, if someone claims he can
&gt; hear a difference between A and B, then he should need no training at
&gt; all in order to demonstrate that ability in a blind test. That he
&gt; usually can't do so merely proves he's a phony.
">

You ignore the fact that Harmon rejects over 40% of people as simply unable
to be consistent in the use of an ABX test.  Since obviously 100% of people
can listen to two components playing music, this means that USING THE ABX
TEST many people are inadequate to use the test.  It doesn't mean they are
phonys.  Nor does it mean they couldn't hear a difference using other tests.
Or using no tests.  All you can conclude is that USING THE ABX TEST, they
can hear no difference with any consistency. Even when there is one.  So in
using the test without knowing if there is a difference, if one "flunks" the
test, then one does not know whether that is because there is no difference,
or because one is not good at ABX'ng.  And this cannot be determined without
pre-screening.  You oversimplifications undermine any legitimacy to your
argument.

<QUOTE PREVIOUSPOST="
&gt;&gt; &gt;&gt; The test is as much a test of the listener as it is of
&gt;&gt; &gt;&gt; the items under test.  Moreover, both ABX and ABC/hr were developed
&gt;&gt; &gt;&gt; and
&gt;&gt; &gt;&gt; optimized specifically for codec testing,

&gt;&gt; &gt; .This is also false

&gt;&gt; Wishful thinking.

&gt; That ABX was developed to test codecs?
">

Telephone transmission compression, yes.  A forerunner.

<QUOTE PREVIOUSPOST="
- Hide quoted text - - Show quoted text -
">

<QUOTE PREVIOUSPOST="
&gt;&gt; &gt;&gt; where easily identifiable
&gt;&gt; &gt;&gt; distortions can be used at various levels of impact to &quot;train&quot;
&gt;&gt; &gt;&gt; listeners,
&gt;&gt; &gt;&gt; who then listen to the blind samples but &quot;knowing&quot; what they are
&gt;&gt; &gt;&gt; listening
&gt;&gt; &gt;&gt; for.

&gt;&gt; &gt;&gt; Open-end evaluation of audio gear does not work this way.  The human
&gt;&gt; &gt;&gt; brain
&gt;&gt; &gt;&gt; tries to relate the sound to a real sound, and doesn't even know
&gt;&gt; &gt;&gt; &quot;what&quot;
&gt;&gt; &gt;&gt; to
&gt;&gt; &gt;&gt; listen for...timbre, soundspace, subtles distortions, etc.  That seems
&gt;&gt; &gt;&gt; to
&gt;&gt; &gt;&gt; be
&gt;&gt; &gt;&gt; why the result of open-ended listening via ABX results in almost
&gt;&gt; &gt;&gt; immediate
&gt;&gt; &gt;&gt; listening fatique...it is a total unnatural use of the technique for
&gt;&gt; &gt;&gt; this
&gt;&gt; &gt;&gt; purpose.

&gt;&gt; &gt; This is idle speculation by someone who knows nothing about the
&gt;&gt; &gt; subject he's talking about. There isn't a shred of real evidence for
&gt;&gt; &gt; any of it. It's pseudoscience.

&gt;&gt; This is reality, as even people who desire to take the test often drop
&gt;&gt; out
&gt;&gt; before even 15 samples for this very reason.

&gt; Your whole paragraph was pseudoscience, not just the last bit of
&gt; nonsense. You're making everything up as you go along, Harry. As for
&gt; subjects dropping out from &quot;listening fatigue,&quot; I can cite you
&gt; numerous published studies where this did not happen. Can you cite any
&gt; where it did?
">

Anecdotally, in several efforts at testing here on usenet (not in this
forum) by people actively attempting to use the technique (not
subjectivists), yes.  Can I cite the posts, no....some of them were
seven-eight years ago.

<QUOTE PREVIOUSPOST="
&gt;&gt; &gt;&gt;  Put simply it violates the first cardinal principal of test
&gt;&gt; &gt;&gt; design...that is to prevent any aspect of the test from intervening as
&gt;&gt; &gt;&gt; a
&gt;&gt; &gt;&gt; variable.

&gt;&gt; &gt; Again, you haven't a shred of evidence that ABX or ABC/hr tests
&gt;&gt; &gt; interfere with perception in any way.

&gt;&gt; More evidence (admittedly anecdotal)  than has been presented to validate
&gt;&gt; that it works for open-ended evaluation of audio components.

&gt; You don't even know what &quot;open-ended evaluation of audio components&quot;
&gt; means. It's just a nonsense phrase you throw into every post because
&gt; you haven't any real arguments.
">

That is pure baloney.  I have defined it over and over and have done so just
recently.  You just don't want to acknowledge what it is, for there is no
way it can be accomodated in an ABX test.

<QUOTE PREVIOUSPOST="
- Hide quoted text - - Show quoted text -
">

<QUOTE PREVIOUSPOST="
&gt;&gt; &gt;&gt; ABX can be used for crude audio measures....volume, frequency shifts
&gt;&gt; &gt;&gt; in
&gt;&gt; &gt;&gt; white noise, etc.  As soon as it comes to listening to music,
&gt;&gt; &gt;&gt; sensitivity
&gt;&gt; &gt;&gt; decreases or disappears.

&gt;&gt; &gt; It is certainly true that it is easier to hear differences in level
&gt;&gt; &gt; and FR using test tones than using music. This has nothing to do with
&gt;&gt; &gt; any particular test. It has to do with the way the human hearing
&gt;&gt; &gt; mechanism works, and it is true no matter what listening method you
&gt;&gt; &gt; use.

&gt;&gt; To paraphrase, you haven't a shred of evidence that long term,
&gt;&gt; exploratory
&gt;&gt; tests
&gt;&gt; paired with short term comparisons doesn't overcome this limitation.  We
&gt;&gt; are
&gt;&gt; talking MUSIC, after all...not white noise.

&gt; We are talking masking. Something else you appear to know nothing
&gt; about. Do you honestly believe that masking doesn't happen when you
&gt; listen to music, Harry? Yes, I believe you do.
">

I believe masking happens when listening for differences in an ABX test.  I
also believe "sharpening" happens when listening in extended listening
tests, if one is a careful listener.   Music is not just "sound", a fact
that you and others ignore time and time again, at the expense of
undermining your own arguments.
</POST>
<POST>
<POSTER> "Harry Lavo" &lt;h...@hotmail.com&gt; </POSTER>
<POSTDATE> 2007-03-31T10:24:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;Steven Sullivan&quot; &lt;ssu ... @panix.com&gt; wrote in message
">

news:eujdft0v5p@news5.newsguy.com ...

<QUOTE PREVIOUSPOST="
&gt; Harry Lavo &lt;h ... @hotmail.com&gt; wrote:
&gt;&gt; &quot;bob&quot; &lt;nabo ... @hotmail.com&gt; wrote in message
&gt;&gt; news:euh8i102336@news5.newsguy.com ...
&gt;&gt; &gt; On Mar 28, 11:21 pm, &quot;Harry Lavo&quot; &lt;h ... @hotmail.com&gt; wrote:
&gt;&gt; &gt;&gt; Unfortunately, this is not true.  The researchers at Harman Kardon
&gt;&gt; &gt;&gt; have
&gt;&gt; &gt;&gt; found that over 40% of people, even with careful training, cannot
&gt;&gt; &gt;&gt; reliably
&gt;&gt; &gt;&gt; distinquish even known differences in their training, and have to be
&gt;&gt; &gt;&gt; dropped
&gt;&gt; &gt;&gt; from any testing.

&gt;&gt; &gt; This is false. Harmon wasn't even training people to &quot;distinguish
&gt;&gt; &gt; differences.&quot; All of its subjects could *distinguish* the differences;
&gt;&gt; &gt; what they couldn't do was correlate those differences to specific
&gt;&gt; &gt; variations in frequency response. That is a much harder task, which is
&gt;&gt; &gt; why the failure rate, even after training, was so high. Anyone who's
&gt;&gt; &gt; read Sean Olive's work would understand this (assuming they wanted to
&gt;&gt; &gt; understand it).

&gt;&gt; So what does this say about the average music listeners ability to use
&gt;&gt; ABX
&gt;&gt; with NO training?

&gt; What does it say about the average music listener's ability to correctly
&gt; identify difference in a sighted comparison?  There, one is compounding
&gt; a lack of training, with a surfeit of bias.
">

What it does is rely on the listeners ability to judge the natural sound of
music.  If the person is good at it, he will probably reach a valid
conclusion.  If he has a tin ear, he probably will reach a "no difference"
or "random difference" conclusion, both of which are okay for him.  But he
will judge based on music heard in a more natural way without any need to be
"trained".  And he can listen multidimensionally, rather than as a test
subject.

<QUOTE PREVIOUSPOST="
&gt; Yet that's the regimen used most commonly in audio equipment 'reviewing'.

&gt; Any wonder that the 'audiophile' is something of a joke?
">

And any wonder why the attempts to impose sterile and artificial tests are
mostly just simply ignored?
</POST>
<POST>
<POSTER> "Harry Lavo" &lt;h...@hotmail.com&gt; </POSTER>
<POSTDATE> 2007-03-31T12:34:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;Harry Lavo&quot; &lt;h ... @hotmail.com&gt; wrote in message news:...
">

"Steven Sullivan" &lt;ssu ... @panix.com&gt; wrote in message
news:eujh7d031ak@news3.newsguy.com ...

<QUOTE PREVIOUSPOST="
&gt; Harry Lavo &lt;h ... @hotmail.com&gt; wrote:
&gt;&gt; &quot;Steven Sullivan&quot; &lt;ssu ... @panix.com&gt; wrote in message
&gt;&gt; news:euh8ji0234l@news5.newsguy.com ...
&gt;&gt; &gt; Harry Lavo &lt;h ... @hotmail.com&gt; wrote:
&gt;&gt; &gt;&gt; &quot;William Eckle&quot; &lt;a ... @wmeckle.com&gt; wrote in message
&gt;&gt; &gt;&gt; news:epadnWEps7qydpfbnZ2dnUVZ_sWdnZ2d@pghconnect.com ...
">

snip, shortened to most relevant points&lt;

<QUOTE PREVIOUSPOST="
&gt;&gt; Sure you can.  You simply don't have to require 100% &quot;proof&quot; to make an
&gt;&gt; audio purchase.

&gt; Now you're moving the goalposts. I'm talking about establishing audible
&gt; difference, period,
&gt; not making purchasing decisions.  There was nothing about 'purchases' in
&gt; the stuff you quoted.
&gt; For the 10,000th time, no one says anyone 'has' to have 100% proof of
&gt; audible difference *to
&gt; make a purchase*.  But when people ask (perhaps in relation to a purchase,
&gt; perhaps not)
&gt; whether one piece of gear SOUNDS 'better' than another (implying
&gt; difference), or assert same,
&gt; they are making an assumption that either stands or falls based on
&gt; evidence.  And 'evidence'
&gt; from sighted comparison is inevitably prone to bias, whether the
&gt; comparison is 'open-ended' or
&gt; not.  If you're happy with that, fine, jsut don't act like  you've got
&gt; more than '50%' proof
&gt; for your claim.  If you do want to determine if *you've* heard a *real*
&gt; difference, then
&gt; you cannot get around the need for a blind comparison.
">

I am in agreement with this, but I would not use either ABX or ABC/hr as
that blind test, as I do not think they are the best possible for this
purpose, and have more limitations than simple blind a-b preference tests
or
extended listening blind monadic semantic rating tests.

<QUOTE PREVIOUSPOST="
&gt;snip again, for same reason&lt;

&gt; All audio comparisons, sighted or not, are affected by significant changes
&gt; in level.
&gt; And it is well-known from psychoacoustics that test signals can reveal
&gt; differences that are
&gt; masked by more complex signals.  So why single out ABX?  These effects
&gt; operate generally and
&gt; are well-known to people who advocate scientific standards of 'audio
&gt; reviewing'.  If there is
&gt; ignorance of these factors, it's more likely to be on the part of the
&gt; sighted-paradigm
&gt; advocates.
">

Because while objectivists disparage long term listening, it tends to offer
a way
around short-term masking effects.  And holistic focus on the music, as
opposed to "identification" also provides both a broader and a deeper
context or framework for evaluating the subtle modifications that equipment
might make in the natural reproduction of music.

Again if a persons involvment in music is limited, or they have no natural
frame of
reference of live acoustic music, then they are not likely to be good at
this.  But if they have the requesite experience they can be with patience.

<QUOTE PREVIOUSPOST="
&gt;snip again&lt;
">

I was just surprised that nobody did so.  So apparently the claim is not
beyond possible belief to these guys.

<QUOTE PREVIOUSPOST="
&gt;&gt; Moreover, the general consensus of the group (which included Jim Johnson
&gt;&gt; and
&gt;&gt; Dan Lavry) was that the CD cutoff was too low and artifacts were often
&gt;&gt; audible as a result, including pre-ringing and/or phase shift, and that
&gt;&gt; 64K
&gt;&gt; was the necessary minimum to avoid even the possibility of problems.

&gt; Doesn't sound like an *inherently* audible result of the technology to me.
&gt; I'm sure both Lavry and JJ are aware that technology can be implemented
&gt; well, or suboptimally.
">

Of course...but they are also aware that given the parameters chosen for CD
it is difficult if not impossible to mask all audible effects....and if
done
badly, for those effects to be blatantly obvious.

<QUOTE PREVIOUSPOST="
&gt;&gt; Please
&gt;&gt; note that this directly contradicts Arny's recent assertions here that
&gt;&gt; CD's
&gt;&gt; are audibly at the level of ultimate transparency(1), and that the
&gt;&gt; 66khz/20bit recommendation of the Japanese hi-rez group in the mid-90's
&gt;&gt; was
&gt;&gt; nothing but marketing-driven propoganda(2).

&gt; No, it doesn't contradict (1), as long as JJ and Lavry used a qualifier
&gt; like 'often' and Arny
&gt; didn't use the qualifier 'always' to mean that 'a CD is always transparent
&gt; to its
&gt; source'.  Which it appears he didn't.
">

I'm sorry, that is *exactly* what Arny said.  Read his quote below.

AK: March 19, "Cable Upgrade Solutions": "The CD format has always and
continues to prvoide sonically transparent
recording and reproduction of music."

<QUOTE PREVIOUSPOST="
&gt; Do Lavry and JJ claim that 16/44 simply *cannot* be transparent to source?
">

Yes, essentially JJ says for there to be no audible effect to younger men
and women, a "slope" bandwidth of at least 5k is needed on top of the 20khz
audible bandwidth, while CD only provides 2khz.  Lavry argues that 50khz
would probably be sufficient but that the 64khz requirment is real to
provide a practical margin, and that beyond that is excess (which justifies
his decision to limit his DACs to 88khz-96kh, rather than 192khz.)

<QUOTE PREVIOUSPOST="
&gt;snip, once again&lt;
&gt; Hilarious that you're now becoming a fan of Lavry and JJ.   I've been
&gt; reading their stuff for some years now.
">

I've had great respect for JJ for many years.  In fact, he was the one who
first (in a private message) put me onto the fact that the Panasonic 3700
DACs were terrible at 44.1khz at the time I indicated I was planning to buy
one.  Unfortunately, his stint at ATT ended before I could take him up on
an
offer to visit him to see the work he was doing on multichannel mic'ng over
in NJ.

Lavry I didn't know of until I began getting myself involved in digital
recording a few years ago...but there is general acknowledgement among the
pros that his DACs, along with the Benchmark and the Meitner, are the best
sounding ones in existance.  And now the audiophile community is pretty
much
coming to the same conclusion.

<QUOTE PREVIOUSPOST="
&gt; Btw, how did you access the Pro list?  I couldn't find it.
">

It is not obvious. Try www.pgm.com .
</POST>
<POST>
<POSTER> "Arny Krueger" &lt;a...@hotpop.com&gt; </POSTER>
<POSTDATE> 2007-03-31T12:37:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;Harry Lavo&quot; &lt;h ... @hotmail.com&gt; wrote in message
">

news:eujabf0t4l@news5.newsguy.com

<QUOTE PREVIOUSPOST="
&gt; &quot;bob&quot; &lt;nabo ... @hotmail.com&gt; wrote in message
&gt; news:euh8i102336@news5.newsguy.com ...
&gt;&gt; On Mar 28, 11:21 pm, &quot;Harry Lavo&quot; &lt;h ... @hotmail.com&gt;
&gt;&gt; wrote:
&gt;&gt;&gt; Unfortunately, this is not true.  The researchers at
&gt;&gt;&gt; Harman Kardon have found that over 40% of people, even
&gt;&gt;&gt; with careful training, cannot reliably
&gt;&gt;&gt; distinquish even known differences in their training,
&gt;&gt;&gt; and have to be dropped
&gt;&gt;&gt; from any testing.

&gt;&gt; This is false. Harmon wasn't even training people to
&gt;&gt; &quot;distinguish differences.&quot; All of its subjects could
&gt;&gt; *distinguish* the differences; what they couldn't do was
&gt;&gt; correlate those differences to specific variations in
&gt;&gt; frequency response. That is a much harder task, which is
&gt;&gt; why the failure rate, even after training, was so high.
&gt;&gt; Anyone who's read Sean Olive's work would understand
&gt;&gt; this (assuming they wanted to understand it).

&gt; So what does this say about the average music listeners
&gt; ability to use ABX with NO training?
">

What does this say about anybody's ability to reliably hear differences with
or without training?

As usual we see a post that tries to blame the problems of the world on ABX.
One core problem is the horrific propensity of sighted evaluations to
product false positives. If the number of positive results that is used to
judge is based on a listening methodolgy that spawns false positives like
pregnant pacific salmon produce eggs, what can compete?

<QUOTE PREVIOUSPOST="
&gt;&gt;&gt; The test is as much a test of the listener as it is of
&gt;&gt;&gt; the items under test.
">

True of any listening test involving subtle differences, or even differences
that aren't glaringly obvious.

<QUOTE PREVIOUSPOST="
&gt;&gt;&gt;  Moreover, both ABX and ABC/hr
&gt;&gt;&gt; were developed and optimized specifically for codec
&gt; &gt;&gt; testing,
&gt;&gt; .This is also false
&gt; Wishful thinking.
">

No factually wrong. ABX was developed and popularized before testing codecs
was a serious business. Back in the middle 1970s, MP3 was 20 or more years
in the future.

<QUOTE PREVIOUSPOST="
- Hide quoted text - - Show quoted text -
">

<QUOTE PREVIOUSPOST="
&gt;&gt;&gt; where easily identifiable
&gt;&gt;&gt; distortions can be used at various levels of impact to
&gt;&gt;&gt; &quot;train&quot; listeners, who then listen to the blind samples
&gt;&gt;&gt; but &quot;knowing&quot; what they are listening
&gt;&gt;&gt; for.
&gt;&gt;&gt; Open-end evaluation of audio gear does not work this
&gt;&gt;&gt; way.  The human brain
&gt;&gt;&gt; tries to relate the sound to a real sound, and doesn't
&gt;&gt;&gt; even know &quot;what&quot; to
&gt;&gt;&gt; listen for...timbre, soundspace, subtles distortions,
&gt;&gt;&gt; etc.  That seems to be
&gt;&gt;&gt; why the result of open-ended listening via ABX results
&gt;&gt;&gt; in almost immediate
&gt;&gt;&gt; listening fatique...it is a total unnatural use of the
&gt;&gt;&gt; technique for this purpose.
&gt;&gt; This is idle speculation by someone who knows nothing
&gt;&gt; about the subject he's talking about. There isn't a
&gt;&gt; shred of real evidence for any of it. It's pseudoscience.
">

Especially given that "open-ended" listening is whatever Harry wants it to
be today.

<QUOTE PREVIOUSPOST="
&gt; This is reality, as even people who desire to take the
&gt; test often drop out before even 15 samples for this very
&gt; reason.
">

No foundation has been laid  for this claim.

<QUOTE PREVIOUSPOST="
&gt;&gt;&gt;  Put simply it violates the first cardinal principal of
&gt;&gt;&gt; test design...that is to prevent any aspect of the test
&gt;&gt;&gt; from intervening as a variable.
&gt;&gt; Again, you haven't a shred of evidence that ABX or
&gt;&gt; ABC/hr tests interfere with perception in any way.
&gt; More evidence (admittedly anecdotal)  than has been
&gt; presented to validate that it works for open-ended
&gt; evaluation of audio components.
">

Keys words "admittedly anecdotal".  IOW there's nothing but unsubstantiated
stories to back it up. As other posters have said, urban legends, but in
this case urban legends know to only one person.

<QUOTE PREVIOUSPOST="
&gt;&gt;&gt; ABX can be used for crude audio measures....volume,
&gt;&gt;&gt; frequency shifts in white noise, etc.  As soon as it
&gt;&gt;&gt; comes to listening to music, sensitivity decreases or
&gt;&gt;&gt; disappears.
&gt;&gt; It is certainly true that it is easier to hear
&gt;&gt; differences in level and FR using test tones than using
&gt;&gt; music. This has nothing to do with any particular test.
&gt;&gt; It has to do with the way the human hearing mechanism
&gt;&gt; works, and it is true no matter what listening method
&gt;&gt;  you use.
&gt; To paraphrase, you haven't a shred of evidence that long
&gt; term, exploratory tests
&gt; paired with short term comparisons doesn't overcome this
&gt; limitation.  We are talking MUSIC, after all...not white
&gt; noise.
">

What is an exploratory test?

I have an idea of what an exploratory test is, and it no way does it
conflict with the use of ABX, ABC/hr or whatever.

<QUOTE PREVIOUSPOST="
&gt;&gt;&gt; This isn't just speculation....review the
&gt;&gt;&gt; Greenhill tests in Stereo Review (search index at their
&gt;&gt;&gt; site).
&gt;&gt; Where you won't find it. But if anyone wants to read
&gt;&gt; what Greenhill actually found (rather than someone's
&gt;&gt; re-invention of it), e-mail me and I can send you the
&gt;&gt; article.
">

Agreed, I believe I have the text of those tests on my hard drive.

<QUOTE PREVIOUSPOST="
&gt; And if you wish to email me I can send you an accurate
&gt; and complete Excel table of the results.
">

Seems like rehashing just one test done about 20 years ago is pretty
senseless, anyhow.

<QUOTE PREVIOUSPOST="
&gt;&gt; Harry is peddling pure pseudoscience here.
&gt; You've heard from a true ABX believer.
">

Who might that be?

<QUOTE PREVIOUSPOST="
&gt;  Ask for the
&gt; validation test that this technique, developed very
&gt; specifically for codec distortions, works as the best
&gt; tool for open-ended evaluation of audio components.
">

This is nonsense. ABX predates codec tests by about 20 years. I won't say
that there weren't codecs way back then, but the ones that provided
meaninful amount of compression had so many audible faults that they were
only proposed for use with telephones, not hifis.
</POST>
</TEXT>
</BODY>
</DOC>
