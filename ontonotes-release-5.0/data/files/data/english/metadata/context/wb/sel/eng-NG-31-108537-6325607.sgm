<DOC>
<DOCID> eng-NG-31-108537-6325607 </DOCID>
<DOCTYPE SOURCE="usenet"> USENET TEXT </DOCTYPE>
<DATETIME> 2007-01-20T21:05:00 </DATETIME>
<BODY>
<HEADLINE>
investigation, definitions &amp; logic
</HEADLINE>
<TEXT>
<POST>
<POSTER> "g" &lt;gillaw...@earthlink.net&gt; </POSTER>
<POSTDATE> 2007-01-20T21:05:00 </POSTDATE>
Ask a few people what "forensics" means, and (thanks to certain gory TV
dramas that spoil your appetite right in the middle of your evening meal, if
you eat in front of the tube, that is) most of them will say that it has to
do with
solving murders, using scientific knowledge and tools.

Now here is a published definition {Houghton-Mifflin e-edition, the American
Heritage (copyright) Dictionary of the English language:

1. The art or study of formal debate; argumentation.

2. The use of science and technology to investigate and establish facts in
criminal or civil courts of law.

Notice two things about it:  a.  The most prevalent usage (at least, until
the TV shows) has to do with formal debate (which has a colon after it,
meaning start over again); and it has to do with argumentation.  If any
reader believes that formal debate or argumentation generally, deals in
formal logic... no, no, no, no, no...  The formal part applies to a
structuring of how people should behave during a debate.

A whole section in a library could be devoted to what the *ART* of
argumentation is all about, and I could copy and paste a few thousand words
here quoting in copious detail from Dr. David Zarefsky, one of the world's
foremost thinkers and teachers on it.  But let me just say that merely the
citing of all the credentials, and awards, and positions Dr. Zarefsky has
accumulated would make this message far too long. Latest info I have on him
had him at Northwestern U. (Evanston, Ill.), where he was Owen L. Coon
Professor of Argumentation and Debate and professor of Communications
Studies.  And, also, he has served as President of the National
Communications Association (one of the oldest and most respected in the U.
S.) and is a former editor of the journal 'Argumentation and Advocacy.'

Therefore, some of the assertions I shall make on the subject of the nature
and limitations on this thread...  my actual intent to make a number of
"observations" concerning THE  DOING  OF  SCIENTIFIC  INVESTIGATION,  AND
THE ORGANIZATION  AND  INTERPRETATION  OF DATA SO DERIVED... rely upon
*INFORMAL  LOGIC* more than on formal logic.  Let me unravel the assertion
by making a sweeping statement {at least I didn't just jump up and fling a
generalization at you without building ramping up to it (:&lt;)}
To wit:  Formal logic is useful in programming computers and applying
formulas that have been worked out by such great synthesists as Newton,
Einstein, to some calculations.  But formal logic is something controlled
from outside.  (So if this sounds like something John Edser has maintained,
then get used to it.  Dr. Zarefsky would back him up all the way on this
point... though not on all "the Edser's" points, I suspect.)

Oh, the "subject" caption of this thread didn't say that.  But the reason is
that it would not fit the space alloted.

Okay, enough for this first, merely INTRODUCTORY, message on this new
thread.  So let me end with a flat out
summary statement:

Formal logic is one tool (among many) useful in some narrowly confined and
controlled applications within the work or scientific investigation and
interpretation.  (And in at least one subsequent message I shall address how
formal logic ONLY feeds back to the user the ASSUMPTIONS fed into it, and
additional computations derivable only pursuant to THOSE assumptions.)

(To be continued)

g
</POST>
<POST>
<POSTER> "g" &lt;gillaw...@earthlink.net&gt; </POSTER>
<POSTDATE> 2007-01-20T21:05:00 </POSTDATE>
This is the SECOND  MESSAGE:

Let me address a few of the reasons why INFORMAL  LOGIC is what we humans
are constrained to rely upon in the process of what literally is (by the
second part of the American Heritage (c) definition) of *FORENSICS*.  But
first let me sew together this message with the first one by saying that
definition (1) and definition (2) (see first message) are not unrelated to
one another.  If this is not clear from what is written so far in this
thread, it shall become much clearer, as the thread progresses.

First of all, pure logic (synonymous with pure mathematics) is -- for
purposes of evolutionary biology forensics (EBF) -- one of the more valuable
tools, but totally useless by itself alone.  Will not even attempt to
exhaust the reasons why, but here are just a few:

1.    To arrive at any kind of meaningful investigatory data about any
natural thing or process or dimension (or any other way "reality is
expressed" ) we must first observe some natural things and happenings and
get some ideas about it.  While those ideas may seem to be quite obvious to
us, we know that any brained animal infant, if deprived of most sensory
stimulation, will not become "hard wired" as it were to make much sense of
any stimuli thereafter.  The evidence compelling that has been obtained from
experimentation with non-human species, except for instances where such
deprivation in a human infant is caused by circumstances outside a
researcher's control.
An abundance of evidence, both circumstantial and direct, converges upon
this forensic "conclusion."

2.   Hence, our human reason can literally be said to be ABSOLUTELY
DEPENDENT upon having some kind
of interaction with at least some portion of reality providing some
consistencies of sensory experience.  Most things successfuly pushed out of
the confines of a baby bed go downward if they are not sufficiently
supported by something below; although until the infant senses (sees) the
something below, they might go downward but not
all the way to the bottom of things (floor).  But then again... once in a
while something seems to tend to go up (a fly; a helium-filled balloon or a
balloon slapped upwardly with a hand.  A kitten with eyelids taped shut for
the first several weeks of its life my experience light, but is likely to
run into things like table legs, and never be able to
figure out to go to the right or to the left to avoid it.  Hopefully these
are enough alusions to examples, although they fall far short of explaining
all that is "known to" or "quite abundantly assumed by and agreed among"
physiologists, psychologists, pediatricians, parents...

3.   Notice that many, if not MOST, sensory experiences are NOT of a
binomial or polemical nature.  Much experience is unpredictable and
statistical.  MOST things dropped go down.  SOME go up.  Being able to make
some crude sense of this does not require completion of a course in
probability.  It can be approximated by something akin to what rifle hunters
of wild game, and target shooters, call "Kentucky windage."   We must not
think of it as too extremely crude, however, because the ability to estimate
by some expert shooters, to allow for
the effect of wind on a bullet enroute to a target, are amazingly accurate.
And some professional basketball players make a high percentage of
strip-hoop shots from the three-point areas of a basketball court.  It is a
challenge for us even to design and construct a machine that accurate.  But
a "sense" of statistical phenomena is "learned" from reality.  It is a
conformity (improved by intent and by practice) of the brain with reality.
(And I avoid using the word "adaptation" in this context, because that word
has become LOADED with intellectual baggage that would
distract from the message here, rather than help to clarify it.

4.    Even a human who has become very "indoctrinated" as an infant, by what
we could call "reality's general rules and their scopes and their
statistical natures, " can become severely stressed and disoriented by
sensory deprivation, (vis a vis experiments in the prior century, in which
humans were put into situations approximating total darkness, zero gravity,
temperature invariant from subject's body's own internal control, zero
sound, zero odors).  All experimental parameters were virtual, of course, as
it is quite impossible to deprive 100 % of every last vestige of external
stimuli.  These simulations, if prolonged, resulted in a subjects hearing
his/her own blood pumping, in loss of physical bearings,  in auditory and
visual and tactile hallucinations, and in some instances in a temporary form
of "insanity" in which the research subject becomes uncertain whether the
real world even remained out there waiting for the experiment to be over...
and uncontrollable panic set in.  I seem to recall reading that some
research subjects never fully got over the traumatic experience, and
required treatment for something akin to what nowadays is termed post
traumatic stress disorder.  So, it is clear to see that we humans are
addicted to our sensory stimuli which we require to keep us psychologically,
philosophically and physiologically oriented.  (Astronauts must train
intensively to prepare for, and require a lots of reminders of, their
connections with, and participation in, a familiar "reality."  And, for
reasons not clearly understood, by me at least, victims of brain
debilitating diseases -- although they be unable to store any conscious
memory of any structure in their lives, fair far better in institutional
inviornments which provide consistency as, for example, in what times they
eat, what time certain things are done for them, where they sit at a dinner
table, familiar (???) faces ...etc.)

5.    (We've barely scratched the surface here... but these points are
sufficient, hopefully, to demonstrate that there seems to be compelling
evidence that we humans reason in large part as conditioned by the "reality"
we are "plugged into," and do not get along well if unplugged from it.)

Again... there is so much argumentation (informal) required to bring the
primary points to be established here... that messages must not become to
elongated.  (Also, this is first draft attempt, so please bear with...)

In first message, plus this one, we have seen (I hope) some things which are
only prepatory background for points
most desired to be gotten at...  However, hopefully I have brought us to the
point at which a generality can be made
based upon all so far... namely:  Formal logic, requires defined terms,
postulates, operations... and is a useful tool.  Let us STIPULATE that pure
mathematics, also known as pure logic, also known in particular models as
logic systems, also known as simply "mathematics" processes only WHAT  WE
PUT  INTO  IT.  It can be, and is pursued by some humans, FOR  ITS  OWN
ENJOYMENT, without having to be applied to anything.  However, it also is a
useful tool for dealing with SOME aspects of "reality."  We humans are
hampered in sensing or processing with our brains ALL of reality or, for
that matter, of measuring and grasping with absolute certainty or accuracy
the whole of reality.  Our experience with reality is "learned" through
imperfect sensory abilities and is processed with something akin to
"statistical Kentucky windage;" and just ONE of the things we humans are
CONFINED by is our own ability to experience everything, all the time, and
process all the information even if we
COULD.

Hopefully these ASSUMPTIONS are sufficiently explained so far to enable us
to adopt them, if only for purposes, of seeing where these messages are
heading, in making some points this layman would like to pose for your
CONSIDERATION toward the end of this thread.

(To be continued)

g
</POST>
<POST>
<POSTER> "g" &lt;gillaw...@earthlink.net&gt; </POSTER>
<POSTDATE> 2007-01-20T21:05:00 </POSTDATE>
Third message

If this layman has appeared to dangle something about empiricism, and then
to snatch it away, then let us recall the example of the baby seeing most
things fall "toward" the floor, if not prevented from doing so, while on
occasion some things fly or float upward.  This is an *APPARENT  PARADOX* if
one has no underlying experience wherewith to figure out that flies have
apparati that enable them to go upward as well as in other directions... and
to figure out that ONE of the differences among the various items on the
Periodic Table of Elements is their variable specific gravity and duhhhh,
there's this stuff called "air" which, at certain elevations in relation to
sea level has an aggregate specific gravity among its constituents which is
greater than that of the aggregate of the parts of a thin-skinned rubber
balloon with helium or hydrogen in it.  (And we even know today that it is
not a good idea
to fill toys with the latter, because it is so flammable.  Then, too, we
humans have some sort of opinionation about babies that we should nurture
and protect them... although there is no empirical PROOF that we should.

So do we have a paradox when we combine the following two assumptions:

1.  That we humans get our notions experientially, from our "exposure to
reality"; AND,

2.  Our sensory capabilities are INSUFFICIENT for us to measure each and
every iota of the small intersection we
have with reality as an entirety?

It does not require -- it seems to this layman -- that we need to be a
"genius" of the Bertrand Russellian variety to
see that this is NOT a juxtaposition of irreconcilables but a combining of
two viable ideas in accordance with some understanding of what are some, at
least, of the pertinent underlying facts... no less so than for us to
reconcile the fact that some things seem to fall while some things appear to
rise, sometimes.

Forgive me if I seem to border on an unprovable assumption when I insert
here (it would be a footnote, if this were a formal paper) that I,
personally, assume that when MORE  DETAILS have been exposed in the matter
of the
"APPARENT  PARADOX" between Newtonian and Quantum physics, then someone who
is not a Bertrand Russellian-style genius will not have to see those two as
irreconcilable, either.  However, as this layman tries consistently to
preach others should do, this layman both RECOGNIZES AND EMBRACES the
possibility that,
such details shall not be attained, or not in my lifetime and yours, or not
ever... and ALSO the possibility that there simply is a levels-based
difference in how things work.

Not wishing to get too far off into physics and photographical realism, but
let us consider the very REAL fact that we could commission an artist to
place a grid over a picture that we in the U. S. normally consider to be a
recognizable picture of George Washington and -- using those pictures of
Abraham Lincoln as pixesl, arrange them on that grid.  From high up in the
air, we would "see" the face of George Washington, although when we came
down to Earth we would see thousands of pictures of Abraham Lincoln.  Now
some who would deem themselves to be logical, encounter situations such as
this and discern them to present a *PARADOX*, as would be implied by the
question, "Who IS it a picture of, then?" ... followed perhaps by the
question, "How can it be both the one and the other, when they are not the
same.

In  EITHER  SCENARIO, this layman does not perceive that there NECESSARILY
consists in the difference between Newtonian and Quantum mechanics an
unfathomable mystery.  But, if a highly touted physicist were to wish to
perceive it so, I would not feel guilty about saying I respectfully
disagree, and am more than willing to be persuaded when, and after, more
underlying details are on the table... if I should live so long.

My studied (far from casual) *STANCE* then -- and only tentatively so -- is
that there are no paradoxes in reality... but only *APPARENT  PARADOXES*
arising from our human propensity (and reasonably as it is) to plug into
some formal logic models... or impressionistic (Kentucy Windage-type models)
the best we can come up with at any given time.  And, at THIS particular
given time, the models grind, and grunt, and remain consistent, and crank
out a "picture" that, for us, is an *APPARENT  PARADOX* (or a gross
contradiction of nature, by nature, and for nature... which somehow is
not -- for this dumb old layman -- "intellectually satisfying."

Okay... enough, once again, for one message.

(To be continued...)

g
</POST>
<POST>
<POSTER> "John Edser" &lt;e...@ozemail.com.au&gt; </POSTER>
<POSTDATE> 2007-01-22T15:02:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;g&quot; gillaw ... @earthlink.net wrote:-
&gt; So do we have a paradox when we combine the following two assumptions:

&gt; 1.  That we humans get our notions experientially, from our &quot;exposure to
&gt; reality&quot;; AND,

&gt; 2.  Our sensory capabilities are INSUFFICIENT for us to measure each and
&gt; every iota of the small intersection we
&gt; have with reality as an entirety?
">

JE:-
We cannot claim to know what we do not know so that incompleteness cannot be
claimed to be total unknown otherwise we could not know anything remains
incomplete. What we mean when we claim to understand what we do not know is
that a better theory enables us to see the limitations of a poorer theory.
This was proven by the evolution of Newton to Einstein. The poorer theory
was Newton's because it could not explain the Michelson Morley result. No
matter how incomplete the measure of the velocity of light happened to be
within this experiment it remained _complete enough_ to refute Newton which
was the only theory that was on the table at the time. Apart from ideas
evolving via free and fair contests to refutation our ability to measure
them more exactly likewise evolves. The evolution of any idea depends
entirely on our (non mechanical) inductive imagination and our integrity to
test them. The more I think about it the more I have come to realize that
the latter is the hardest bit. Arguing that the Michelson Morley measure of
c was not perfect or that millions of other entirely unknown theories may
have been be able to explain things remain only so much pie in the sky.
Science can only deal in practical realities in an entirely empirical way.
All that is required is sufficient rigor to separate and test ideas no
matter how incomplete ANYTHING is. It was Newton who provided the critical
stepping stone for Einstein who used his inductive genius to view old things
in entirely new ways WHILE REMAINING REFUTABLE. Anybody and their cat can
come up with "better" irrefutable ideas! In the future Einstein will provide
a stepping stone for somebody else who will also see old things in new ways
as well as new things which nobody can even imagine but only as long as each
stepping stone remains refutable. Irrefutable stepping stones lead to
everywhere so they lead to nowhere.

<QUOTE PREVIOUSPOST="
&gt; It does not require -- it seems to this layman -- that we need to be a
&gt; &quot;genius&quot; of the Bertrand Russellian variety to
&gt; see that this is NOT a juxtaposition of irreconcilables but a combining of
&gt; two viable ideas in accordance with some understanding of what are some,
&gt; at
&gt; least, of the pertinent underlying facts... no less so than for us to
&gt; reconcile the fact that some things seem to fall while some things appear
&gt; to
&gt; rise, sometimes.
">

JE:-
Without refutability science becomes reduced to politics.

<QUOTE PREVIOUSPOST="
&gt; Forgive me if I seem to border on an unprovable assumption when I insert
&gt; here (it would be a footnote, if this were a formal paper) that I,
&gt; personally, assume that when MORE  DETAILS have been exposed in the matter
&gt; of the
&gt; &quot;APPARENT  PARADOX&quot; between Newtonian and Quantum physics, then someone
&gt; who
&gt; is not a Bertrand Russellian-style genius will not have to see those two
&gt; as
&gt; irreconcilable, either.
">

JE:-
Quantum physics represents a verified statistical view of nature, i.e. it is
just an observation waiting for a theory and not a theory of science in its
own right. The only value that mathematically based statistics has for the
sciences is to provide a probability frame of reference to measure when an
observation can _reasonably_ claim to have been made.

<QUOTE PREVIOUSPOST="
&gt; However, as this layman tries consistently to
&gt; preach others should do, this layman both RECOGNIZES AND EMBRACES the
&gt; possibility that,
&gt; such details shall not be attained, or not in my lifetime and yours, or
&gt; not
&gt; ever... and ALSO the possibility that there simply is a levels-based
&gt; difference in how things work.
">

JE:-
Popper quantified it. All that is required is at least ONE sufficiently
complete empirical observation which can refute the idea. Unfortunately it
is this which remains the focus of increasingly intense political activity
within the sciences as purveyors of mediocre irrefutable ideas attempt
any-ruse-that-they-can-muster to allow their views entry as valid science.
The latest weapon in their (considerable) arsenal is their utter misuse of
valid mathematical tautologies employed to bamboozle the keepers of the gate
to allow entry. Please refer to "Felsenstein's Paradox" which remains
exclusive to sbe as a classic example. Ask yourself why Felsenstein's
Paradox remains evaded here and why I am forced to endure continuous
vilification only because I loudly state that this remains the case and
insist that it HAS to be solved if evolutionary theory is to remain credible
in the eyes of the general public.

Amazingly, even the gates of commercial rationality were breached via the
Enron scandal in which accountants actually wrote up debits as credits. The
only possible way this can be done with any arguable validity is via an
accounting tautology of mathematics. Ring any bells?

Regards,

John Edser
Independent Researcher

e ... @ozemail.com.au
</POST>
<POST>
<POSTER> "g" &lt;gillaw...@earthlink.net&gt; </POSTER>
<POSTDATE> 2007-01-22T15:02:00 </POSTDATE>
FOURTH  message:

Reader, please be aware of the following important issues concerning the
messages on this thread:

1.  They have not turned up on the web site in order sent by poster.  The
SEQUENCING of them, as submitted, is important; and the FIRST message is not
identified as such in the text.  All messages of the series other than the
first one, however, are labeled in the text as to where they fit in the
sequence;

2.  These are first drafts, and contain some typo errors, some homonymic
errors (spellings of sound-alikes, which can be misleading), incomplete
sentences.  Sometimes letting ideas flow as they will, communicates more
clearly than overly "structured" words, robbed of spontaneity;

3.  Concepts simple and perhaps obvious, early on, must be clearly in place
before some of the more advanced concepts, in later messages, will be clear.
Many of the most complex ideas in this world are constructed out of
simple and perhaps obvious parts, pulled together into forms which, unless
one has the earlier, simple ones clearly in place, can SEEM to be remote,
counter-intuitive, or tangled.  Taken one by one, very clearly, and THEN
combined, some of the ideas to come farther along, will make a lot of sense.
So far the ideas are little more to what bricks are to the construction of a
good house.

Now on with the materials for the ultimate construction:

DEFINITION  ISSUES

Ask a small child what a skate is, and the child may look at you as if you
were pretty silly.  A skate is a SKATE, for crying out loud.  There is one
right there in the corner, stupid.  But if we think about it, the child
realizes something adults sometimes tend to forget.  Namely, we humans have
lots of common sensory experiences that we can communicate about; and the
defining of a material object is as simple as cuing one another to a word we
have learned to associate with that common experience.  Remove the common
experience, however, and DEFINING becomes difficult if not downright
impossible.

NOTHING  CHANGES about the underlying issues involved in the *defining of
things* as one grows up from childhood to adulthood, even if we train for,
and become, an expert at something such as one of the sciences.  We remain
*EXPERIENTIALLY  DEPENDENT* in both our private thinking and our
communications with others.  If we want to teach a child what blue is, all
we have to do is provide the common experience, state a conventional name
for that experience and, assuming the child is fairly normal and in
possession of all the normal and usual human faculties we take for granted,
we have gotten the job done.  But that is NOT defining.

If we were capable of DEFINING  BLUE, then we could recite our "definition"
to a child who was born totally blind, and the child would know EXACTLY what
blue is.  Also... and this is a very, very important point that will be
aluded to in a more complex setting, later in these messages... we cannot be
sure that what the totally blind-from-birth child sees in his/her mind is
exactly what we have defined, in defining "blue."

Yes, this is simple and obvious at the simple and obvious level; but
sometimes it gets forgotten -- as do lots of simple and obvious things -- by
some very "advanced thinkers."  So, let's you and me not forget our
experiential dependence in the defining of things, when we get to some
complex issues.  Okay?  Great.

Now we can move on to our human ability to conceive of... think in terms
of... and communicate with one another about... abstract things.  Here our
"dependence" upon common experience becomes indirect.  For example, how
would we define the concept of frustration?  Well, its obvious.  We have
all... no, wait, that's not right... not all... okay MOST of us... have
experienced frustration.  As a child grows up and feels frustration a good
understanding parent can point out to the child that the child appears to be
feeling frustration.  In this scenario we cannot point to an object like a
skate in a corner or to something we and the child experience as blue.
Neither can we draw a picture of frustration.  Neither can we directly sense
frustration in another.  We merely ASSUME that what a child is experiencing
on basis that the child APPEARS to have the same kind of look on his/her
face that we have when we feel frustrated and is expressing by way of body
language what we feel when we are frustrated.  And, also, we can reflect
upon the fact that when we want something very much, and very much NOW, and
are convinced that we "should" have it, and that having it is not
impossible... we can sense that this scenario for the child is one which
leads us to form similar facial expressions and body language.  But if we
were to encounter an individual who feels no emotion, and wished to define
for that person what "frustration" is, how would we define it?  An autistic
child may entertain itself by waving its hand between it's eyes and a light
source.  If we restrain that child's hand, the child may exhibit some
vocalizations and body language we associate with what WE feel, when we feel
frustration.  And this is not to say that the autistic child in this
situation does not feel the same emotional set that we do when caught in a
traffic jam, when we are driving to a lunch engagement with someone we
really, really enjoy being with.  But how do we DEFINE it, even if we are a
professional psychiatrist, EXCEPT in terms of some common experiencial
reference.

Now let us go back and bring forward the concept of "Kentucy windage" and
see how it applies to our "experiencing" of the color blue.  We do not see
anything which *IS* blue.  What we experience *AS* blue is
a reflection of a certain narrow band of wave lengths that trigger certain
things to happen in our eyes, which trigger certain things in our brains
....etc.  Is this boring?  Has it been too oft repeated.  Is it something we
generically refer to as something "everybody knows?"  What if we come across
some theoretical constructs that seem to have been formulated in which the
principle of it appears to have been FORGOTTEN.  Not yet.  But we may get to
an example later on in these messages...  Let's you and me not be guilty of
forgetting it.  Okay?  It may turn out to be very important later on.

And, enough for this message...

g
</POST>
<POST>
<POSTER> "g" &lt;gillaw...@earthlink.net&gt; </POSTER>
<POSTDATE> 2007-01-22T15:02:00 </POSTDATE>
WARNING -- Taken message by message, in the order written, nothing in these
messages will be difficult to follow.  When one walks up an inclined plane
(or a stepped inclined plane, such as a stairway to the top of a tall
building) the amount of work required for any one step upward is the same.
If one tries to jump from floor to floor, and something does not seem to
make sense, the writer should not be blamed.

FIFTH  MESSAGE

There is no such thing as "the definition of" any natural thing.

Now, if you do not wish to accept that statement as valid, feel free to
disagree.  But keep an open mind as this old layman seeks to explain why the
best science has, at any juncture, is one or more *trial definitions*.

In prior messages we spoke of a baby's being able to get some kind of sense
about what we call gravity (as in, most things go down if allowed to, most
of the time, but not always).  But adults know what gravity "is."  Right?
Wrong.  Not even Albert Einstein knew what gravity "is," for sure.  He gave
a good shot to forming a synthesis about it; but he did not come up with
"the" theory of gravity.  He came up with "the best so far" theory of
gravitation, but not "the" (as in ultimate, final, perfect, unimprovably or
even 'right') theory of gravitation.  Is that a detraction?  Heck no.  But
an important point for us (as we ramp upward from some simple and obvious
little things to some things about scientific inquiry that even some very
smart people seem to forget) is there is not yet
"the" theory of gravitation.

Someone might seek to excuse highly educated, or advanced, thinkers for
saying one thing and meaning another.
But this layman objects to our excusing anyone for it and strongly believes
that it leads for the more highly educated, or researched advanced, to their
being MISUNDERSTOOD.  And, also, this layman has seen evidence that, after a
while, a person who talks about the latest, or most widely accepted or
currently best theory of anything as though it were "the" theory of it,
tends sooner or later to internalize an assumption that it IS "the"
theory... that it is beyond considering tentative, that it is ridiculous for
any other researcher even to run experiments to check out the feasibility of
a different theory.  You and I must not allow ourselves to forget the simple
and obious things that beginners should understand, even if we climb to
higher levels of learning and thinking, investigating.

Hopefully any and every reader will agree that "good investigation" --
whether in science, philosophy, law enforcement, or any other kind of
process of "finding things out" -- has some *PRINCIPLES  IN  COMMON.*
And nothing... repeat NOTHING... throws a bigger monkey wrench into any
"investigation" than an assumption that we already know that our favorite,
or best theory at any given time is "the" theory.  From the moment we do
that, we are either dead in the water of finding out anything contrary to it
or, worse yet, so preoccupied with building a case around an ASSUMPTION,
that we don't have time for any testing of other reasonable assumptions.

Now highly advanced scholars don't do that, do they?

Well, yes, this old layman sees some rather flagrant instances of it, he
perceives.  But examples now might not seem obvious or important to you.
What say we just stick with taking one as-simple-and-obvious-as-can-be-made
step at a time and perhaps it will not even be necessary for this old layman
to point out examples.  You may find yourself reading, seeing, hearing clues
going on within your own awareness horizons (such as they may be) on a daily
basis... assuming you do not already...

Enough for this message.  In the next one we will take a look at some things
you may or may not already know about calculations (logical problem solving
techniques) and algorithms (also logical, but conforming calculations to
things a machine can do).

g
</POST>
<POST>
<POSTER> "g" &lt;gillaw...@earthlink.net&gt; </POSTER>
<POSTDATE> 2007-01-22T22:25:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&gt; JE:-
&gt; We cannot claim to know what we do not know so that incompleteness cannot
&gt; be
&gt; claimed to be total unknown otherwise we could not know anything remains
&gt; incomplete. What we mean when we claim to understand what we do not know
&gt; is
&gt; that a better theory enables us to see the limitations of a poorer theory.
&gt; This was proven by the evolution of Newton to Einstein. The poorer theory
&gt; was Newton's because it could not explain the Michelson Morley result. No
&gt; matter how incomplete the measure of the velocity of light happened to be
&gt; within this experiment it remained _complete enough_ to refute Newton
&gt; which
&gt; was the only theory that was on the table at the time. Apart from ideas
&gt; evolving via free and fair contests to refutation our ability to measure
&gt; them more exactly likewise evolves. The evolution of any idea depends
&gt; entirely on our (non mechanical) inductive imagination and our integrity
&gt; to
&gt; test them. The more I think about it the more I have come to realize that
&gt; the latter is the hardest bit. Arguing that the Michelson Morley measure
&gt; of
&gt; c was not perfect or that millions of other entirely unknown theories may
&gt; have been be able to explain things remain only so much pie in the sky.
&gt; Science can only deal in practical realities in an entirely empirical way.
&gt; All that is required is sufficient rigor to separate and test ideas no
&gt; matter how incomplete ANYTHING is. It was Newton who provided the critical
&gt; stepping stone for Einstein who used his inductive genius to view old
&gt; things
&gt; in entirely new ways WHILE REMAINING REFUTABLE. Anybody and their cat can
&gt; come up with &quot;better&quot; irrefutable ideas! In the future Einstein will
&gt; provide
&gt; a stepping stone for somebody else who will also see old things in new
&gt; ways
&gt; as well as new things which nobody can even imagine but only as long as
&gt; each
&gt; stepping stone remains refutable. Irrefutable stepping stones lead to
&gt; everywhere so they lead to nowhere.
">

John,

I understand, and to some extent concur with, the importance of the *ROLE
OF  REFUTABILITY" in "good" scientific investigation and hypothesization.
What I am trying to do in these messages is break down some concepts, and
issues, to a level at (and even below) the entry-level student... but also
IMPORTANT  TO a professional researcher, a post graduate, or particularly to
one who would do the WONDERFUL  work of
translating things being learned at the frontiers of scientific inquiry to
the motivated, marginally science-literate
person on the street.

Some of the statements you make above go leaping from mountain to mountain
and may -- OR  MAY  NOT --
meet precisely with my stances on some of the fine points.

This is both a compliment to you (you obviously have a fantastic mind) and a
solicitation not to grab something JUST  YET  and leap from thence to
another and another and another peak... leaving some connecting paths in
between.

In the past I have just had to bite my tongue for KNOWING that if I
responded with some of the same kinds of large leaps I would not be
providing you, or any other reader, with enough dots connecting one concept
to another... or to use another metaphor... would be asking you to "see"
pictures which contain so few pixels, as it were, of interstitial points to
be received as intended by me.

I promise -- after getting much farther along in these messages -- to break
down some of the things you say into
bite-sized chunks (still another metaphor... but not too mixed, I hope) we
can compare and analyze without too many unfollowable leaps.

For all you know, I may agree with you quite solidly.  And, then again, I
may disagree.  But, in either case, no guesswork will be required by you, me
or anyone else who has read well along in these messages, as to some very
(at least seemingly) simple and obvious steps in my reasonings between one
place and another.

I appreciate your interest, and will be honored to respond when I feel I
have laid sufficient groundwork that I can say something and not be
misunderstood.

Thanks for responding, and please stick around...

g

<QUOTE PREVIOUSPOST="
- Hide quoted text - - Show quoted text -
">

<QUOTE PREVIOUSPOST="
&gt;&gt; It does not require -- it seems to this layman -- that we need to be a
&gt;&gt; &quot;genius&quot; of the Bertrand Russellian variety to
&gt;&gt; see that this is NOT a juxtaposition of irreconcilables but a combining
&gt;&gt; of
&gt;&gt; two viable ideas in accordance with some understanding of what are some,
&gt;&gt; at
&gt;&gt; least, of the pertinent underlying facts... no less so than for us to
&gt;&gt; reconcile the fact that some things seem to fall while some things appear
&gt;&gt; to
&gt;&gt; rise, sometimes.

&gt; JE:-
&gt; Without refutability science becomes reduced to politics.

&gt;&gt; Forgive me if I seem to border on an unprovable assumption when I insert
&gt;&gt; here (it would be a footnote, if this were a formal paper) that I,
&gt;&gt; personally, assume that when MORE  DETAILS have been exposed in the
&gt;&gt; matter
&gt;&gt; of the
&gt;&gt; &quot;APPARENT  PARADOX&quot; between Newtonian and Quantum physics, then someone
&gt;&gt; who
&gt;&gt; is not a Bertrand Russellian-style genius will not have to see those two
&gt;&gt; as
&gt;&gt; irreconcilable, either.

&gt; JE:-
&gt; Quantum physics represents a verified statistical view of nature, i.e. it
&gt; is
&gt; just an observation waiting for a theory and not a theory of science in
&gt; its
&gt; own right. The only value that mathematically based statistics has for the
&gt; sciences is to provide a probability frame of reference to measure when an
&gt; observation can _reasonably_ claim to have been made.

&gt;&gt; However, as this layman tries consistently to
&gt;&gt; preach others should do, this layman both RECOGNIZES AND EMBRACES the
&gt;&gt; possibility that,
&gt;&gt; such details shall not be attained, or not in my lifetime and yours, or
&gt;&gt; not
&gt;&gt; ever... and ALSO the possibility that there simply is a levels-based
&gt;&gt; difference in how things work.

&gt; JE:-
&gt; Popper quantified it. All that is required is at least ONE sufficiently
&gt; complete empirical observation which can refute the idea. Unfortunately it
&gt; is this which remains the focus of increasingly intense political activity
&gt; within the sciences as purveyors of mediocre irrefutable ideas attempt
&gt; any-ruse-that-they-can-muster to allow their views entry as valid science.
&gt; The latest weapon in their (considerable) arsenal is their utter misuse of
&gt; valid mathematical tautologies employed to bamboozle the keepers of the
&gt; gate
&gt; to allow entry. Please refer to &quot;Felsenstein's Paradox&quot; which remains
&gt; exclusive to sbe as a classic example. Ask yourself why Felsenstein's
&gt; Paradox remains evaded here and why I am forced to endure continuous
&gt; vilification only because I loudly state that this remains the case and
&gt; insist that it HAS to be solved if evolutionary theory is to remain
&gt; credible
&gt; in the eyes of the general public.

&gt; Amazingly, even the gates of commercial rationality were breached via the
&gt; Enron scandal in which accountants actually wrote up debits as credits.
&gt; The
&gt; only possible way this can be done with any arguable validity is via an
&gt; accounting tautology of mathematics. Ring any bells?

&gt; Regards,

&gt; John Edser
&gt; Independent Researcher

&gt; e ... @ozemail.com.au
">
</POST>
<POST>
<POSTER> "g" &lt;gillaw...@earthlink.net&gt; </POSTER>
<POSTDATE> 2007-01-22T22:25:00 </POSTDATE>
MESSAGE SIX

IMPORTANT NOTE: Although these messages start out with things that may seem
simple and obvious, they are neither. Neither are they kid stuff. It is
assumed that the reader DOES have as a minimum an entry level familiarity
with many of the concepts raised here. While each concept may appear simple
and obvious when focused upon by itself, some of the hybridizations, or
syntheses which will arise from COLLISIONS between some of them may be quite
unexpected, or even startling, when the time is right.

In this message, let's look at what you and I mutually understand (I hope)
about how logic relates to calculating, how calculating relates to
algorithms, and how algorithms can never do more than conform to the
*assumptions* plugged (i.e., designed, built, programmed...) into them. It
is not necessary for the reader to be expert in these concepts; but it is
assumed that the reader has a basic understanding of -- if nothing else --
the amount of rigor required in arriving at what mathematicians call a
mathematical "proof," how rigorous is a requirement to begin from
"scratch" -- being given nothing -- establish even what the concept of
number is, and continue from there, step by step, to providing definitions
and postulates explaining even the math that grammar school children are
taught *BY ROTE* some rules about.

No mathematician ever HAS started from scratch, as in, from the position of
being able to design anything NOT reliant upon some sensory experience with
physical things and their interactions in physical events. Each and every
mathematician has a veritable set of empirical references which guide his
bottom-most conceptualizations and thought processes, and is constrained to
rely totally upon commonality of sensory empirical experience of any with
whom he would communicate anything -- whether he deems that to be "from
scratch" or denies it so. And (as may become more clear as these messages
move forward, concept upon concept, much of what we humans experience is not
in the particular, nor even measurable, but is experienced in ways enabling
thought about thinking of a "Kentucky windage" sort.

To build mathematical theory, qua an explanation of defining a priori
concepts even as basis as "p plus one" requires some COMMON experiential
grounds for communicating. It begins even without any concept of "number" or
"quantification," or "value" or "comparative value." And without any common
experiential designations to rely upon the most brilliant mathematician who
ever lived -- if he had no experiential foundation for sensing any empirical
things or happenings and wanted to communicate in "pure" logical terms with
someone else who also had not... just assuming he could figure out such
things as "quantification" or "qualification" how would he hope to
communicate to the other party anything whatsoever about them. No more can a
mathematician explain "one" or "two" to a person who never has physically
experienced one of something nor two of something than can that same
mathematician explain blue to a person who has never had any eyes So... this
layman assumes, at the very least, that the reader has experienced some
things in this old world, has formed some associations in his mind between
experienced things, and THEN has at least contemplated how easy... or how
difficult it is to "define" rather than "designate." Further treatment of
the difference in defining and designating will be treated in message seven.
NOTHING we humans can "explain" is "from scratch." But more on this later.
This message is only message 6, for crying out loud (:&gt;)

The aforesaid (in this message) being understood by the reader, I hope, we
can now get on down to discussing some things that are at-least-seemingly
simple and obvious... about the differences between calculations and
algorithms. And this old layman cannot, and therefore shall not, pretend to
define them but will only attempt to "designate" things about them which
hopefully will jog some experientially familiar "things" you and I feel we
mutually can "agree" on.

There is a story from way back in the 19th century about a recipe provided
by someone in the Alleghenies for "possum stew." (Please allow the spelling
"possum." In the time when this story is believed to have originated and,
indeed, when and where this old layman was a child, that was the preferred
spelling and pronunciation. Pah'-sm)

As the story goes, the recipe begins with "Git a possum."

Pretty dumb, huh. But, it assumes you cannot skin and quarter and brown one
unless you first "git" one. And the placement of this at the beginning of
the recipe certainly would discourage one from first making a rue and then
cutting up some potatoes and carrots and onions and THEN having to come to a
step saying to skin and quarter and brown the possum pieces.

So now let's go back to the skate example. If we would like to tell a kid
how to skate, a good place to start is to tell him to "Git a skate... no,
make that TWO skates," is it not. And, if the kid has never seen, heard,
touched, tasted, or smelled a skate... what's the most logical question for
the kid to ask at that juncture. You got it. "What's a skate?" And that's
where the onus is back in the describer's court. You must either "git" the
skate and provide it to the communications arena, or tell the kid where to
"git" one, and what to look for when he gets there. And, if you start saying
it is made of metal, and has wheels, and fits on the bottom of your shoe...
you have to be sure the kid knows what metal is, and what wheels are, and
what a shoe is. Let's just state it as simply as we can. SOMEbody has to
provide a skate, or make one.

And, this may be awfully complicated for some folks to grasp, but just
because one person makes a skate... or two skates... and skates on them,
does not necessarily make that "the" skate. That would mean it would be
impossible to come up with any better skate that is similar, or any OTHER
kind of skate.

So people who publish dictionaries are EXPERTS at "defining" things, aren't
they. Well... if "expert" means "the best so far" then, probably so, I would
guess. So, lets see how an expert publication (Houghton Mifflin's
e-dictionary, derived from the American Heritage Dictionary) EXPERTLY
defines a calculation::

calculation -- n.

1.

a. The act, process, or result of calculating.

b. An estimate based on probabilities.

2. Careful, often cunning estimation and planning of likely outcomes,
especially to advance one's own interests.

Oh ohhhhhh. Now don't that number 1. part a. just kill you? QUESTION from
someone who has never seen a skate: What's a skate? ANSWER from someone
very, very smart and experienced: Something you SKATE with, stupid!

Okay, to number one's b. part then: "b. An estimate based on probabilities."

Huh?

Okay, let's got to number 2., then.

"2. Careful, often cunning estimation and planning of likely outcomes,
especially to advance one's own interests."

Ah HA! Maybe this is the definition that fits some cases of out and out
fraudulent skewing of research results by some

EXPERTS doing research of certain kinds today. Can't say THEY have forgotten
each and every part of "an" expert definition of "calculation."

But you and I want to talk about what a calculation is in reference to pure
mathematics rather than to biased applications of mathematics.

Well... let's see. Oh, I know what. let's just assume that you KNOW what a
mathematical calculation is, and that I know what one is, and it's as simple
as that. We each have *experienced a possum,* so that takes care of THAT
issue.

Now we can move on and see what an algorithm is, and compare the two. Let's
rely on Houghton-Mifflin's help again:.

"algorithm -- n. A step-by-step problem-solving procedure, especially an
established, recursive computational procedure for solving a problem in a
finite number of steps."

Hmmmmmm. Now no mention was made of "recursive" in respect to a calculation,
nor of a finite number of steps.

Now, let me try to just designate my way, and your way, over the crests of
some seemingly simple and seemingly obvious waves here -- I can't tell you
EVERYTHING, you know... (:&gt;)... and just say that this old layman's
understanding is that you cannot show a machine such as one of those
old-fashioned. geared "logic" grinder machines,

or a new fangled computer how you calculate something on paper, and expect
it to do that. And that's why you and I owe such a debt of gratitude to Alan
Turing for sort of bridging the gap between how we calculate with pencil on
paper (which, if it had been simple, would not have take thousands of years
for some geniuses to develop *CONVENTIONS* for doing the ways we do that
today. (In a subsequent message we will talk about the essentiality of
conventions. For now suffice it to say that WITHOUT them, each of us would
be on his own, and having -- as it were to reinvent the wheel every time we
wish to calculate, and being to explain every jot to anybody we would show a
calculation to, when most people do not want to THINK hard enough to
listen).

So, anyhow, Turing figured out that we have to "translate" as it were,
mathematical calculations into machinable events.

(Oh, and let us consider an systematic electronic switching gadgets as
qualifying within the bounds of what is meant by "a machine" FOR PURPOSES OF
this discussion, right along with applications of gears and gear ratios, and
numbers of teeth on a gear, and pulleys and belts and

inclined planes and all that.

Another thing Turing helped others to "grasp" is that machines are incapable
of doing anything other than what they are built and set up to do in
conformance with formal logical process. (We can discuss how fuzzy logic and
Kentucky Windage are not the same, in a later message.) And the way they are
designed, constructed and
...
read more »
</POST>
<POST>
<POSTER> "g" &lt;gillaw...@earthlink.net&gt; </POSTER>
<POSTDATE> 2007-01-24T12:38:00 </POSTDATE>
MESSAGE SEVEN

Please forgive message six for focusing on more than one specific point. No
point in these messages exists unto itself alone; but one can be FOCUSED on,
and others which BY NECESSITY impact and/or are impacted by it, can be kept

as quiet as possible. Shall try harder to do that.

And now, as promised early in Message Six, let's focus on the issue of
"definition vs. designation."

BACKGROUND

PLEASE UNDERSTAND that this old layman's purpose in offering these messages
is NOT to rehash all the enormous number of observations and thoughts of
philosophers such as Plato and others who (according to Alfred North
Whitehead) have but written footnotes to Plato's observations (which, though
it have a grain of validity, also has made a many a naive and shallow
perceive himself to have something wise to offer to even the most astute
conversation). This old layman seeks to share by designating some of the
roots of issues you and I and ALL may see for ourselves, or disagree with as
much as we choose. The purpose of these messages is to communicate the best
efforts out of his life and thoughts, so far, to MAKE SENSE of some things
that seem to him both profound AND seemingly simple and obvious, and which
he believes YOU TOO will identify with in many particulars, if you think
about them. FOR PURPOSES OF these purposes here, I beg you to explore not
what thought Plato or Descartes or Immanuel Kant or any other, but what do
YOU think, WHEN you focus on some of the roots of things those philosophical
geniuses were up against -- as surely as you and I -- an NO HUMAN can prove
or disprove. This old layman CONCURS with the observation of Nobel Laureate
John F. Nash in his opinionation that it is better (sometimes) to do
something with one's OWN mind, rather than going to classes and memorizing
and regurgitating what others have done with THEIRS. This is not to say we
should not go to classes and learn. It is to say, also, let us THINK
TOGETHER, and THINK IN PRIVATE and hence be not merely "recorders and
players back" of the ideas of others... but PARTICIPANTS in reasoning, as
well..

And now let us focus together the flashlight of our thinking on the
difference between "definitions and designations."

First we need to lay on the table of our thinking some things that, while
not the primary focus in THIS message, were focused on earlier and IMPACT
AND/OR ARE IMPACTED BY what we will focus on "definitions vs designations."

If you have not read and thought deeply about some of the seemingly simple
and obvious points made prior to this message, you may not recognize them in
the following form:

1. Without some COMMONALITY of sensory experience with some common empirical
consistencies therein, no human would have any "cognitive reference" from
which to EXTRAPOLATE and thence "reason" or "communicate with another
concerning" any *FIRST PRINCIPLES*, nor any first cause, nor even an absence
of first cause. And what is more, without any concept of *FIRST PRINCIPLES*,
or first cause, there could be no *PURE REASON" to be imagined -- much less
applied -- as applicable or inapplicable to anything... nor any "thing"
imaginable as having the potential to exist. For where there were no
experience, there would be no

concept of it, and thence no significance to attach to "number," nor to
"comparative number," nor to "value," nor to "comparative value;" nor to any
"operation" whereby one "thing" might be deemed as being other in its to
relation to another thing different prior to manifestation of that
"operation" than before it, by virtue of

said operation. Nor would any cause be assignable, by virtue of any First
Principle or "a priori condition" whereby any change or motion might be
possible nor even imaginable. And what the foregoing add up to, is that man
has no reason but by virtue of experience. We may refer FOR PURPOSES OF
present examination of "logic" that it is not in the least invented by the
human mind, but INDUCED by human sensory experience.

2. But, unfortunately, human "experience" is at best partial in space and
time (that is, no man can be in all places at all times and observing all
things from all sides similtaneously). Neither is the mind of a human
capable of grasping even the paltry few little things and events that he is
privy to in a single hour or less of his lifetime. (A good reader can read a
lot of names and addresses in a telephone directory in minutes. But few, if
any, could close the directory and recite them. And it should not be
necessary to consider all the events of change and motion which have
occurred on Earth during that small span of time, nor much less in the
appariverse.

And with those two points in mind (I hope) we can zoom in on the difference
between "designation" on the one hand

and "definition" on the other. (And PLEASE do not accuse this old man of
proposing we do away with the word "definition." The purpose here is to lay
on the table of your communication with me, and my communication with you,

some understanding of WHAT ALL IS INVOLVED in defining or designating things
when we share ideas about them.

To designate is to refer to something which already is in one's own mind
and/or in the mind of another... by way of

common experience. For example, if I mention to you a "hypotenuse" I am
referring to something that coexists in your head and with mine by way of
some rather complex associations of things PROBABLY cueing up some similar
pictures of right triangles. If I say to you something regarding "the
hypotenuse of a 30-degree angle" you probably are going to

discern, as I do, that I have proffered an oxymoron. "Only a RIGHT triangle
has a hypotenuse," you might very well object.

And if I were to ask why you would say that, I expect you might reply to the
effect that it is by "definition."

Then we may look at "a" definition of hypotenuse in a source book we
mutually agree is "authoritative."

For instant purposes let us see what the Houghton-Mifflin eReference offers
us on it:

" hypotenuse -- n. The side of a right triangle opposite the right angle."

Now let me say that I "designated" something in your mind, which is held (if
not exactly the same, at least in ways that might be sufficient FOR PURPOSES
OF whatever point I would wish to get at here. I did not "define" it by
simply speaking a word that triggered a certain appropriate image, or set of
images, or whatever it triggered in your head.

So far, so good.

NOW, take a look at the would-be "definition" offered by Houghton-Mifflin.
Is that a "definition?"

My stance is that, if it were, then we could find ourselves a bright young
child who never heard of a hypotenuse, nor a right angle, nor a right
triangle and voice the alleged definition, and bingo... Into that child's
head would pop all that the definition provides.

The P0INT in this message is not to DEFINE "DEFINE." It is to clarify
between you and me FOR PURPOSES OF

our communicating meaningfully about definitions some seemingly simple and
obvious differences between what are

definitive acts as opposed to designative acts, when we communicate.

And not another POINT we need to COLLIDE with that one is this:

What IS is what IS, and not what we humans PERCEIVE it to be...
notwithstanding how accurate or how inaccurate that may be.

And now let us take it to a higher philosophical level and say that a
definition is not the thing defined. It is an ARTIFACT.

Let me repeat for emphasis and close this message here, because this is a
point which some very, very smart people sometimes -- per this old layman's
experience -- TEND TO FORGET.

ALL DEFINITIONS ARE ARTIFACTS. And, hence, it is NAIVE of any two of us to
debate any such frivolous thing as what "the" definition of something IS,
such as "the" definition of evolution, or "the" definition of space, or
"the" definition of time, or "the" definition of morality, or "the"
definition even of something so intuitive as "the" definition of a
hypotenuse.

ALL our attempts at defining are little more than attempts to call up in our
own individual minds what in blazes we wish to contemplate, and hoping to
call up in the mind of another some experiential references in his mind that
are sufficient FOR PURPOSES OF whatever it is we would like to contemplate
TOGETHER... or, if ego is one of our monsters... to bludgeon the other's
mind with our perceived corner on the market of understanding.

So ends Message Seven. In the next message, which probably will be Message
Eight, I shall share with you some points this old layman perceives to be
ENORMOUSLY important to you (and also to me) concerning the significance of
what is meant by "FOR PURPOSES OF." Simply and obvious. Right? Well.... let's
not be too sure until we look a little deeper. Okay?

(:&gt;)

g
</POST>
<POST>
<POSTER> "g" &lt;gillaw...@earthlink.net&gt; </POSTER>
<POSTDATE> 2007-01-24T12:38:00 </POSTDATE>
MESSAGE EIGHT

Sometimes logic (which term by itself usually refers to formal logic, and is
indistinguishable from mathematics) gets blamed for being contrary to common
sense, or unfair, or some such thing. Logic is just logic. It is
undiscriminating,

uncaring and sometimes, to us humans, un-common unsensible; but that is not
logic's fault Logic is just what it is... no more and no less.

Suppose you and I were to decide to become partners and open a cookie store.
And suppose we wanted to start out with just two kinds of cookies --
macaroons and apricot coconut squares. So we bake up a bunch of each and we
go out on the street in front of where our store will be and ask every
passer by whether he likes macaroons or apricot coconut squares, and make
marks on paper to show which. And then we add up and discover that twice as
many of those sampled stated a preference for apricot coconut squares.

We hire a cook and tell the cook that on opening day we are going to want
about 5,000 cookies, one third of them macaroons and two thirds of them
apricot coconut squares, and we ask the cook, "Are you good at math?"

To which the cook replies, "Oh, yes. I never make an error in math."

"Okay, then," we tell the cook, "We'll let you calculate how much dough to
mix to come out with a 2 to 1 ratio of apricot coconut squares to
macaroons."

Opening day comes, and we go back into the kitchen to bring out our product.
But something is wrong. The apricot coconut cookies are awfully small.

We say to the cook, "Didn't you say you are good at math?"

"Yes."

"The what did you do wrong."

"Nothing, " says the cook. "I calculated I would need equal amounts of dough
for each kind of cookie, and all I had to do, to make the two kinds of
cookies come out in the ratio you prescribed is, make the apricot coconut
squares half the size of the macaroons."

"Yes," you insist, "But we never told you to make any of the cookies half
size."

"Well, no, you didn't" says the cook, "But you didn't tell me NOT to,
either."

Maybe the cook should have asked. Maybe we should have made "all" our
expectations known. But, regardless of what hindsight tells us, it was not
LOGIC that was at fault.

Now let me tell you a true story about an investigation I did once for a U.
S. agency.

Upon receiving the assignment, I went to the law library (no I'm not a
member of the bar, but I can read and comprehend a few things) and I read
Book, Chapter, Paragraph, Sentence right down to the last jot. And (grossly
oversimplifying, but not losing the principle of it) if a legal person or
his/its duly appointed representative commits act F, that legal person is
guilty of a crime punishable by a minimum fine of X and other penalties
provided by statute.

I put that together with the knowledge I had -- based upon not one but a
general rule of law -- whereby a corporation is a "legal person."

Corporation A had committed was suspected of having committed that specific
act X, and it was my job to established evidence sufficient to establish
same in a court of law. I did investigate, long and hard, and did ascertain
that act X had been committed by Corporation A.

After much careful INVESTIGATION and gathering and organizing of evidence, I
prepared my investigation results which were compelling, and submitted the
documentation of same to the office of the U. S. Attorney General. Seven
weeks later, the file was "returned" to me, non-prosecutable, with a
notation, "Yes, but Statute R states unequivocally that "FOR PURPOSES OF"
the law you cited, a corporation IS NOT A LEGAL PERSON."

I've cut out much specificity to protect parties involved, and to keep this
example brief. But, in a nutshell, one statute can state something under the
laws FLAT OUT. And another law, or a bureaucratic Regulation, or a ruling of
a court can stand it on its head.

Charles Dickens' characters, Brumlow and Bumble made the following
statements in Oliver Twist::

Brumlow: The law assumes that your wife acts under your direction.
Bumble: If the law supposes that, then the law is a ass, a idiot!

So FOR PURPOSES OF a point this old layman intents to make here, what do
these anecdotes have in common?

They merely are intended as evidence that SCIENCE qua SCIENCE is not a ass,
the LAW as the LAW is not a ass; nor is LOGIC qua LOGIC a ass.

Science, empiricism, human knowledge, human understanding, the laws we live
under, formal logic... are WHAT THEY ARE.

It is OUR ANTHROPOCENTRIC EXPECTATIONS of each, where different from what
and how they are, that sometimes are tantamount to a ass.

We do not change nature. We do not manipulate nature. We merely manipulate
*WITHIN THE CONSTRAINTS OF* nature. Now whether nature is gd, or Gd, or none
of the above... that is something over which we have no control. So the best
we can do is continue striving to figure that out, and cope with it as
nearly as our science can come to figuring out what that is AS IS... SUBJECT
TO our anthropological LIMITS, physical, psychological, philosophical.

We are, despite all our anthropological arrogant judgmentalism... NOTHING if
not limited...

Message Nine will delve into the question, "What can we know about what we
do not know."

g
</POST>
<POST>
<POSTER> "g" &lt;gillaw...@earthlink.net&gt; </POSTER>
<POSTDATE> 2007-01-25T14:09:00 </POSTDATE>
Message Nine

QUESTION:  What Can We Know About What We Cannot Know?

Oxymoronic question?

Is the best answer, "We cannot know what we cannot know?"

Well, lets examine that answer for a moment.  If this old layman were to ask
you what your plans for tomorrow morning are, what would you say?  Are you
planning to get up, shower, shave, dress, get the kids ready and drop them
off at school, go to the office, work until 5:00 P.M.?

Why would you want to make plans about something you DO  NOT  KNOW.  You may
THINK you will wake up tomorrow morning.  You may THINK your house will not
be destroyed by a tornado, or burn down, tonight.  You may THINK one of the
kids won't get seriously ill during the night and have to be taken to an
emergency room.  You may THINK you will not be fired the minute you walk in
the door at your office.  But you do not KNOW.  If what we THINK we know
tomorrow  will bring were correct, then it would be correct 100 % of the
time.  And if one of the kids were going to get sick on night, we would KNOW
that.  And every person whose house is going to be hit by a tornado tonight,
or burn down, would KNOW that.

Extrapolation is cool; but it is not knowing.  Projecting a trend is cool;
but it is not knowing.  Calculating probabilities is cool; but it is not
knowing.  In fact, we can calculate the probabilites of how many times a
coin will come out heads (if all things are equal during a set of flips...
which all things NEVER are) and then when we flip the coin in trials of
fifty times each, we might get heads 48 percent of the time in one trial,
and 55 % of the time in another.  (Yes, if all things are equal... which
they never are, THEN there are some outside limits.  But in a real life
experience, something COULD cause the coin to come out heads every time, or
not times.  Probability calculations, when done with pure, sound logic, are
a good tool.  But pure logic works best with pure circumstances.  And nature
does not seem to provide many pure circumstances.

If we you or I would investigate something, and do an optimum job of it, we
need to get as clearly in our mind before, during, and after, the
investigation what we KNOW, what is PROBABLE under the KNOWN circumstances,
what is POSSIBLE under the KNOWN circumstances, and how to SHIFT  GEARS when
something improbable turns out to be the way things ARE, in a given
instance, and sets our best laid assumptions on their heads.

A many an innocent party has been picked out of a line-up because a witness
KNOWS he/she saw that person do a certain criminal thing... saw it with
his/her own eyes.  Eyes don't lie.  Interpretations of what they "report" to
our brains often do.  (Won't bore you with a hundreds of examples of
experiments in which tricks can be played on a person's visual "witness" of
something "right before his/her very eyes."  But could...)

More than once this old investigator was assigned a case and was told it was
"OBVIOUS" who done it.

More than once this old layman got cross-wise with an adminstrative superior
who became frustrated and angry when presented with hard evidence he/she was
WRONG about what he/she KNEW !   In fact, this old layman has been pressured
(off the record, of course) to omit certain evidence from a report and
refused, and has been "punished" indirectly for refusing to do so.  How can
that work?  Easy.  If you want to sand bag a civil servant you merely damn
him/her with faint praise, or describe him/her as "not a team player," or
"difficult to supervise,"  or some such indirect negatory thing.   And when
asked for details, the administrative superior can always come up with some
half truths that cannot be proved or disproved about "the look on someone's
face when given instructions, or some such lie.  As the lying superior, you
NEVER mention that your bad evaluations began to turn bad shortly after the
"inferior" refused to cook evidence on a case... NEVER !  That would be
tantamount to an admission of subornation of evidence.  Suppervisors are not
THAT stupid!

Enough.  Too much, maybe.  This message has barely even TOUCHED upon all the
ways in which we sort of know somethings that we cannot prove or disprove.
Not all of them are "proved" in the sense of turning out to turn out as
predicted.  That is not scientific proof.  For example if I say I shall flip
a coin three times and get heads each time, and I do that.  This does not
prove I KNEW it was going to happen, even if I believed it was...

Lesson Ten will discuss Tools of Informal Reasoning.

Formal logic is fine when and if we are so lucky as to deal only with
CERTAINTIES.   But certainties
</POST>
<POST>
<POSTER> "g" &lt;gillaw...@earthlink.net&gt; </POSTER>
<POSTDATE> 2007-01-25T14:09:00 </POSTDATE>
MESSAGE TEN (not Lesson Ten)

QUESTION: If formal logic is infallible in being logical (which is the
converse of saying that if it contains an error it is not logical and,
therefore, not logic) then, for crying out loud, why don't we cease and
desist from using anything else?

ANSWER PARTIAL -- Your attention span, and my alloted budget of time to
writing these sharings, do not allow anything remotely approaching an
exhaustive answer, so let a few "designations" be made to trigger up some
things in YOUR experience, as well as mine, just taking a good stab at it.

For one thing, as we have seen in these messages up to now, there is a heck
of a lot WE DON'T KNOW FOR CERTAIN. (To heck with Heisenberg and Schrödinger
FOR PURPOSES OF triggering up experiences in your mind relating to this. We
don't need any scholarly quotes to get at that, do we? How certain are you
that the people you think are your parents actually are? If you and they
have been DNA tested, and the results indicate that there is only a one in
(however many gazillions) chance you are NOT their child, then you are
pretty sure, although not 100 % certain.

But you look like your mom? Then how about your dad? Okay, so you have
characteristics of both of them? Well, people who adopt babies sometimes
take great pains to pick out a child having characteristics in common with
each.

But no one who would have demonstrated so much love for you, and whom you
never have caught in any lie but a little white one now and then would lie
about anything so important as that? Think again. Documented cases exist.

A family got to know a family once who had a late-life child. When they were
in their mid forties, they were raising a three year old "daughter" who
looked very much like both parents. They also had a daughter in college that
the three-year-old called "Big Sister." Unfortunately half the town knew
"Big Sister" was actually "momma." So many people knew, that the family
finally went to a professional counselor to find a way to deal with the fear
"Sue" would find out, and -- among other alternatives considered was moving
away, and starting over in another town or city. But that thought got
shucked, and finally it was decided that the whole family would sit down
with "Sue" and tell her.

By the way, "Sue" took it better than anyone else. In fact she liked being
Big Sister's daughter, as long as she didn't have to change schools or
anything.

The POINT is, we don't always KNOW what we THINK we know. And, shucks, this
only touches on one kind of example.

But the messaged promised to be about THE HUMAN DEFENSE MECHANISMS.

Ooooookay. Defense mechanisms are bad, aren't they? Oh, you had Psychology
101. You KNOW they are as essential to good psychological health, because
they serve as a BUFFER between the psyche and many shocks reality slams us
with. Wait, did I say "psyche." Make that... hmmmmm... All that id, ego,
superego and psyche stuff has "evolved" so much since I had 101, I'd better
say, "emotional comfort zone." Either way, the designation called something
up when you heard it. Good enough FOR PURPOSES OF the making of point
intended here.

If you are really "psychology literate," you know that psychological
"health" includes a healthy set of defense mechanisms. They are what allow
you, when momma dies, to take care of all the arrangements, get things done,
say "goodbye" to all the relatives, ask for a couple of days off from your
job, and THEN become a mass of blubbering,

incompetent, self-absorption. Going through the "classical stages of grief"
is pretty much something one not only has to do, however rapidly or slowly,
or drastically or mildly, but -- if you DON'T, then somebody needs to start
worrying.

A child who does not seem the least bit bothered by the death of mommy, or
has a "flat affect" for days, weeks, months afterward is long overdue for
professional medical/psychological intervention... usually.

What has any of this to do with bio-evolution? It has EVERYTHING to do with
any and EVERY scientific investigation... that's all.

So we know all that from psych 101 right. Good. Maybe we all know, also,
that researchers and clinicians in the psych field like to refer to these
mechanisms as (the) "EGO MECHANISMS OF DEFENSE.").

Before we take a look at the "formal" list of these mechanisms, let us
contemplate a question about scientists: QUESTION: Can a SCIENTIST afford to
resist against CHANGE, self-delusions of any kind, entertain fallacious rosy
notions... goodness gracious... afford to LIE TO HIMSELF about anything
pertaining to his work.

Well, here we go with definitions, but: According to a pretty sizeable
consensus among shrinks, ALL humans not only have, but have a right to, and
not only have a right to but have a "NEED" to... have a healthy set of ego
defense mechanisms... albeit "MATURE" ones. Mature, as in not "arrested" in
an early stage of development.

So wait... does a SCIENTIST have a right and a need and an innate and
indispensable encumbrance with some mechanisms that enable him to DELUDE
himself? Welllll.... if he/she is HUMAN he/she does... at least, according
to a consensus among shrinks. But, then, what do shrinks know? They just
WORK with that kind of stuff. Some folks say shrinks don't have the common
sense nature (or whatever) gave a goose.

We who like to talk about science like to think in terms of total
objectivity, and total self-honesty, and pure logic, and pure scientific
motives, don't we. We like to talk about "EMPIRICAL EVIDENCE." Well, those
who are in the business of trying to help people with what they call
"Different Defensive Styles" from others have their differences

INDEPENDENT OF environmental influences.

Whoa, Nellie! Is this saying all the stuff this old layman has been saying
about the necessity of an experiential possum

is off the mark. No, no, no... Don't forget the mention that individual
humans, at conception, get hard wired differently and respond differently to
the same... (not identical but approximately the same, okay?) scenarios.

But saying ANYTHING about psychology and SCIENTISTS is a slipper slope,
isn't
it? Isn't it?

So, okay, what point is this old layman trying to get across?

Simply this. Scientists are human. Reality can be brutal. Careers can vanish
in a puff of smoke. Peers can shun you if you don't sort of buy-in to the
current conventions and modes of thinking in your field. Funds can be GIVEN,
and funds can be TAKEN AWAY.

One has to COPE, survive, defend one's "comfort zone," sleep at night, have
enough income to live on.

Hey, nobody promised SCIENTISTS a rose garden. But, now and then, a pair of
rose-colored lenses and some ear plugs... temporarily at least... until one
has time to acclimate to some shocking new change in his professional life
or his field or his income... those might be nothing less than tools of
survival. And if that means sort of looking the other way if results of an
experiment do not please the fund sources, that's no deliberate, cold,
calculated, intentional fraud, is it?

Welcome to life in the real world, folks. But, given enough time, and enough
means to keep the family alive and together, and a healthy, maturity of
ego-defense mechanisms... a SCIENTIST should raise the bar of honesty and

objectivity a little higher for himself than most, should he not?

First one has to SURVIVE, and THEN bend his work around to conforming with
data exactly as data is... whether it means the whole project goes down the
tube, or one simply gets kicked out of the lab for not telling some
administrator what the funding source wants to hear.

It hard. But some scientists have something some of us call "personal
integrity." We CANNOT PROVE NOR DISPROVE that a scientist who loses his job
for not being a "team player" is any better than one who games the system
for all it's worth. I think so. Maybe you think so. But we cannot prove it,
now can we?

Message Eleven -- ain't figured out what it's be about yet...

g.
</POST>
<POST>
<POSTER> "g" &lt;gillaw...@earthlink.net&gt; </POSTER>
<POSTDATE> 2007-01-26T13:35:00 </POSTDATE>
MESSAGE ELEVEN -- PHILOSOPHICAL CATATONIA (A WAY OUT OF IT)

What would you think if this old layman were to offer you and me a way out
of philosophical catatonia here in this seventh year of this 21st century
AD?.

Perhaps, you might protest..., this old man should tell us what he MEANS by
*PHILOSOPHICAL CATATONIA*; and THEN we may wish to decide.

Well, shucks. That's easy enough. But, you might have to THINK a little bit
harder than just reading the newspaper, to git it (:&gt;)

If you have read (through all the typos and such) the messages leading up to
this one, and have thought deeply about some of the seemingly simple and
obvious things this old f--t has been building up to here, you may not need
any rehash now. But just in case you have just glanced over those messages
building seeming simple and obvious brick upon seemingly simple and obvious
brick... OR, if you have just come in and don't know whether it's worth your
while to go back and climb the ramp I provided, let's go over some of points
covered so far.

First of all, you will remember (if you've read it all) that this old f--t
has offered here, and on the table of sincere sharing of ideas as between
you and me, a definition of "definition" itself, whereby the highest and
best purpose of a definition is NOT to recreate or replace any and every
conceivable subsumptive relation to put a fence around a specific cognitive
"target", but to tag in some way a key word or phrase and form an
associative path from it to something of mutual experiential meaning to both
definer and definee... to *DESIGNATE*  some *PATH OF THE MIND, TO TRIGGER A
RETURN TO A SPECIFIC SUBJECT OF CONTEMPLATION* again, after it has been let
to fester a while, to condition YOUR  OWN  experiential background in such a
way as that when the "key" is turned, you know the trail BACK to some thing
of mutual significance to us, so that we may go from there to somewhere we
both find of interest... or even of learning, maybe.  And, IDEALLY, said
definition (if we would call it that, knowing it is only a designative key
(or call it a *DESIGNATION*, if you will) would be one you would wish to
return to on your own, and do more than this old buzzard can with it.  The
"place in the mind" where you and I might mutually find a particular set of
things, operations, sequences of operations, connections between operations,
or whatever else could be conjured up by this discussion, would put us "on
the same page" as it were, without spelling out the WHOLE page, just to
trigger the route to it.

Failure of the first part of such a definition of "definition" would result
in the DEFINER'S being unable to
get you to that place in the first instance; whereas failure of part two
would be that DEFINER would be incapable of getting you BACK to that mutual
place of our minds and, hence, "on the same page as before" the next time
you hear the trigger word or phrase from the definer.  (In instances in
which an individual does not think thoughts, but merely memorizes and
regurgitates the thoughts of others, dictionary definitions of words and
phrases are somewhat adequate.  Any launching away from overly beaten paths
of pseudo-think requires some triggers not to be found in just any
dictionary.

Let it be emphasized that a definition does not have to be 100 % precise in
offering a perfect set of subsumptive relations wherewith to arrive at
perfect description... as that would entail a volume per word, and would
cover every use to which it ever had been put.  But EVEN  WORDS  COMMONLY
FOUND  IN  DICTIONARIES  have MULTIPLE  designations, often mutually
exclusive ones, and a careless thinker/writer who does not clarify WHICH one
or more of the several meanings going around of a single word or phrase is
not disambiguating his
discussion and, hence, can and probably SHALL be misunderstood to the max.
And we must not forget that SOME esoteric bassholes DELIBERATELY leave
multiple meanings un-tied-down in hopes their reader will think
himself/herself more stupid than the writer/thinker and be IMPRESSED by
ambiguities merely DISGUISED as
would-be profundities.  (:&gt;)

A *PERFECT* set of disambiguating subsumptive relations (if defining were to
require it) would absolutely and unequivocally RULE IN EVERYTHING that the
trigger word or expression *would* entail and would RULE OUT EVERYTHING *not
entailed by it*. And hence it would render IMPOSSIBLE the triggering of any
cognitive contemplation deviating to the slightest extent from intended
meaning. A perfect definition, in other words, would be tantamount to what
would result if DEFINER were capable of plugging one end of a cable into his
brain and the other end into the brain of DEFINEE, and, after a loud ZAP !,
or some such, DEFINEE would see EXACTLY the same set of whatevers... en
toto, ad infinitum, and sans-distortion, sans-deviation.

All that having been made crystal clear (:&gt;) let this old gumshoe offer a
definition (designation) of what he would wish to trigger in your mind when
THIS old f--t uses the expression:  *PHILOSOPHICAL LITERACY*, while
in route to whatever else he might say.

Philosophical literacy (per this old f--t) is the state of having arrived at
a realization that philosophy is nothing more -- nor anything less -- than a
marvelously wonderful tool for examining things we CAN NEITHER PROVE NOR
DISPROVE..., for trying out first one and then another set of ASSUMPTIONS
from among many ALTERNATIVE  ones, on empirically untestable matters..., for
trying out principles and logical operations we have EXTRAPOLATED from among
things we DO deem ourselves able to prove or disprove, by applying them
ARBITRARILY to meta-physical things (as in empirically untestable) such as
right, wrong, virtue, madness, why we are even here doing what we do, and
such... WITHOUT  WHICH  EMPIRICAL  EVIDENCE  DOES  NOT  MEAN  DIDDLY
CRAP... and which, therefore, is ESSENTIAL  TO  HAVING  ANY  NOTION  OF
WHAT  SCIENCE  IS  ABOUT, in delving into empirical things.  Even any notion
of WHY  IT  SHOULD requires some meta-physical (i.e., qualitative judgment),
whether any empiricist wishes to realize that or not.

Now please note that the above designation (whereby a "same page" cognitive
image of  philosophical literacy might find common experiential resonance in
both your mind and my mind, RULES  OUT  the misconception widely held among
many would-be philosophically qualified soap boxers that philosophical
literacy consists in the MEMORIZING AND REGURGITATING of ideas eclectically
lifted from the ideas of a few famous thinkers or, shudder, cringe, gnash
teeth... of merely ONE renowned thinker of dead-end cul de sac philosophical
school of thought, which has become  OSSIFIED into the self-styled disciples
mind to the inclusion of only a few, out of MANY  equally arguable
ASSUMPTIONS. to the exclusion of ALL  THE  REST, all being comparably if not
equally one as unprovable as another.  Such ossification is dogma. Holding
to it is orthodoxy.  And dogma and orthodoxy, while they may qualify as
being derivable FROM philosophy, are NOT earmarks of philosophical literacy
but the same as any totally illogical dogma or orthodoxy that can be come up
with.  Hence, this old f--t has offered upon the table of our "getting on
the same page" the proposition that any ossified, entrenched dogma or
orthodoxy which REFUSES  TO  FURTHER  APPLY  the wonderful tools of
philosophical inquiry, and the recognition of MANY possible assumptions
about things unprovable and undisprovable, is in a state of *PHILOSOPHICAL
PARALYSIS.*

AND... lest anyone get the false notion that ANYTHING in the above
"designation" of what is philosophical literacy RULES  OUT  THE  EXERCISE
OF  STANCE,  let it be understood that without the taking of any
philosophical STANCE, after open-mindedly examining as many of the
ALTERNATIVES among assumptions takable, one dooms oneself to the OTHER  SIDE
of the same coin of illiteracy of being PARALYZED.   Hence, this old f--t
asserts that stances are as unavoidable as they are defensible... but should
always be recognized AS  WHAT  THEY  ARE, and not taken as "GIVENS."
Frighteningly, there are those among mankind who not only are ossified and
entrenched in something they MISTAKE for philosophically sound reasoning,
and who not only resent anyone else's thinking in terms of any unprovable
assumptions OTHER than their own (and that of their clique) but, ALSO, who
perceive themselves to be under a duty and an obligation to MILITATE against
"unbelievers."

BELIEF, is faith.  MILITANT  DOGMATISM is NOT faith.  If the stance of faith
were KNOWING, then it would not be faith but empirical knowing... which, no
matter how simple and obvious it is to the open mind... some very smart
people TEND  TO  FORGET.

And that sort of brings us to the necessity of drawing a clear distinction
between philosophical "paralysis" and *PHILOSOPHICAL  CATATONIA*.

We are on the same page as to what catatonia is, are we not?

Well, perhaps there might be a reader among us who needs a little refreshing
on it.  In mental disorders, catatonia refers to a condition which has not
one state of expression, but TWO. The one of these two states may be
compared to how a wild squirrel thinks and behaves when first caught in a
cage-trap.  Everything in its mind and body, it would appear, cries out "MY
VERY  EXISTENCE  IS  IN  CRISIS  AND  I  MUST  DO  SOMETHING!  BUT  WHAT!"
And (assuming that is what it is, and although a squirrel has no words for
it, as far as we know) leads to either a freezing into a readiness to fight,
flee or just bear the death-bringing, or a frenetic Katy-bar-the-door mode
of trying anything and everything to get out, even if nothing is working...
or first one and then the other... or alternately both.  And so it is with,
say, a patient with paranoid schizophrenia who may stand in a frozen posture
for hours, and then create bedlam.

Also, we -- some of us at least -- who seek through philosophical inquiry
...
read more »
</POST>
<POST>
<POSTER> "g" &lt;gillaw...@earthlink.net&gt; </POSTER>
<POSTDATE> 2007-01-26T13:35:00 </POSTDATE>
MESSAGE TWELVE -- A WAY OUT

The way out of getting into an intellectual cage-trap is to be skeptical of
ANY AND EVERY DOGMA DISGUISED AS A PHILOSOPHICAL SCHOOL OF THOUGHT OR AN
EMPIRICAL LY TESTABLE FACT WHEN IT

MAY NOT BE..

One who understands that philosophical literacy consists in EXAMINING things
neither provable nor disprovable from as many DIFFERENT ALTERNATIVE
ASSUMPTIONS as possible. It does NOT consist in buying-into a handful of
assumptions that are treated as if they were GIVENS, and which -- if we
accept them -- lead inevitably to the conclusion that life and love and
meaning, beyond empiricism are but illusions, and all that really exists is
physics.

If it takes a going back to the ROOTS of what we humans can know, and seeing
that even much of what SEEMS to be knowledge is very nebulous to begin with,
and then moving forward in our thinking while -- AT EACH AND EVERY

STANCE-JUNCTURE IN OUR LIVES -- we have simply selected certain
unprovable/undisprovable ASSUMPTIONS and mistaken this for "truth...

We can just as rationally choose OTHER assumptions which do NOT lead to dead
ends of pointlessness, hopelessness and despair. Only a very NARROW pathway
of selections of assumptions lead there. But none should take this old
geezer's word for it. The loops of assumptions about things neither provable
nor disprovable that we make in our lives can be like the loops of the
spider in the story of "The Spider and the Fly."

For some reason, there are many among us who are so bound up in ASSUMPTIONS
mistaken for "provables" (which they are not) that some people do not
discern that a possibility of escape from a philosophical state of
hopelessness and despair is a narrow path chosen from among MANY others...
they do not see that the trap is an illusion.

We ALL live with some illusions, because we simply live in a world of an
enormous amount of uncertainty and a

very limited amount of ACTUAL KNOWLEDGE.

Imagine a SCIENTIST who is skeptical of everything and who CHECKS OUT
EVERYTHING.

If that were not an illusion, then that SCIENTIST has worked through each
and every mathematical "PROOF" of every genius who claims to have found
one... or rejected some of the simplest and most familiar mathematical
assumptions made by all.

If that SCIENTIST believes in gravity because it is "proven" then he has
DUPLICATED such experiments as the Michelson-Morley experiment . In fact he
has repeated every experiment ever done, which has gone into every
CONVENTION AND CONSENSUS which make up what those in his field view as
GIVENS.

This is not to say that those conventions or consensus are WRONG. But the
SCIENTIST who does not take anything on faith, just because a lot of peers
AGREE on it, but because he, personally, has CHECKED IT OUT... has to be the

greatest genius who ever has lived AS WELL AS the busiest son of a gun who
ever lived, because he is having to confirm by duplication EVERY MOON SHOT
made by NASA, and has poured over every iota of data that has been gathered
from every available source and has checked all the computations done, and
every interpretations made of

every TWIT of that data, and...

Wait a minute... did I say... "INTERPRETATIONS?" No, the purely empirical
SCIENTIST cannot interpret anything. He has to be CERTAIN of each and
everything he believes.

This old man says to you, "There is NO SUCH SCIENTIST, folks."

There is no such physicist. There is no such philosopher. There is no such
psychologist. We ALL accept things as being empirical truth that we have not
CHECKED OUT FOR OURSELVES... repeat... ALL.

And the way out of any assumptions that empirical refutability leaves us
nothing to believe in but what can be established by way of technology and
hard evidence... baloney.

If any of us is in a dead end hopelessness, despair-trap, and thinking
he/she got there by way of science, psychology or philosophy... then that
person is his/her OWN spider, as well as his/her own fly.

But, again, please do not take THIS ol' coot's word for it. Back up and
rethink the experiences of your own life, from as near scratch as you can,
and you will see where you have thrown some pseudo-empirical-fact loops
around yourself which were not the least bit testable, nor tested.

Enough for this lesson? Too much?

Suit yourself. (:&gt;).

Oh, by the way, I LIED earlier, when I told you Message Ten would be about
the TOOLS OF REASON. It was not intentional. Please accept my apology. It
was a goof. Maybe MESSAGE THIRTEEN will be about THE TOOLS OF REASON.

g
</POST>
<POST>
<POSTER> "g" &lt;gillaw...@earthlink.net&gt; </POSTER>
<POSTDATE> 2007-02-03T14:24:00 </POSTDATE>
MESSAGE THIRTEEN --
TOOLS  OF  REASON, renamed TOOLS  OF  THOUGHT

Experience --  can be misleading.  As every prestidigitator knows full well,
we cannot always be certain that what our vision system seems to be telling
us is right.  Neuro-psychologists and neuro-physiologists know this, too.
They have experimented and figured out to some extent how and why our human
sensory systems make mistakes and miss a lot.  We see only a very narrow
range of the electromagnetic spectrum.  Our vision organs and wiring and
interpretation cannot even see motion.  We just see a bunch of still shots,
and sort of interpret that as motion.  We can't even see a bullet that is
traveling out of a gun.  And more.  Our auditory detection/interpretation
systems are pretty fallible, too.  In fact, if we don't hear something
clearly, we may have been issued a compliment and believe we have just been
insulted.  That can make us act pretty inappropriately.  And our sense of
smell can be fooled, as one smell interferes with detection of another.  Let
those who like the smell of toasted almonds beware of strychnine.  And, as
for touch, parts of our bodies we have fewer pain nerves than others and can
be burned before we know to jerk away.  And, here too, we have a gap of
sorts in that we can receive a lethal dose of radiation and interpret it to
be no more than a warm glow.  But, as if the bugs in our sensory
experiencing systems were not enough, we have an experiential problem with
observing the universe as it really is in that we are physically unable to
be everywhere, all the time, and observing everything that is happening from
each and every angle on a real time basis.  And, worse yet, we humans can
and do hallucinate at times, when extraordinarily fatigued, when certain
drugs upset our brain chemicals, when our brain chemicals get out of whack
due to disease symptoms such as infections or high fever, when we suffer
physical trauma, or inherit certain "bad" genes.

Memory -- can be misleading.  Try designing a crossword puzzle in your head.
Or, simpler than that, try working
one someone else has designed, without a pencil.  If we do not even sense
the bulk of all that goes on in the universe (see "experience") in the first
instance, there is much missing that is not even there TO be forgotten but,
also, we remember only interpretations, remember, whether they were right at
the outset or wrong at the outset.  It is well established by contemporary
cognitive researchers that memories not only get off to a bad start in terms
of getting everything right, and stored right, in the first place, but we
forget even some things we would be better off remembering, such as wife's
birthdays and such.  And not only do we forget randomly but we also forget
eclectically.  That is, we tend to remember certain kinds of experiences
less well than other kinds... unpleasant ones, for example, as opposed to
pleasant ones.  And, as if that were not bad enough, human memories have
been proved to be quite often altered and sometimes totally fabricated from
the imagination, to accommodate our desire to remember some overall scenario
in a way that pleases us, or to accommodate our ego defense mechanisms
generally.  Some of us love a good story so much that we first embellish an
experience in the telling and then, later on, remember the embellished form
as though it were the experience itself.

Pattern discernment -- can be misleading.  It does not apply, of course,
only to visual stimuli.  It can apply to the other senses, as well.  The
very recognition of one pattern can preclude the discernment of another.
The significance of something at one distance can be differently interpreted
at another... as when an oil painting, viewed from two feet away may make no
sense at all, but from ten feet away is a picture of a crowd of people on a
busy city street.  Actually there are far more patterns among sensory
stimuli than any of us can detect, although some detect more of one kind and
some more of another.  For example, a color-sighted person my totally fail
to discern a military tank under camouflage netting, while a color-blind
person will see it virtually instantly.  As for auditory patterns, we can
listen to one individual in a crowd and totally lose the ability to hear
another speaker talking from the same distance and with equal loudness.  As
with the other tools of thought, pattern discernments of certain kinds can
be ENHANCED by brain traumas that deprive us of others.  At least one math
intuiting autistic savant is unable to discern the patterns involved in
recognizing human faces or those required to operate a motor vehicle.

Intuition --  can be misleading.  Some of the greatest syntheses in science
have been attributed by their authors to such nebulous things as
"inspiration," "dreams," "epiphanical insights," ...etc.  But for most of us
those kinds of experiences produce nothing we can use or make sense of.
Cognitive research has revealed that extraordinary intuition can be
associated with brain abnormalities, such as had Dr. Einstein.  Was he
perhaps a savant?  Some say yes.  Some say no.  But students on campuses on
which he taught have been quoted as reporting instances of his stopping them
to ask them directions to a classroom where he had been lecturing for
months.  How interesting to wonder what would have been his fate, had he not
gotten out of Germany in time and had ended up at Auswitz.

Invention -- can be misleading.  It is a wonderful tool.  However, where the
experimenter is oblivious to what  mechanisms actually lie behind a material
phenomenon, and do not even think to test a hypothesis that never occurs to
him, he can experiment on basis of hypotheses that are off the mark until it
snows in Hades, and not come up with anything enlightening.  Or, he can
thereby rule out things that won't work, as did Thomas Edison whose critics
are said to have ridiculed some of the "preposterous"  things he tried
out -- except, of course, when they worked anyhow.  One wonders how many
hypotheses have been squelched or preempted because they were off the beaten
track, outside the Zeitgeist of the day, beyond the weltanschauung of their
contemporary political or academical establishment.

Reason -- can be misleading.  First of all, if it is based upon aggregated
experience -- where that experience was not comprehensive, where it was
limited to only those places, at those times, and from those angles where
one has been in real time -- where that experience is mostly second hand,
and others cannot always be relied upon to get it right -- acculturated to
certain biases of interpretation, before an experience even occurred -- even
perfect inductive or deductive reasoning is not likely to exceed the bugs in
one's "input" and "recall."

Sorry, I grow tired of being trite, and shall stop here.  None of this is
new nor enlightening.

What is appalling to this old coot is how often he comes across some
comments of even some highly educated people (academically) who make
comments sometimes that seem OBLIVIOUS to the limitations of any and all
tools of human thinking...

Maybe I shall go on later...  Maybe not.  If enough has been said here to
serve as a REMINDER, then perhaps enough said.

But to top it off, let it be observed that TOO  MUCH  RELIANCE  UPON  ANY
ONE  TOOL  OUT  OF  THE  ENTIRE  TOOL  BOX  can lead to "bad" science.

No greater understanding of this can be demonstrated of THIS, in this old
codger's respectful opinion than for anyone... scientist, layman, author...
whoever... to say words to the effect of:

I  DO  NOT  KNOW, but here is my studied "stance" at this juncture, informed
by the following (facts and assumptions of fact) by which I mean
(disambiguating all terms and operations involved at arriving at it), and if
you perceive a fly to be in this ointment, and you, too, have studied and
thereby arrived at a different informed view, then PLEASE DO  ME  THE  FAVOR
of making me privy to your stance.

But just one other thing, let me add.  Sometimes, even if rarely, there can
be someone from outside a field of expertise who MAY discern a fly to exist
in an ointment BY  VIRTUE  OF  THE  FACT  that he is standing a bit farther
away from the academic establishment.

By no means should Wallace be put on the same pedestal with Darwin... but
Wallace developed the same overall insight Darwin had taken years to work
up, with far less experience.  (One of the things I admire about Darwin is
that when Wallace offered this insight to Darwin, Darwin agreed for
Wallace's paper to be published along with one of his own.  Now THAT is an
example of what this old layman deems to be both good character AND
scientific honesty.

g
</POST>
</TEXT>
</BODY>
</DOC>
