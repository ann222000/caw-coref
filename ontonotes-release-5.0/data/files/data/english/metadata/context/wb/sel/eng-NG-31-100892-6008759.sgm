<DOC>
<DOCID> eng-NG-31-100892-6008759 </DOCID>
<DOCTYPE SOURCE="usenet"> USENET TEXT </DOCTYPE>
<DATETIME> 2007-01-10T16:50:00 </DATETIME>
<BODY>
<HEADLINE>
Another Cockroach Question
</HEADLINE>
<TEXT>
<POST>
<POSTER> Sir Frederick &lt;mmcne...@fuzzysys.com&gt; </POSTER>
<POSTDATE> 2007-01-10T16:50:00 </POSTDATE>
Another question :
Do cockroaches experience an "I"?
Do they experience anything?
--
Frederick Martin McNeill
Poway, California, United States of America
mmcne ... @fuzzysys.com
http://www.fuzzysys.com
http://members.cox.net/fmmcneill
*************************
"LIFE IS ONE BIG MUDDLE. Sometimes you have to muddle more, sometimes you have to muddle less, but for all of us “muddling through” is the natural state of things. Luckily, while we muddle, we can surround ourselves with things we cherish. We can muddle nobly, happily and with a sense of purpose. We can choose to love and allow ourselves to be loved as we muddle.  Ultimately, if you want it to be and let it be, it’s a beautiful muddle indeed."
--Dean Barrnett
:-))))Snort!)
**************************************
</POST>
<POST>
<POSTER> "George Dance" &lt;georgedanc...@yahoo.ca&gt; </POSTER>
<POSTDATE> 2007-01-10T17:10:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
Sir Frederick wrote:
&gt; Another question :
&gt; Do cockroaches experience an &quot;I&quot;?
&gt; Do they experience anything?
">

They appear to be able to experience light and motion; as they run away
from both.  Since they don't have much of a brain, it's unlikely that
they'd experience any deep thoughts.
</POST>
<POST>
<POSTER> Publius &lt;m.publ...@nospam.comcast.net&gt; </POSTER>
<POSTDATE> 2007-01-10T17:50:00 </POSTDATE>
"George Dance" &lt;georgedanc ... @yahoo.ca&gt; wrote in news:1168467053.292037.45550
@p59g2000hsd.googlegroups.com:

<QUOTE PREVIOUSPOST="
&gt; Sir Frederick wrote:
&gt;&gt; Another question :
&gt;&gt; Do cockroaches experience an &quot;I&quot;?
&gt;&gt; Do they experience anything?
&gt; They appear to be able to experience light and motion; as they run away
&gt; from both.  Since they don't have much of a brain, it's unlikely that
&gt; they'd experience any deep thoughts.
">

"Deep" is vague, of course, but we probably underestimate the data processing
capabilities of insects. A study last year, for example, showed that
honeybees are capable of abstract reasoning. (They quickly learned that the
correct path in a maze was the one whose marker matched the marker at the
entrance, regardless of the particular markers used.) They also have
trichromatic vision, a sophisticated visual processing system, and
sophisticated communication ability, as described by von Frisch, et al.

http://en.wikipedia.org/wiki/Karl_von_Frisch

It suggests that the basic components or features of "thought" might be
accomplished by fairly simple neural structures. I suspect that if "qualia"
prove of value in explaining the behavior of humans, it will also be useful
in explaining that of bees.
</POST>
<POST>
<POSTER> "Immortalist" &lt;reanimater_2...@yahoo.com&gt; </POSTER>
<POSTDATE> 2007-01-10T23:53:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
Sir Frederick wrote:
&gt; Another question :
&gt; Do cockroaches experience an &quot;I&quot;?
&gt; Do they experience anything?
&gt; --
">

Is the "I" something that has to have a critical amount of neural
activities to be an "I" or are like blurry or faded "I's" Maybe there
is a range of "Iness" and all animals or other sufficient processes,
have some of it. If Iness is associated with self_awareness then many
creatures may not have it but may still have consciousness.
Consciousness is the real subject and the "I" is probably some later
evolved layers that help us say, wow, we have consciousness. But even
when not thinking about it with the I they may still be conscious. Who
knows?

<QUOTE PREVIOUSPOST="
&gt; Frederick Martin McNeill
&gt; Poway, California, United States of America
&gt; mmcne ... @fuzzysys.com
&gt; http://www.fuzzysys.com
&gt; http://members.cox.net/fmmcneill
&gt; *************************
&gt; &quot;LIFE IS ONE BIG MUDDLE. Sometimes you have to muddle more, sometimes you have to muddle less, but for all of us &quot;muddling through&quot; is the natural state of things. Luckily, while we muddle, we can surround ourselves with things we cherish. We can muddle nobly, happily and with a sense of purpose. We can choose to love and allow ourselves to be loved as we muddle.  Ultimately, if you want it to be and let it be, it's a beautiful muddle indeed.&quot;
&gt; --Dean Barrnett
&gt;  :-))))Snort!)
&gt; **************************************
">
</POST>
<POST>
<POSTER> "Wordsmith" &lt;wordsm...@rocketmail.com&gt; </POSTER>
<POSTDATE> 2007-01-11T01:09:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
Immortalist wrote:
&gt; Sir Frederick wrote:
&gt; &gt; Another question :
&gt; &gt; Do cockroaches experience an &quot;I&quot;?
&gt; &gt; Do they experience anything?
&gt; &gt; --

&gt; Is the &quot;I&quot; something that has to have a critical amount of neural
&gt; activities to be an &quot;I&quot; or are like blurry or faded &quot;I's&quot; Maybe there
&gt; is a range of &quot;Iness&quot; and all animals or other sufficient processes,
&gt; have some of it. If Iness is associated with self_awareness then many
&gt; creatures may not have it but may still have consciousness.
&gt; Consciousness is the real subject and the &quot;I&quot; is probably some later
&gt; evolved layers that help us say, wow, we have consciousness. But even
&gt; when not thinking about it with the I they may still be conscious. Who
&gt; knows?
">

Any animal with an "I" would have to be able to articulate its "I-ness"
via
rational symbols (language). A being can be conscious without an "I";
however,
it can't be *self*-conscious without one.

W : )

<QUOTE PREVIOUSPOST="
- Hide quoted text - - Show quoted text -
">

<QUOTE PREVIOUSPOST="
&gt; &gt; Frederick Martin McNeill
&gt; &gt; Poway, California, United States of America
&gt; &gt; mmcne ... @fuzzysys.com
&gt; &gt; http://www.fuzzysys.com
&gt; &gt; http://members.cox.net/fmmcneill
&gt; &gt; *************************
&gt; &gt; &quot;LIFE IS ONE BIG MUDDLE. Sometimes you have to muddle more, sometimes you have to muddle less, but for all of us &quot;muddling through&quot; is the natural state of things. Luckily, while we muddle, we can surround ourselves with things we cherish. We can muddle nobly, happily and with a sense of purpose. We can choose to love and allow ourselves to be loved as we muddle.  Ultimately, if you want it to be and let it be, it's a beautiful muddle indeed.&quot;
&gt; &gt; --Dean Barrnett
&gt; &gt;  :-))))Snort!)
&gt; &gt; **************************************
">
</POST>
<POST>
<POSTER> "sunson" &lt;sun...@gmail.com&gt; </POSTER>
<POSTDATE> 2007-01-11T05:31:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
Immortalist wrote:
&gt; have some of it. If Iness is associated with self_awareness then many
&gt; creatures may not have it but may still have consciousness.
&gt; Consciousness is the real subject and the &quot;I&quot; is probably some later
&gt; evolved layers that help us say, wow, we have consciousness. But even
&gt; when not thinking about it with the I they may still be conscious. Who
&gt; knows?
">

Than merely saying "wow, we have consciousness" I would look at the "I"
as a powerful tool that helps us in our survival. That one tends to
have a line running through all the past events of memory, that one can
model 'oneself' along with one's own environment and 'simulate'
possible outcomes of a given decision can definitely help vastly in
survival.

As a related note, I recommend this wonderful paper on "General
Intelligence and Seed AI":

http://www.singinst.org/ourresearch/publications/GISAI/index.html

cheers,

-Suraj
</POST>
<POST>
<POSTER> "Kan" &lt;k...@homeworld.com&gt; </POSTER>
<POSTDATE> 2007-01-11T07:01:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;Publius&quot; &lt;m.publ ... @nospam.comcast.net&gt; wrote in message
">

news:S6OdnVi1MrQm8DjYnZ2dnUVZ_ternZ2d@comcast.com ...

<QUOTE PREVIOUSPOST="
&gt; &quot;George Dance&quot; &lt;georgedanc ... @yahoo.ca&gt; wrote in
&gt; news:1168467053.292037.45550
&gt; @p59g2000hsd.googlegroups.com:

&gt;&gt; Sir Frederick wrote:
&gt;&gt;&gt; Another question :
&gt;&gt;&gt; Do cockroaches experience an &quot;I&quot;?
&gt;&gt;&gt; Do they experience anything?

&gt;&gt; They appear to be able to experience light and motion; as they run away
&gt;&gt; from both.  Since they don't have much of a brain, it's unlikely that
&gt;&gt; they'd experience any deep thoughts.

&gt; &quot;Deep&quot; is vague, of course, but we probably underestimate the data
&gt; processing
&gt; capabilities of insects. A study last year, for example, showed that
&gt; honeybees are capable of abstract reasoning. (They quickly learned that
&gt; the
&gt; correct path in a maze was the one whose marker matched the marker at the
&gt; entrance, regardless of the particular markers used.) They also have
&gt; trichromatic vision, a sophisticated visual processing system, and
&gt; sophisticated communication ability, as described by von Frisch, et al.

&gt; http://en.wikipedia.org/wiki/Karl_von_Frisch

&gt; It suggests that the basic components or features of &quot;thought&quot; might be
&gt; accomplished by fairly simple neural structures. I suspect that if
&gt; &quot;qualia&quot;
&gt; prove of value in explaining the behavior of humans, it will also be
&gt; useful
&gt; in explaining that of bees.
">

It is debatable that rather than an "I" insects may experience a "we" - they
seem to operate as a collective.
</POST>
<POST>
<POSTER> "George Dance" &lt;georgedanc...@yahoo.ca&gt; </POSTER>
<POSTDATE> 2007-01-11T08:09:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
Kan wrote:
&gt; &quot;Publius&quot; &lt;m.publ ... @nospam.comcast.net&gt; wrote in message
&gt; news:S6OdnVi1MrQm8DjYnZ2dnUVZ_ternZ2d@comcast.com ...
&gt; &gt; &quot;George Dance&quot; &lt;georgedanc ... @yahoo.ca&gt; wrote in
&gt; &gt; news:1168467053.292037.45550
&gt; &gt; @p59g2000hsd.googlegroups.com:

&gt; &gt;&gt; Sir Frederick wrote:
&gt; &gt;&gt;&gt; Another question :
&gt; &gt;&gt;&gt; Do cockroaches experience an &quot;I&quot;?
&gt; &gt;&gt;&gt; Do they experience anything?

&gt; &gt;&gt; They appear to be able to experience light and motion; as they run away
&gt; &gt;&gt; from both.  Since they don't have much of a brain, it's unlikely that
&gt; &gt;&gt; they'd experience any deep thoughts.

&gt; &gt; &quot;Deep&quot; is vague, of course, but we probably underestimate the data
&gt; &gt; processing
&gt; &gt; capabilities of insects. A study last year, for example, showed that
&gt; &gt; honeybees are capable of abstract reasoning. (They quickly learned that
&gt; &gt; the
&gt; &gt; correct path in a maze was the one whose marker matched the marker at the
&gt; &gt; entrance, regardless of the particular markers used.) They also have
&gt; &gt; trichromatic vision, a sophisticated visual processing system, and
&gt; &gt; sophisticated communication ability, as described by von Frisch, et al.

&gt; &gt; http://en.wikipedia.org/wiki/Karl_von_Frisch

&gt; &gt; It suggests that the basic components or features of &quot;thought&quot; might be
&gt; &gt; accomplished by fairly simple neural structures. I suspect that if
&gt; &gt; &quot;qualia&quot;
&gt; &gt; prove of value in explaining the behavior of humans, it will also be
&gt; &gt; useful
&gt; &gt; in explaining that of bees.

&gt; It is debatable that rather than an &quot;I&quot; insects may experience a &quot;we&quot; - they
&gt; seem to operate as a collective.
">

It's debatable whether insects experience anything.  They undoubtedly
respond to stimuli, but so do machines, and there's no reason to think
that machines experience anything; so that is no evidence.
</POST>
<POST>
<POSTER> "chazwin" &lt;chazwy...@yahoo.com&gt; </POSTER>
<POSTDATE> 2007-01-11T08:14:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
Sir Frederick wrote:
&gt; Another question :
&gt; Do cockroaches experience an &quot;I&quot;?
&gt; Do they experience anything?
">

Do you experience anything?

<QUOTE PREVIOUSPOST="
&gt; --
&gt; Frederick Martin McNeill
&gt; Poway, California, United States of America
&gt; mmcne ... @fuzzysys.com
&gt; http://www.fuzzysys.com
&gt; http://members.cox.net/fmmcneill
&gt; *************************
&gt; &quot;LIFE IS ONE BIG MUDDLE. Sometimes you have to muddle more, sometimes you have to muddle less, but for all of us &quot;muddling through&quot; is the natural state of things. Luckily, while we muddle, we can surround ourselves with things we cherish. We can muddle nobly, happily and with a sense of purpose. We can choose to love and allow ourselves to be loved as we muddle.  Ultimately, if you want it to be and let it be, it's a beautiful muddle indeed.&quot;
&gt; --Dean Barrnett
&gt;  :-))))Snort!)
&gt; **************************************
">
</POST>
<POST>
<POSTER> "Wanker" &lt;simonharp...@hotmail.co.uk&gt; </POSTER>
<POSTDATE> 2007-01-11T08:45:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
George Dance wrote:
&gt; Kan wrote:
&gt; &gt; &quot;Publius&quot; &lt;m.publ ... @nospam.comcast.net&gt; wrote in message
&gt; &gt; news:S6OdnVi1MrQm8DjYnZ2dnUVZ_ternZ2d@comcast.com ...
&gt; &gt; &gt; &quot;George Dance&quot; &lt;georgedanc ... @yahoo.ca&gt; wrote in
&gt; &gt; &gt; news:1168467053.292037.45550
&gt; &gt; &gt; @p59g2000hsd.googlegroups.com:

&gt; &gt; &gt;&gt; Sir Frederick wrote:
&gt; &gt; &gt;&gt;&gt; Another question :
&gt; &gt; &gt;&gt;&gt; Do cockroaches experience an &quot;I&quot;?
&gt; &gt; &gt;&gt;&gt; Do they experience anything?

&gt; &gt; &gt;&gt; They appear to be able to experience light and motion; as they run away
&gt; &gt; &gt;&gt; from both.  Since they don't have much of a brain, it's unlikely that
&gt; &gt; &gt;&gt; they'd experience any deep thoughts.

&gt; &gt; &gt; &quot;Deep&quot; is vague, of course, but we probably underestimate the data
&gt; &gt; &gt; processing
&gt; &gt; &gt; capabilities of insects. A study last year, for example, showed that
&gt; &gt; &gt; honeybees are capable of abstract reasoning. (They quickly learned that
&gt; &gt; &gt; the
&gt; &gt; &gt; correct path in a maze was the one whose marker matched the marker at the
&gt; &gt; &gt; entrance, regardless of the particular markers used.) They also have
&gt; &gt; &gt; trichromatic vision, a sophisticated visual processing system, and
&gt; &gt; &gt; sophisticated communication ability, as described by von Frisch, et al.

&gt; &gt; &gt; http://en.wikipedia.org/wiki/Karl_von_Frisch

&gt; &gt; &gt; It suggests that the basic components or features of &quot;thought&quot; might be
&gt; &gt; &gt; accomplished by fairly simple neural structures. I suspect that if
&gt; &gt; &gt; &quot;qualia&quot;
&gt; &gt; &gt; prove of value in explaining the behavior of humans, it will also be
&gt; &gt; &gt; useful
&gt; &gt; &gt; in explaining that of bees.

&gt; &gt; It is debatable that rather than an &quot;I&quot; insects may experience a &quot;we&quot; - they
&gt; &gt; seem to operate as a collective.

&gt; It's debatable whether insects experience anything.  They undoubtedly
&gt; respond to stimuli, but so do machines, and there's no reason to think
&gt; that machines experience anything; so that is no evidence.
">

Either that or response to stimuli isn't the whole answer.
</POST>
<POST>
<POSTER> "George Dance" &lt;georgedanc...@yahoo.ca&gt; </POSTER>
<POSTDATE> 2007-01-11T08:52:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
Wanker wrote:
&gt; George Dance wrote:
&gt; &gt; Kan wrote:
&gt; &gt; &gt; &quot;Publius&quot; &lt;m.publ ... @nospam.comcast.net&gt; wrote in message
&gt; &gt; &gt; news:S6OdnVi1MrQm8DjYnZ2dnUVZ_ternZ2d@comcast.com ...
&gt; &gt; &gt; &gt; &quot;George Dance&quot; &lt;georgedanc ... @yahoo.ca&gt; wrote in
&gt; &gt; &gt; &gt; news:1168467053.292037.45550
&gt; &gt; &gt; &gt; @p59g2000hsd.googlegroups.com:

&gt; &gt; &gt; &gt;&gt; Sir Frederick wrote:
&gt; &gt; &gt; &gt;&gt;&gt; Another question :
&gt; &gt; &gt; &gt;&gt;&gt; Do cockroaches experience an &quot;I&quot;?
&gt; &gt; &gt; &gt;&gt;&gt; Do they experience anything?

&gt; &gt; &gt; &gt;&gt; They appear to be able to experience light and motion; as they run away
&gt; &gt; &gt; &gt;&gt; from both.  Since they don't have much of a brain, it's unlikely that
&gt; &gt; &gt; &gt;&gt; they'd experience any deep thoughts.

&gt; &gt; &gt; &gt; &quot;Deep&quot; is vague, of course, but we probably underestimate the data
&gt; &gt; &gt; &gt; processing
&gt; &gt; &gt; &gt; capabilities of insects. A study last year, for example, showed that
&gt; &gt; &gt; &gt; honeybees are capable of abstract reasoning. (They quickly learned that
&gt; &gt; &gt; &gt; the
&gt; &gt; &gt; &gt; correct path in a maze was the one whose marker matched the marker at the
&gt; &gt; &gt; &gt; entrance, regardless of the particular markers used.) They also have
&gt; &gt; &gt; &gt; trichromatic vision, a sophisticated visual processing system, and
&gt; &gt; &gt; &gt; sophisticated communication ability, as described by von Frisch, et al.

&gt; &gt; &gt; &gt; http://en.wikipedia.org/wiki/Karl_von_Frisch

&gt; &gt; &gt; &gt; It suggests that the basic components or features of &quot;thought&quot; might be
&gt; &gt; &gt; &gt; accomplished by fairly simple neural structures. I suspect that if
&gt; &gt; &gt; &gt; &quot;qualia&quot;
&gt; &gt; &gt; &gt; prove of value in explaining the behavior of humans, it will also be
&gt; &gt; &gt; &gt; useful
&gt; &gt; &gt; &gt; in explaining that of bees.

&gt; &gt; &gt; It is debatable that rather than an &quot;I&quot; insects may experience a &quot;we&quot; - they
&gt; &gt; &gt; seem to operate as a collective.

&gt; &gt; It's debatable whether insects experience anything.  They undoubtedly
&gt; &gt; respond to stimuli, but so do machines, and there's no reason to think
&gt; &gt; that machines experience anything; so that is no evidence.

&gt; Either that or response to stimuli isn't the whole answer.
">

But their responses to stimuli is the only evidence that anything or
anyone (other than oneself) does experience anything.  Either one
argues that response to stimuli is all there is (as do the
behaviorists), in which case one has to conclude that machines are
conscious (as some behaviorists I've encountered do argue); or one has
the burden of defining what that something more is, and (as
importantly) how to tell whether anything has that or not; at which
point it becomes an empirical matter of discovering whether insects
have that something more or not.
</POST>
<POST>
<POSTER> "J.A.Legris" &lt;jaleg...@sympatico.ca&gt; </POSTER>
<POSTDATE> 2007-01-11T09:33:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
chazwin wrote:
&gt; Sir Frederick wrote:
&gt; &gt; Another question :
&gt; &gt; Do cockroaches experience an &quot;I&quot;?
&gt; &gt; Do they experience anything?

&gt; Do you experience anything?
">

I find that a useful way to think about questions such as this is to
imagine the point of view of an unconscious robot programmed to gather
data about earth creatures. It would never attribute self-consciousness
to anyone (or anything) unless its sensors were able to detect the
physical evidence of such. Not understanding language, it would have to
dissect (or otherwise scan or analyze) living human brains and
correlate the observed neural activity with the environmental
conditions to determine that humans are self-conscious. Likewise with
cockroaches. My prediction: yes, they are "slightly" self-conscious,
but they are mute on the subject. IMO any natural organism must have a
degree of self-consciousness, if only to avoid eating itself.

--
Joe Legris
</POST>
<POST>
<POSTER> Sir Frederick &lt;mmcne...@fuzzysys.com&gt; </POSTER>
<POSTDATE> 2007-01-11T09:43:00 </POSTDATE>
On 11 Jan 2007 05:14:18 -0800, "chazwin" &lt;chazwy ... @yahoo.com&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt;Sir Frederick wrote:
&gt;&gt; Another question :
&gt;&gt; Do cockroaches experience an &quot;I&quot;?
&gt;&gt; Do they experience anything?

&gt;Do you experience anything?
">

The virtual reality model of my "self" that is
constructed by my brain, includes experiencing
as an attribute. Since that model is also referenced
as the "you" ("you" equals "self"), that is
referenced in your post, then ,
yes, "you", experiences "anything" (virtually).
That's as good as it gets from a reductionistic
paradigm. From a holistic paradigm, there may be more.
</POST>
<POST>
<POSTER> "Wanker" &lt;simonharp...@hotmail.co.uk&gt; </POSTER>
<POSTDATE> 2007-01-11T11:10:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
George Dance wrote:
&gt; Wanker wrote:
&gt; &gt; George Dance wrote:
&gt; &gt; &gt; Kan wrote:
&gt; &gt; &gt; &gt; &quot;Publius&quot; &lt;m.publ ... @nospam.comcast.net&gt; wrote in message
&gt; &gt; &gt; &gt; news:S6OdnVi1MrQm8DjYnZ2dnUVZ_ternZ2d@comcast.com ...
&gt; &gt; &gt; &gt; &gt; &quot;George Dance&quot; &lt;georgedanc ... @yahoo.ca&gt; wrote in
&gt; &gt; &gt; &gt; &gt; news:1168467053.292037.45550
&gt; &gt; &gt; &gt; &gt; @p59g2000hsd.googlegroups.com:

&gt; &gt; &gt; &gt; &gt;&gt; Sir Frederick wrote:
&gt; &gt; &gt; &gt; &gt;&gt;&gt; Another question :
&gt; &gt; &gt; &gt; &gt;&gt;&gt; Do cockroaches experience an &quot;I&quot;?
&gt; &gt; &gt; &gt; &gt;&gt;&gt; Do they experience anything?

&gt; &gt; &gt; &gt; &gt;&gt; They appear to be able to experience light and motion; as they run away
&gt; &gt; &gt; &gt; &gt;&gt; from both.  Since they don't have much of a brain, it's unlikely that
&gt; &gt; &gt; &gt; &gt;&gt; they'd experience any deep thoughts.

&gt; &gt; &gt; &gt; &gt; &quot;Deep&quot; is vague, of course, but we probably underestimate the data
&gt; &gt; &gt; &gt; &gt; processing
&gt; &gt; &gt; &gt; &gt; capabilities of insects. A study last year, for example, showed that
&gt; &gt; &gt; &gt; &gt; honeybees are capable of abstract reasoning. (They quickly learned that
&gt; &gt; &gt; &gt; &gt; the
&gt; &gt; &gt; &gt; &gt; correct path in a maze was the one whose marker matched the marker at the
&gt; &gt; &gt; &gt; &gt; entrance, regardless of the particular markers used.) They also have
&gt; &gt; &gt; &gt; &gt; trichromatic vision, a sophisticated visual processing system, and
&gt; &gt; &gt; &gt; &gt; sophisticated communication ability, as described by von Frisch, et al.

&gt; &gt; &gt; &gt; &gt; http://en.wikipedia.org/wiki/Karl_von_Frisch

&gt; &gt; &gt; &gt; &gt; It suggests that the basic components or features of &quot;thought&quot; might be
&gt; &gt; &gt; &gt; &gt; accomplished by fairly simple neural structures. I suspect that if
&gt; &gt; &gt; &gt; &gt; &quot;qualia&quot;
&gt; &gt; &gt; &gt; &gt; prove of value in explaining the behavior of humans, it will also be
&gt; &gt; &gt; &gt; &gt; useful
&gt; &gt; &gt; &gt; &gt; in explaining that of bees.

&gt; &gt; &gt; &gt; It is debatable that rather than an &quot;I&quot; insects may experience a &quot;we&quot; - they
&gt; &gt; &gt; &gt; seem to operate as a collective.

&gt; &gt; &gt; It's debatable whether insects experience anything.  They undoubtedly
&gt; &gt; &gt; respond to stimuli, but so do machines, and there's no reason to think
&gt; &gt; &gt; that machines experience anything; so that is no evidence.

&gt; &gt; Either that or response to stimuli isn't the whole answer.

&gt; But their responses to stimuli is the only evidence that anything or
&gt; anyone (other than oneself) does experience anything.
">

I have lots of experience of wandering around in a daze but I don't
have any particular stimulus-responses I could offer as evidence of
that experience.

I guess what I'm driving at here is the question: When you say it's
debatable whether insects experience anything, in what sense are you
using the word 'experience'?

<QUOTE PREVIOUSPOST="
&gt; Either one argues that response to stimuli is all there is (as do the
&gt; behaviorists), in which case one has to conclude that machines are
&gt; conscious (as some behaviorists I've encountered do argue);
&gt; or one has the burden of defining what that something more is, and (as
&gt; importantly) how to tell whether anything has that or not; at which
&gt; point it becomes an empirical matter of discovering whether insects
&gt; have that something more or not.
">

I'm not convinced experience is all just a matter of stimulus/response.
For one thing 'experience' means many things - best be clear which of
those many things we're talking about. For another, even if we decide
that we'd like our analysis to encompass most everyday meanings of the
word there's more to experience than just "stimulus/response" unless
you're looking at this issue through behaviourist glasses (i.e. not
just trying to reduce any and all outcomes of experiments to one set of
easily classifiable data). I wouldn't, for example, characterise my
experiences of practicing the guitar as "stimulus/response": I'd
characterise most of them as "boring".

Now, obviously, insects don't have human language. This means we can't
do some of the things we'd do with other humans in order to verify
their experiences, viz: we can't have a conversation with them and ask
them what they make of "it all". But then again we can't do this with
very small children either. The difference between insects and children
in this regard is that although we have to judge our actions in regard
to babies in terms of stimulus/response eventually most children learn
language, while on the other hand insects never do. The barrier, when
looking at it this way is just that insects don't talk. But that seems
a rather facile analysis when it's put that baldly - even I want to say
that that can't be all there is to it. But other than a conviction that
it should, really, be more complicated than that I'd have a hard time
putting my finger on exactly what /the/ difference is. (Although the
fact that I've gone looking for /one/ thing rings many philosophical
alarm bells in my head - why should there be just /one/ difference -
why can't there be a whole raft of differences? Surely not just because
it's complicated that way - that would just be intellectual laziness
masquerading as science).
</POST>
<POST>
<POSTER> "andy-k" &lt;spam.free@last&gt; </POSTER>
<POSTDATE> 2007-01-11T12:29:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;Wanker&quot; wrote:
&gt; When you say it's debatable whether insects experience
&gt; anything, in what sense are you using the word 'experience'?
">

In the sense that it's debatable whether insects are associated with a
qualitative phenomenal perspective upon a world that is similar to *this*
phenomenal perspective upon a world that considers itself to be "me".

"P-consciousness is experience. P-conscious properties are experiential
properties. P-conscious states are experiential states, that is, a state is
P-conscious if it has experiential properties. The totality of the
experiential properties of a state are "what it is like" to have it. Moving
from synonyms to examples, we have P-conscious states when we see, hear,
smell, taste and have pains. P-conscious properties include the experiential
properties of sensations, feelings and perceptions, but I would also include
thoughts, wants and emotions."

-- Block, N. (1995) "On a Confusion About a Function of Consciousness,"
Behavioral and Brain Sciences 18: 227-247.
</POST>
<POST>
<POSTER> "Immortalist" &lt;reanimater_2...@yahoo.com&gt; </POSTER>
<POSTDATE> 2007-01-11T12:42:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
Wordsmith wrote:
&gt; Immortalist wrote:
&gt; &gt; Sir Frederick wrote:
&gt; &gt; &gt; Another question :
&gt; &gt; &gt; Do cockroaches experience an &quot;I&quot;?
&gt; &gt; &gt; Do they experience anything?
&gt; &gt; &gt; --

&gt; &gt; Is the &quot;I&quot; something that has to have a critical amount of neural
&gt; &gt; activities to be an &quot;I&quot; or are like blurry or faded &quot;I's&quot; Maybe there
&gt; &gt; is a range of &quot;Iness&quot; and all animals or other sufficient processes,
&gt; &gt; have some of it. If Iness is associated with self_awareness then many
&gt; &gt; creatures may not have it but may still have consciousness.
&gt; &gt; Consciousness is the real subject and the &quot;I&quot; is probably some later
&gt; &gt; evolved layers that help us say, wow, we have consciousness. But even
&gt; &gt; when not thinking about it with the I they may still be conscious. Who
&gt; &gt; knows?

&gt; Any animal with an &quot;I&quot; would have to be able to articulate its &quot;I-ness&quot;
&gt; via
&gt; rational symbols (language). A being can be conscious without an &quot;I&quot;;
&gt; however,
&gt; it can't be *self*-conscious without one.

&gt; W : )
">

So when a bug or a cow "experiences" orgasm or some good chow, it
cannot "experience" these activities? Kant might respond that we are
confusing (REPRESENTATIONS) here. Re-pre-sentations are interacting and
this "I" thing probably isn't necessary for many experiences. Memories
of orgasm could be activated in the animal, but in humans we have
different ways to trigger these memories. Is that all the I is, a group
of representations which interact with conscious experience and
memories?

------------------------------------------

"It must be possible," as Kant put it in a key paragraph, "for the 'I
think' to accompany all my representations; for otherwise something
would be represented in me which could not be thought at all, and that
is equivalent to saying that the representation would be impossible, or
at least would be nothing to me." (In one of the grander
understatements of his whole oeuvre, Kant concludes that paragraph by
simply noting: "From this original combination, many consequences
follow.'") Kant's point about the way in which the "I think" must be
able, in his words, to "accompany" any representation was that unless
it were possible for me to become aware of a representation as a
representation - to become aware of my experience of the stone as an
experience of the stone - then that representation would be as nothing
for me; and that any representation must therefore meet the conditions
under which it could become an object of such reflective awareness.
That particular move, of course, meant that the condition for any
representation's being a representation (having some cognitive content,
being experienced as a representation (of something) had to do with the
conditions of self-consciousness itself.

Kant's term for the kind of self-consciousness involved in such a
thought is apperception, the awareness of something as an awareness
(which itself is a condition of being able to separate the object from
the representation of the object). The question then was: what is the
nature of this apperception?

Any representation of a multiplicity as a multiplicity involves not
merely the receptivity of experience; experiencing it as one
experiential multiplicity requires the possibility of there being a
single complex thought of the experience. The unity of the multiplicity
of experience is therefore in Kant's words a "synthetic unity of
representations." A single complex thought, however, requires a single
complex subject to think it since a single complex thought could not be
distributed among different thinking subjects. (A single complex
thought might be something like, "The large black stone is lying on the
ground" - different subjects could think different elements of the
complex, such as "large," "black," etc., but that would not add up to a
single thought; it would only be a series of different thoughts.) Thus,
we need one complex thinking subject to have a single complex thought.

On Kant's picture therefore, we have on the one hand the identity of
the thinking subject, and on the other hand the multiplicity of the
representations which it has. The same complex thinking subject - as
the same subject of different experiences - is correlated therefore to
the "synthetic" unity of the multiplicity of experience. On the basis
of this, Kant drew his most basic conclusion: a condition of both the
synthetic unity of the multiplicity of representations (and what he
called the analytic unity of apperception) is the synthetic unity of
apperception.* That the "I that experiences or thinks about X" is the
same "I that experiences or thinks about Y" is, after all, not an
analytic truth. (From "somebody thought of Kant" and "somebody thought
of Hume," it does not follow that it was the same person who thought of
both Kant and Hume.) On the other hand, it is absolutely necessary that
all the different experiences be ascribed to the same thinking subject,
that they be capable of being "accompanied" by the same "I think."
Since it is both necessary (and therefore only know-able a priori), and
also synthetic (not a self-contradiction to deny), the judgment that I
have a unity of self-consciousness is, odd as it sounds, a synthetic a
priori judgment.

*I am here following Beatrice Longuenesse in taking the analytic unity
of apperception to be that consciousness in which the synthetic unity
is "reflected," that is, "thought" or judged by means of concepts. See
Longuenesse, Kant and the Capacity to Judge, p. 73. On her account,
synthesizing "by means of analytic unity" is bringing several intuitive
representations under one concept or bringing several concepts under a
concept of greater universality. See Kant and the Capacity to Judge, p.
81.

What follows from that? Whatever is necessary for my being able to
comprehend myself as the same thinking subject over a series of
temporally extended experiences is also necessary for representations
in general to be representations, that is, to have cognitive content,
to be not merely internal, subjective occurrences within one's mental
life but to be about something - which brings Kant around to another
version of his original question: how can a representation be about
anything at all?

If there is any way in which the intuitive representations in our
consciousness must be combined, then that "must" embodies the
conditions under which anything can be a "representation" at all; and
the key to understanding what might be further implied by that move,
Kant noted, lay in the very idea of judgment itself, the topic with
which he had begun the Critique. To make a judgment - to assert
something that can be true or false - is different in kind from merely
associating some idea with some other idea. To make a judgment is to
submit oneself to the norms that govern such judgments. It is, however,
simply a matter of fact and not of norms whether I associate, for
example, "Kant" with Prussia or Germany or long walks in the afternoon,
or, for that matter, with disquisitions on the proper way to throw
dinner parties. To make a judgment is to do something that is subject
to standards of correctness, whereas to associate something with
something else is neither to be correct nor incorrect - it is simply a
fact about one's psychic life.

Judgments themselves, as normative matters, are combinations therefore
of two different types of representations into a unity according to the
rules of right judgment. This, in turn, showed that concepts could not
simply be abstractions from intuitions: a concept is a rule for
synthesis in judgments; in Kant's words, a concept is a "unity of the
act of bringing various representations under one common
representation." Since intuitions cannot produce the unity of such
combination themselves, they cannot combine themselves into judgments;
only concepts can combine (that is, "synthesize") such experiential
items. To have a concept, Kant argued, is be in possession of a norm, a
rule of "synthesis" for a judgment. Having a concept is more like
having an ability - an ability to combine representations according to
certain norms - than it is like having any kind of internal mental
state.

All this finally comes together, Kant argued, when we think about the
conditions under which we could become apperceptively self-conscious as
thinking subjects. For me to be aware of myself as a thinking being is
to be aware of myself as a unity of experience - as a kind of unified
viewpoint on the world - and that unity must be brought about by myself
in the activity of combining representations into judgmental form. In
combining the multiplicity of sensuous intuitions into a "synthetic
unity" (in seeing my experience as more than a series of subjective,
psychic events, but instead as a connected series of representations of
things), I combine the elements of that experience (intuitions)
according to the rules that are necessary for such combinations.
Establishing the necessity of these rules thus must consist in looking
at how sensuous intuitions must be combined if we are to make judgments
about them - if we are to be able to say even mundane things like, "Oh,
it looks green in that light, but really it's blue." The most basic of
those concepts would therefore be the basic concepts necessary in
experience in general, or, to use Kant's reinvention of Aristotle's
classical term, would be the necessary categories of all possible
experience. (Kant defined a category as a "concept of an object in
general, by means of which the intuition of an object is regarded as
determined in respect of one of the logical functions of judgment.")
Indeed, without such categories, we could not see our intuitions as
representations at all. They would be merely psychic occurrences,
things that were either there or not, happened or did not happen, not
be items that could be said to be adequate or inadequate, correct or
incorrect, true or false.

To see them as representations, moreover, is to see them as
representations of an object.
...
read more »
</POST>
<POST>
<POSTER> "knock down the milk bottles, win a prize" &lt;drksn_b...@yahoo.com&gt; </POSTER>
<POSTDATE> 2007-01-11T13:12:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
Sir Frederick wrote:
&gt; Another question :
&gt; Do cockroaches experience an &quot;I&quot;?
">

Isn't that just a concept? Regardless of how it is instantiated
beforehand, how would "self" be expressed in experience without audible
or visual language? As a feeling? Pre-verbal toddlers are being taught
sign-language today, but even if they could sign that they have a
feeling of "I", they would already have been corrupted by language
acquistion. The feeling might only be caused by having learned the sign
for "I". In the end, "self" as a purely sensational circumstance,
without concept, would seem to consist of one's experience having a
boundary, where it ceases to be the whole universe. That probably has
to be framed by a concept just to know that it is a boundary, though.

<QUOTE PREVIOUSPOST="
&gt; Do they experience anything?
">

Intuitions must be synthesized with concepts to become experience or
things must be abstracted from raw data to become detectable. I'm not
sure what a bare intuition is before that; I'm unable to think about it
at all without the later stage.

..
</POST>
<POST>
<POSTER> "andy-k" &lt;spam.free@last&gt; </POSTER>
<POSTDATE> 2007-01-11T14:40:00 </POSTDATE>
"knock down the milk bottles, win a prize" wrote:

<QUOTE PREVIOUSPOST="
&gt; Sir Frederick wrote:
&gt;&gt; Another question :
&gt;&gt; Do cockroaches experience an &quot;I&quot;?

&gt; Isn't that just a concept? Regardless of how it is instantiated
&gt; beforehand, how would &quot;self&quot; be expressed in experience without audible
&gt; or visual language? As a feeling? Pre-verbal toddlers are being taught
&gt; sign-language today, but even if they could sign that they have a
&gt; feeling of &quot;I&quot;, they would already have been corrupted by language
&gt; acquistion. The feeling might only be caused by having learned the sign
&gt; for &quot;I&quot;. In the end, &quot;self&quot; as a purely sensational circumstance,
&gt; without concept, would seem to consist of one's experience having a
&gt; boundary, where it ceases to be the whole universe. That probably has
&gt; to be framed by a concept just to know that it is a boundary, though.
">

Good post. It's conceivable, though, that a species might acquire an idea
of self simply because it's of practical utility for an organism to model
itself as part of its own world model. There's evidence that Chimpanzees
have just such an idea, even though they are not language users.
</POST>
<POST>
<POSTER> "Miller" &lt;chumley...@chartermi.net&gt; </POSTER>
<POSTDATE> 2007-01-11T06:43:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;Immortalist&quot; &lt;reanimater_2 ... @yahoo.com&gt; wrote in message
">

news:1168491227.279794.29950@i56g2000hsf.googlegroups.com ...

<QUOTE PREVIOUSPOST="
&gt; Sir Frederick wrote:
&gt;&gt; Another question :
&gt;&gt; Do cockroaches experience an &quot;I&quot;?
&gt;&gt; Do they experience anything?
&gt;&gt; --

&gt; Is the &quot;I&quot; something that has to have a critical amount of neural
&gt; activities to be an &quot;I&quot; or are like blurry or faded &quot;I's&quot; Maybe there
&gt; is a range of &quot;Iness&quot; and all animals or other sufficient processes,
&gt; have some of it. If Iness is associated with self_awareness then many
&gt; creatures may not have it but may still have consciousness.
&gt; Consciousness is the real subject and the &quot;I&quot; is probably some later
&gt; evolved layers that help us say, wow, we have consciousness. But even
&gt; when not thinking about it with the I they may still be conscious. Who
&gt; knows?
">

I would think that if a being is not self-aware, then any application of the
idea that that being has some sort of "I-ness" about it is moot.  Likewise,
what is consciousness?  It is always consciousness OF something.
Consciousness of self would seem to me to be a reasonable definition of
I-ness.  So if the being is not self-conscious, I do not see what use it
would be to speculate whether or not it has any conception of "I".

Scott
</POST>
<POST>
<POSTER> Publius &lt;m.publ...@nospam.comcast.net&gt; </POSTER>
<POSTDATE> 2007-01-11T22:31:00 </POSTDATE>
"andy-k" &lt;spam.free@last&gt; wrote in news:Kowph.15061$696.12786@newsfe7-
win.ntli.net:

<QUOTE PREVIOUSPOST="
&gt; &quot;knock down the milk bottles, win a prize&quot; wrote:
&gt;&gt; Sir Frederick wrote:
&gt;&gt;&gt; Another question :
&gt;&gt;&gt; Do cockroaches experience an &quot;I&quot;?

&gt;&gt; Isn't that just a concept? Regardless of how it is instantiated
&gt;&gt; beforehand, how would &quot;self&quot; be expressed in experience without audible
&gt;&gt; or visual language? As a feeling? Pre-verbal toddlers are being taught
&gt;&gt; sign-language today, but even if they could sign that they have a
&gt;&gt; feeling of &quot;I&quot;, they would already have been corrupted by language
&gt;&gt; acquistion. The feeling might only be caused by having learned the sign
&gt;&gt; for &quot;I&quot;. In the end, &quot;self&quot; as a purely sensational circumstance,
&gt;&gt; without concept, would seem to consist of one's experience having a
&gt;&gt; boundary, where it ceases to be the whole universe. That probably has
&gt;&gt; to be framed by a concept just to know that it is a boundary, though.
&gt; Good post. It's conceivable, though, that a species might acquire an idea
&gt; of self simply because it's of practical utility for an organism to model
&gt; itself as part of its own world model. There's evidence that Chimpanzees
&gt; have just such an idea, even though they are not language users.
">

Actually it is inescapable. Any organism with a nervous system complex
enough to be able to model its environment --- able to discern patterns in
data arriving over multiple channels and "algorithmize" them into objects
(conceptual structures), and then situate those objects in a world model,
will, early on, notice a difference among those patterns: Some of those
percepts can be altered at will, and others cannot.

Hume missed the mark with his "bundle theory" of the self. Sensory
impressions sort themselves into two bundles, not one. How is that sorting
done? Imagine that you are viewing a television image of a part of your
body you seldom see, e.g, the bottom of your foot. Beside it on the screen
is an image of someone else's foot (chosen to match yours fairly closely).
How can you decide which is is yours? Well, wiggle your toes, of course.
The image whose toes are wiggling in sync with your will is of your foot.

Percepts of "external" things which are responsive to the will are sorted
into the category "self;" all others are "other." And then there are
percepts of "internal" states (those which are not correlated with visual
or tactile data). E.g., hunger, being sleepy, etc. Those are likewise
responsive to the will. So they also become part of the "self" model, which
is then situated in the world model.

Human (and also chimpanzee) infants differentiate "self" from "other" by
about age 2 months. But it seems likely that any organism which models its
environment will quickly make that differentiation.

Hume complained that in examining his perceptions he encountered none
corresponding to the self. But he was looking for the wrong thing. The self
is not a specific percept, but a class of them which is readily
distinguishable from non-self.
</POST>
<POST>
<POSTER> "andy-k" &lt;spam.free@last&gt; </POSTER>
<POSTDATE> 2007-01-12T03:03:00 </POSTDATE>
How would you say the acquisition of language impacts on the idea of self?
</POST>
<POST>
<POSTER> "Wanker" &lt;simonharp...@hotmail.co.uk&gt; </POSTER>
<POSTDATE> 2007-01-12T07:41:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
andy-k wrote:
&gt; &quot;Wanker&quot; wrote:
&gt; &gt; When you say it's debatable whether insects experience
&gt; &gt; anything, in what sense are you using the word 'experience'?

&gt; In the sense that it's debatable whether insects are associated with a
&gt; qualitative phenomenal perspective upon a world that is similar to *this*
&gt; phenomenal perspective upon a world that considers itself to be &quot;me&quot;.
">

Do you mean: Their experiences are likely to be quite dissimilar from
ours? I agree - I don't have an exoskeleton or compound eyes. There are
likely to be other dissimilarities too. What makes you think there are
/no/ similarities, or (a little kinder) no /significant/ similarities?

<QUOTE PREVIOUSPOST="
&gt; &quot;P-consciousness is experience. P-conscious properties are experiential
&gt; properties. P-conscious states are experiential states, that is, a state is
&gt; P-conscious if it has experiential properties. The totality of the
&gt; experiential properties of a state are &quot;what it is like&quot; to have it. Moving
&gt; from synonyms to examples, we have P-conscious states when we see, hear,
&gt; smell, taste and have pains. P-conscious properties include the experiential
&gt; properties of sensations, feelings and perceptions, but I would also include
&gt; thoughts, wants and emotions.&quot;
&gt; -- Block, N. (1995) &quot;On a Confusion About a Function of Consciousness,&quot;
&gt; Behavioral and Brain Sciences 18: 227-247.
">

Uh-huh. None of which has defined the term 'experience' except to say
"Anything we'd like to count as experience - it's that". IOW: That's no
definition at all! And what, exactly is the introduction of the terms
'P-conscious' and 'P-consciousness' supposed to achieve when from the
foregoing it seems that "P-conscious' and 'P-consciousness' simply mean
'experience' and 'experiential' - why not use the words 'experience'
and 'experiential' and have done with it? I'm all for technical terms,
but not when they're simply replacements for existing words. The above
just sounds like pseudo-technical bollocks of the worst possible kind
to me.
</POST>
<POST>
<POSTER> "andy-k" &lt;spam.free@last&gt; </POSTER>
<POSTDATE> 2007-01-12T08:44:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;Wanker&quot; wrote:
&gt; andy-k wrote:
&gt;&gt; &quot;Wanker&quot; wrote:
&gt;&gt; &gt; When you say it's debatable whether insects experience
&gt;&gt; &gt; anything, in what sense are you using the word 'experience'?

&gt;&gt; In the sense that it's debatable whether insects are associated with a
&gt;&gt; qualitative phenomenal perspective upon a world that is similar to *this*
&gt;&gt; phenomenal perspective upon a world that considers itself to be &quot;me&quot;.

&gt; Do you mean: Their experiences are likely to be quite dissimilar from
&gt; ours? I agree - I don't have an exoskeleton or compound eyes. There
&gt; are likely to be other dissimilarities too. What makes you think there are
&gt; /no/ similarities, or (a little kinder) no /significant/ similarities?
">

That's not what I think -- what I think is that George has a point when
he says it's debatable whether insects experience anything.
This is a perhaps less controversial version of the zombie problem.

<QUOTE PREVIOUSPOST="
&gt;&gt; &quot;P-consciousness is experience. P-conscious properties are experiential
&gt;&gt; properties. P-conscious states are experiential states, that is, a state
&gt;&gt; is P-conscious if it has experiential properties. The totality of the
&gt;&gt; experiential properties of a state are &quot;what it is like&quot; to have it.
&gt;&gt; Moving from synonyms to examples, we have P-conscious states when we see,
&gt;&gt; hear, smell, taste and have pains. P-conscious properties include the
&gt;&gt; experiential properties of sensations, feelings and perceptions, but I
&gt;&gt; would also include thoughts, wants and emotions.&quot;

&gt;&gt; -- Block, N. (1995) &quot;On a Confusion About a Function of Consciousness,&quot;
&gt;&gt; Behavioral and Brain Sciences 18: 227-247.

&gt; Uh-huh. None of which has defined the term 'experience' except to say
&gt; &quot;Anything we'd like to count as experience - it's that&quot;. IOW: That's no
&gt; definition at all! And what, exactly is the introduction of the terms
&gt; 'P-conscious' and 'P-consciousness' supposed to achieve when from the
&gt; foregoing it seems that &quot;P-conscious' and 'P-consciousness' simply mean
&gt; 'experience' and 'experiential' - why not use the words 'experience'
&gt; and 'experiential' and have done with it? I'm all for technical terms,
&gt; but not when they're simply replacements for existing words. The above
&gt; just sounds like pseudo-technical bollocks of the worst possible kind
&gt; to me.
">

I'm not taking an adversarial position, but rather implying a concern about
the way these words are used. Ned Block makes the distinction between
phenomenal consciousness and access consciousness in order to clear
up some of the confusion, but I'm not sure he succeeds:
http://www.bbsonline.org/Preprints/OldArchive/bbs.block.html

My take on this is that when we use terms like "experience" or "conscious
experience" or "consciousness" or "awareness" or "conscious awareness",
we're often trying to say the unsayable, but that shouldn't be taken as a
trivialization of the point. I have total conviction that when somebody else
traps their finger in the door it hurts like hell, just as it would for me
if I trapped my finger in the door. *That* is the sense in which I use these
terms.
</POST>
<POST>
<POSTER> "George Dance" &lt;georgedanc...@yahoo.ca&gt; </POSTER>
<POSTDATE> 2007-01-12T10:47:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
Wanker wrote:
&gt; George Dance wrote:
&gt; &gt; Wanker wrote:
&gt; &gt; &gt; George Dance wrote:
&gt; &gt; &gt; &gt; Kan wrote:
&gt; &gt; &gt; &gt; &gt; &quot;Publius&quot; &lt;m.publ ... @nospam.comcast.net&gt; wrote in message
&gt; &gt; &gt; &gt; &gt; news:S6OdnVi1MrQm8DjYnZ2dnUVZ_ternZ2d@comcast.com ...
&gt; &gt; &gt; &gt; &gt; &gt; &quot;George Dance&quot; &lt;georgedanc ... @yahoo.ca&gt; wrote in
&gt; &gt; &gt; &gt; &gt; &gt; news:1168467053.292037.45550
&gt; &gt; &gt; &gt; &gt; &gt; @p59g2000hsd.googlegroups.com:

&gt; &gt; &gt; &gt; &gt; &gt;&gt; Sir Frederick wrote:
&gt; &gt; &gt; &gt; &gt; &gt;&gt;&gt; Another question :
&gt; &gt; &gt; &gt; &gt; &gt;&gt;&gt; Do cockroaches experience an &quot;I&quot;?
&gt; &gt; &gt; &gt; &gt; &gt;&gt;&gt; Do they experience anything?

&gt; &gt; &gt; &gt; &gt; &gt;&gt; They appear to be able to experience light and motion; as they run away
&gt; &gt; &gt; &gt; &gt; &gt;&gt; from both.  Since they don't have much of a brain, it's unlikely that
&gt; &gt; &gt; &gt; &gt; &gt;&gt; they'd experience any deep thoughts.

&gt; &gt; &gt; &gt; &gt; &gt; &quot;Deep&quot; is vague, of course, but we probably underestimate the data
&gt; &gt; &gt; &gt; &gt; &gt; processing
&gt; &gt; &gt; &gt; &gt; &gt; capabilities of insects. A study last year, for example, showed that
&gt; &gt; &gt; &gt; &gt; &gt; honeybees are capable of abstract reasoning. (They quickly learned that
&gt; &gt; &gt; &gt; &gt; &gt; the
&gt; &gt; &gt; &gt; &gt; &gt; correct path in a maze was the one whose marker matched the marker at the
&gt; &gt; &gt; &gt; &gt; &gt; entrance, regardless of the particular markers used.) They also have
&gt; &gt; &gt; &gt; &gt; &gt; trichromatic vision, a sophisticated visual processing system, and
&gt; &gt; &gt; &gt; &gt; &gt; sophisticated communication ability, as described by von Frisch, et al.

&gt; &gt; &gt; &gt; &gt; &gt; http://en.wikipedia.org/wiki/Karl_von_Frisch

&gt; &gt; &gt; &gt; &gt; &gt; It suggests that the basic components or features of &quot;thought&quot; might be
&gt; &gt; &gt; &gt; &gt; &gt; accomplished by fairly simple neural structures. I suspect that if
&gt; &gt; &gt; &gt; &gt; &gt; &quot;qualia&quot;
&gt; &gt; &gt; &gt; &gt; &gt; prove of value in explaining the behavior of humans, it will also be
&gt; &gt; &gt; &gt; &gt; &gt; useful
&gt; &gt; &gt; &gt; &gt; &gt; in explaining that of bees.

&gt; &gt; &gt; &gt; &gt; It is debatable that rather than an &quot;I&quot; insects may experience a &quot;we&quot; - they
&gt; &gt; &gt; &gt; &gt; seem to operate as a collective.

&gt; &gt; &gt; &gt; It's debatable whether insects experience anything.  They undoubtedly
&gt; &gt; &gt; &gt; respond to stimuli, but so do machines, and there's no reason to think
&gt; &gt; &gt; &gt; that machines experience anything; so that is no evidence.

&gt; &gt; &gt; Either that or response to stimuli isn't the whole answer.

&gt; &gt; But their responses to stimuli is the only evidence that anything or
&gt; &gt; anyone (other than oneself) does experience anything.

&gt; I have lots of experience of wandering around in a daze but I don't
&gt; have any particular stimulus-responses I could offer as evidence of
&gt; that experience.
">

Yes, but I ruled out personal experiences anyway.  I'll take it as a
given that I have those, and expect you to do the same.

<QUOTE PREVIOUSPOST="
&gt; I guess what I'm driving at here is the question: When you say it's
&gt; debatable whether insects experience anything, in what sense are you
&gt; using the word 'experience'?
">

That's a good question.  I think I mean what andy means by
'P-consciousness,' but he's talking over both our heads, so I'll try to
come at it in a different way.

We do not experience everything our bodies do or everything around us -
we normally don't experience breathing, for instance, or the blood
flowing through our bodies, or the lymph glands secreting their
chemicals.  All that can be called 'automatic behavior' - experience
isn't necessary for any of that, since I do it and don't hav any
experience of it.

Cockroaches run from light and motion, and are attracted to food.  When
I do things like that, I do experience them - the difference between
that and breathing being that, whenever I do run towards or away from
something, I'm aware at the time that I'm doing that.  Which gives a
first approximation at a definition of experience:  "awareness of an
event."  Cockroaches could be aware of what they're doing, or their
behavior could all be automatic, like my breathing.

<QUOTE PREVIOUSPOST="
&gt; &gt; Either one argues that response to stimuli is all there is (as do the
&gt; &gt; behaviorists), in which case one has to conclude that machines are
&gt; &gt; conscious (as some behaviorists I've encountered do argue);
&gt; &gt; or one has the burden of defining what that something more is, and (as
&gt; &gt; importantly) how to tell whether anything has that or not; at which
&gt; &gt; point it becomes an empirical matter of discovering whether insects
&gt; &gt; have that something more or not.

&gt; I'm not convinced experience is all just a matter of stimulus/response.
&gt; For one thing 'experience' means many things - best be clear which of
&gt; those many things we're talking about.
">

I'm sure we can come up with a lot of different examples of experiences
- in which case it's a matter of trying to find a word that covers them
all.  Using approximations to a definition makes the process easier;
either we go with experience as awareness, or find just one example
where that definition doesn't fit.

<QUOTE PREVIOUSPOST="
&gt; For another, even if we decide
&gt; that we'd like our analysis to encompass most everyday meanings of the
&gt; word there's more to experience than just &quot;stimulus/response&quot; unless
&gt; you're looking at this issue through behaviourist glasses (i.e. not
&gt; just trying to reduce any and all outcomes of experiments to one set of
&gt; easily classifiable data).
">

I think we can rejet 'stimulus/response' as a criterion of experience,
even learned stimulus/responses (like the type Pavlov conditioned into
his dogs).

<QUOTE PREVIOUSPOST="
&gt; I wouldn't, for example, characterise my
&gt; experiences of practicing the guitar as &quot;stimulus/response&quot;: I'd
&gt; characterise most of them as &quot;boring&quot;.
">

They undoubtedly involved responding to stimuli, though - repeating
chords when you got them wrong, and stuff like that.  Though I'd say
that you were aware of them, and conjecture that the fact of your
awareness made a difference in how you responded.

I'd compre that with the chickens who've been taught to play piano;
they respond simply to food stimuli that gradually reinforces an ever
more complex behavior pattern.  They're not aware that they're playing
songs on the piano, and thus have no experience of that.  What they do
seem to be aware of, and therefore to experience, is that they're going
through a certain ceremony that results in the appearance of food.

<QUOTE PREVIOUSPOST="
- Hide quoted text - - Show quoted text -
">

<QUOTE PREVIOUSPOST="
&gt; Now, obviously, insects don't have human language. This means we can't
&gt; do some of the things we'd do with other humans in order to verify
&gt; their experiences, viz: we can't have a conversation with them and ask
&gt; them what they make of &quot;it all&quot;. But then again we can't do this with
&gt; very small children either. The difference between insects and children
&gt; in this regard is that although we have to judge our actions in regard
&gt; to babies in terms of stimulus/response eventually most children learn
&gt; language, while on the other hand insects never do. The barrier, when
&gt; looking at it this way is just that insects don't talk. But that seems
&gt; a rather facile analysis when it's put that baldly - even I want to say
&gt; that that can't be all there is to it. But other than a conviction that
&gt; it should, really, be more complicated than that I'd have a hard time
&gt; putting my finger on exactly what /the/ difference is. (Although the
&gt; fact that I've gone looking for /one/ thing rings many philosophical
&gt; alarm bells in my head - why should there be just /one/ difference -
&gt; why can't there be a whole raft of differences? Surely not just because
&gt; it's complicated that way - that would just be intellectual laziness
&gt; masquerading as science).
">

Occam's Razor; the simpler theory is preferable to the more complicated
one because it's easier to test, falsify, and modify.  (That process
may result in a more complicated one.)

For now, I'm sticking with 'experience as awareness' until there's a
good counterexample.
</POST>
<POST>
<POSTER> "andy-k" &lt;spam.free@last&gt; </POSTER>
<POSTDATE> 2007-01-12T12:01:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;George Dance&quot; wrote:
&gt; I think I mean what andy means by 'P-consciousness,' but he's talking over
&gt; both our heads
">

I'm sure I'm not -- it's more likely that I'm just not making myself
understood. I find this a very difficult subject to approach because the
words just stop making sense. I think that's why people like Thomas Nagel
are reduced to woolly phrases such as the "what it's like".
</POST>
<POST>
<POSTER> "BORG" &lt;b...@homeworld.com&gt; </POSTER>
<POSTDATE> 2007-01-12T15:21:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;Sir Frederick&quot; &lt;mmcne ... @fuzzysys.com&gt; wrote in message
">

news:konaq2lnijqui7e7d21j336k5jk5kgl7pr@4ax.com ...

<QUOTE PREVIOUSPOST="
&gt; Another question :
&gt; Do cockroaches experience an &quot;I&quot;?
&gt; Do they experience anything?
&gt; --
">

Why do you equate human collective to cockroach?
Why can you not find more pleasant example.
Why do you not move on.
Progress.
Learn.
Four about 3-4 years now - you talk of nothing but human - qualia - and
cockroach.
Do you have no experience in life to teach you of other things?
Why do you not write stories?
Stories should only be told - not written.
Stories change.
When men set stories into written word - they set the past into the present.
The imagination and compassion of storyteller was lost.
The old will never fit into the new.
You have no comprehension of 2000 years past as you have no comprehension of
2000 years future.
The hero then is not the hero now.
In times long ago - where no TV or radio or books - all was about
communication.
The storyteller would "feel" as all sentient beings do - the looks in the
eyes - the sway of emotion.
A hero.  Honour.  Loyalty.  Faithfulness.
All men wish the same things.
They travel too fast - there is no time to reflect - on whether deeply this
is correct.
All becomes bland.
And the hero becomes meaningless.
Until the hero exists no more.
</POST>
<POST>
<POSTER> "Dianelos Georgoudis" &lt;diane...@tecapro.com&gt; </POSTER>
<POSTDATE> 2007-01-12T18:09:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
Publius wrote:
">

[snip]

<QUOTE PREVIOUSPOST="
&gt; Actually it is inescapable. Any organism with a nervous system complex
&gt; enough to be able to model its environment --- able to discern patterns in
&gt; data arriving over multiple channels and &quot;algorithmize&quot; them into objects
&gt; (conceptual structures), and then situate those objects in a world model,
&gt; will, early on, notice a difference among those patterns: Some of those
&gt; percepts can be altered at will, and others cannot.

&gt; Hume missed the mark with his &quot;bundle theory&quot; of the self. Sensory
&gt; impressions sort themselves into two bundles, not one. How is that sorting
&gt; done? Imagine that you are viewing a television image of a part of your
&gt; body you seldom see, e.g, the bottom of your foot. Beside it on the screen
&gt; is an image of someone else's foot (chosen to match yours fairly closely).
&gt; How can you decide which is is yours? Well, wiggle your toes, of course.
&gt; The image whose toes are wiggling in sync with your will is of your foot.

&gt; Percepts of &quot;external&quot; things which are responsive to the will are sorted
&gt; into the category &quot;self;&quot; all others are &quot;other.&quot; And then there are
&gt; percepts of &quot;internal&quot; states (those which are not correlated with visual
&gt; or tactile data). E.g., hunger, being sleepy, etc. Those are likewise
&gt; responsive to the will. So they also become part of the &quot;self&quot; model, which
&gt; is then situated in the world model.
">

Yes, and as all models this too is only approximate. If considered
carefully one sees that internal-external is not a binary variable but
rather a continuum. So in the external direction a wall, for example,
is very little responsive to our will and in the other direction our
thoughts are very responsive. Somewhere in between fits our body. My
fingers are quite responsive but I can't will them to move anyway I
like; my heart is less responsive than my fingers but more responsive
than a wall. I don't think there is word that describes the quantity of
responsiveness (or unresponsiveness) to our will, but it seems to me
that the word "physical" describes the direction of unresponsiveness.
In an experiential environment in which there is no resistance to one's
will, nothing will be seen as physical ISTM.

<QUOTE PREVIOUSPOST="
&gt; Human (and also chimpanzee) infants differentiate &quot;self&quot; from &quot;other&quot; by
&gt; about age 2 months. But it seems likely that any organism which models its
&gt; environment will quickly make that differentiation.
">

Still I believe all the talk of "self", or of modeling one's own body
as present in the model of one's environment, is only used to give the
impression we understand something about consciousness, and nudge the
discussion of consciousness towards the non-hard problem of
intelligence. But we can conceive of a being of vanishingly low
intelligence that is nevertheless conscious, and also of a being that
is extremely intelligent but not conscious (a philosophical zombie).
The question is how to find out whether such beings are instantiated in
reality. Take the OP's question about cockroaches. Suppose it's true
that that cockroaches model themselves within their model of the
environment (actually I believe that *is* true). Then cockroaches have
the notion of "self". How does this fact help us answer the OP's
question of whether cockroaches have conscious experience or not? In no
way at all. So, the talk about the self or about self-consciousness is
just blowing smoke around the problem of consciousness.

In fact I find it remarkable that that same materialist can confidently
claim that conscious experience is produced by the human brain, while
at the same being unable to explain how to find out whether conscious
experience is produced anywhere else. Imagine somebody confidently
claiming that X is produced in Greece but being unable to explain how
to find out whether X is also produced in Italy or in my garage: one
would reasonably conclude that that person knows not what they are
talking about.
</POST>
<POST>
<POSTER> Publius &lt;m.publ...@nospam.comcast.net&gt; </POSTER>
<POSTDATE> 2007-01-13T02:27:00 </POSTDATE>
"andy-k" &lt;spam.free@last&gt; wrote in news:ZgHph.55654$HV6.23443@newsfe1-
gui.ntli.net:

<QUOTE PREVIOUSPOST="
&gt; How would you say the acquisition of language impacts on the idea of self?
">

Language allows us to tag that concept (that bundle of percepts) and
thereafter manipulate it via the tag. Just as with all other concepts.
</POST>
<POST>
<POSTER> Publius &lt;m.publ...@nospam.comcast.net&gt; </POSTER>
<POSTDATE> 2007-01-13T03:19:00 </POSTDATE>
"Dianelos Georgoudis" &lt;diane ... @tecapro.com&gt; wrote in
news:1168643351.079827.159990@51g2000cwl.googlegroups.com:

<QUOTE PREVIOUSPOST="
&gt; Yes, and as all models this too is only approximate. If considered
&gt; carefully one sees that internal-external is not a binary variable but
&gt; rather a continuum. So in the external direction a wall, for example,
&gt; is very little responsive to our will and in the other direction our
&gt; thoughts are very responsive. Somewhere in between fits our body. My
&gt; fingers are quite responsive but I can't will them to move anyway I
&gt; like; my heart is less responsive than my fingers but more responsive
&gt; than a wall. I don't think there is word that describes the quantity of
&gt; responsiveness (or unresponsiveness) to our will, but it seems to me
&gt; that the word &quot;physical&quot; describes the direction of unresponsiveness.
&gt; In an experiential environment in which there is no resistance to one's
&gt; will, nothing will be seen as physical ISTM.
">

All models are only approximate (a fact we know, not because we can compare
them with "reality," but because we always seem to find ways to improve
them). But I think the responsive-to-the-will distinction is quite sharp.
The wall is not "very little responsive," but nonresponsive. Your fingers
are responsive (though, being physical objects, are constrained by physical
laws).

<QUOTE PREVIOUSPOST="
&gt; Still I believe all the talk of &quot;self&quot;, or of modeling one's own body
&gt; as present in the model of one's environment, is only used to give the
&gt; impression we understand something about consciousness, and nudge the
&gt; discussion of consciousness towards the non-hard problem of
&gt; intelligence. But we can conceive of a being of vanishingly low
&gt; intelligence that is nevertheless conscious, and also of a being that
&gt; is extremely intelligent but not conscious (a philosophical zombie).
">

I agree that intelligence does not equate to consciousness. But (as you
know) I suspect that being able to construct a dynamic model (of the right
kind) of a system in real time constitutes consciousness. I.e., that any
system we encounter that is able to do that, and is able to communicate,
will pass the Turing Test, and systems that cannot do it will not.

<QUOTE PREVIOUSPOST="
&gt; The question is how to find out whether such beings are instantiated in
&gt; reality. Take the OP's question about cockroaches. Suppose it's true
&gt; that that cockroaches model themselves within their model of the
&gt; environment (actually I believe that *is* true). Then cockroaches have
&gt; the notion of &quot;self&quot;. How does this fact help us answer the OP's
&gt; question of whether cockroaches have conscious experience or not? In no
&gt; way at all. So, the talk about the self or about self-consciousness is
&gt; just blowing smoke around the problem of consciousness.
">

The question is unanswerable because we have (at present) no means of
communicating with roaches. But should we discover that roaches nervous
systems are constructed in the right way, then we'd probably attribute
consciousness anyway, just because theory predicts it.

<QUOTE PREVIOUSPOST="
&gt; In fact I find it remarkable that that same materialist can confidently
&gt; claim that conscious experience is produced by the human brain, while
&gt; at the same being unable to explain how to find out whether conscious
&gt; experience is produced anywhere else. Imagine somebody confidently
&gt; claiming that X is produced in Greece but being unable to explain how
&gt; to find out whether X is also produced in Italy or in my garage: one
&gt; would reasonably conclude that that person knows not what they are
&gt; talking about.
">

But we can explain "how to find out" --- e.g., by producing consciousness
in man-made systems. Or by discovering it in other natural, non-biological
systems. The difficulties are not conceptual but practical, like the
question of whether there is life on Mars.
</POST>
<POST>
<POSTER> Publius &lt;m.publ...@nospam.comcast.net&gt; </POSTER>
<POSTDATE> 2007-01-13T03:41:00 </POSTDATE>
Publius &lt;m.publ ... @nospam.comcast.net&gt; wrote in
news:CqOdnf0LR8ZtFDXYnZ2dnUVZ_smonZ2d@comcast.com:

<QUOTE PREVIOUSPOST="
&gt; &quot;andy-k&quot; &lt;spam.free@last&gt; wrote in news:ZgHph.55654$HV6.23443@newsfe1-
&gt; gui.ntli.net:

&gt;&gt; How would you say the acquisition of language impacts on the idea of
&gt;&gt; self?

&gt; Language allows us to tag that concept (that bundle of percepts) and
&gt; thereafter manipulate it via the tag. Just as with all other concepts.
">

That may be a bit misleading. The concept is not equivalent to the bundle of
percepts, but is a model of it.
</POST>
<POST>
<POSTER> Sir Frederick &lt;mmcne...@fuzzysys.com&gt; </POSTER>
<POSTDATE> 2007-01-13T07:01:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
On Fri, 12 Jan 2007 20:21:38 GMT, &quot;BORG&quot; &lt;b ... @homeworld.com&gt; wrote:

&gt;&quot;Sir Frederick&quot; &lt;mmcne ... @fuzzysys.com&gt; wrote in message
&gt; news:konaq2lnijqui7e7d21j336k5jk5kgl7pr@4ax.com ...
&gt;&gt; Another question :
&gt;&gt; Do cockroaches experience an &quot;I&quot;?
&gt;&gt; Do they experience anything?
&gt;&gt; --

&gt;Why do you equate human collective to cockroach?
&gt;Why can you not find more pleasant example.
&gt;Why do you not move on.
&gt;Progress.
&gt;Learn.
&gt;Four about 3-4 years now - you talk of nothing but human - qualia - and
&gt;cockroach.
&gt;Do you have no experience in life to teach you of other things?
&gt;Why do you not write stories?
&gt;Stories should only be told - not written.
&gt;Stories change.
&gt;When men set stories into written word - they set the past into the present.
&gt;The imagination and compassion of storyteller was lost.
&gt;The old will never fit into the new.
&gt;You have no comprehension of 2000 years past as you have no comprehension of
&gt;2000 years future.
&gt;The hero then is not the hero now.
&gt;In times long ago - where no TV or radio or books - all was about
&gt;communication.
&gt;The storyteller would &quot;feel&quot; as all sentient beings do - the looks in the
&gt;eyes - the sway of emotion.
&gt;A hero.  Honour.  Loyalty.  Faithfulness.
&gt;All men wish the same things.
&gt;They travel too fast - there is no time to reflect - on whether deeply this
&gt;is correct.
&gt;All becomes bland.
&gt;And the hero becomes meaningless.
&gt;Until the hero exists no more.
">

Since the human body is fifty to ninety percent bacteria and other
single celled nonhuman little bugs, what can you expect?

Same for cockroaches.
</POST>
<POST>
<POSTER> "Tim" &lt;q...@qwerty.com&gt; </POSTER>
<POSTDATE> 2007-01-13T09:00:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;Sir Frederick&quot; &lt;mmcne ... @fuzzysys.com&gt; wrote in message
">

news:90ihq259s64l08hkbq55buos1hu2qggb4p@4ax.com ...

<QUOTE PREVIOUSPOST="
&gt; On Fri, 12 Jan 2007 20:21:38 GMT, &quot;BORG&quot; &lt;b ... @homeworld.com&gt; wrote:

&gt;&gt;&quot;Sir Frederick&quot; &lt;mmcne ... @fuzzysys.com&gt; wrote in message
&gt;&gt; news:konaq2lnijqui7e7d21j336k5jk5kgl7pr@4ax.com ...
&gt;&gt;&gt; Another question :
&gt;&gt;&gt; Do cockroaches experience an &quot;I&quot;?
&gt;&gt;&gt; Do they experience anything?
&gt;&gt;&gt; --

&gt;&gt;Why do you equate human collective to cockroach?
&gt;&gt;Why can you not find more pleasant example.
&gt;&gt;Why do you not move on.
&gt;&gt;Progress.
&gt;&gt;Learn.
&gt;&gt;Four about 3-4 years now - you talk of nothing but human - qualia - and
&gt;&gt;cockroach.
&gt;&gt;Do you have no experience in life to teach you of other things?
&gt;&gt;Why do you not write stories?
&gt;&gt;Stories should only be told - not written.
&gt;&gt;Stories change.
&gt;&gt;When men set stories into written word - they set the past into the
&gt;&gt;present.
&gt;&gt;The imagination and compassion of storyteller was lost.
&gt;&gt;The old will never fit into the new.
&gt;&gt;You have no comprehension of 2000 years past as you have no comprehension
&gt;&gt;of
&gt;&gt;2000 years future.
&gt;&gt;The hero then is not the hero now.
&gt;&gt;In times long ago - where no TV or radio or books - all was about
&gt;&gt;communication.
&gt;&gt;The storyteller would &quot;feel&quot; as all sentient beings do - the looks in the
&gt;&gt;eyes - the sway of emotion.
&gt;&gt;A hero.  Honour.  Loyalty.  Faithfulness.
&gt;&gt;All men wish the same things.
&gt;&gt;They travel too fast - there is no time to reflect - on whether deeply
&gt;&gt;this
&gt;&gt;is correct.
&gt;&gt;All becomes bland.
&gt;&gt;And the hero becomes meaningless.
&gt;&gt;Until the hero exists no more.

&gt; Since the human body is fifty to ninety percent bacteria and other
&gt; single celled nonhuman little bugs, what can you expect?

&gt; Same for cockroaches.
">

I'm sure that you could significantly reduce that percentage if you were to
buy and use a toothbrush.
http://www.fuzzysys.com/
</POST>
<POST>
<POSTER> Sir Frederick &lt;mmcne...@fuzzysys.com&gt; </POSTER>
<POSTDATE> 2007-01-13T09:26:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
On Sat, 13 Jan 2007 09:00:40 -0500, &quot;criminal Tim&quot; &lt;q ... @qwerty.com&gt; wrote:

&gt;&gt; Since the human body is fifty to ninety percent bacteria and other
&gt;&gt; single celled nonhuman little bugs, what can you expect?

&gt;&gt; Same for cockroaches.

&gt;I'm sure that you could significantly reduce that percentage if you were to
&gt;buy and use a toothbrush.
&gt; http://www.fuzzysys.com/
">

Criminal Timmy (100% bacteria) :
Cataracts at the time kept me from seeing
my own face.
</POST>
<POST>
<POSTER> "Tim" &lt;q...@qwerty.com&gt; </POSTER>
<POSTDATE> 2007-01-13T09:28:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;Sir Frederick&quot; &lt;mmcne ... @fuzzysys.com&gt; wrote in message
">

news:mhqhq29ntmcvpt39tl7oh459vtf7med8lq@4ax.com ...

<QUOTE PREVIOUSPOST="
&gt; On Sat, 13 Jan 2007 09:00:40 -0500, &quot;criminal Tim&quot; &lt;q ... @qwerty.com&gt;
&gt; wrote:

&gt;&gt;&gt; Since the human body is fifty to ninety percent bacteria and other
&gt;&gt;&gt; single celled nonhuman little bugs, what can you expect?

&gt;&gt;&gt; Same for cockroaches.

&gt;&gt;I'm sure that you could significantly reduce that percentage if you were
&gt;&gt;to
&gt;&gt;buy and use a toothbrush.
&gt;&gt; http://www.fuzzysys.com/

&gt; Criminal Timmy (100% bacteria) :
&gt; Cataracts at the time kept me from seeing
&gt; my own face.
">

You lucky bastard. The rest of us must suffer.
</POST>
<POST>
<POSTER> "andy-k" &lt;spam.free@last&gt; </POSTER>
<POSTDATE> 2007-01-13T11:23:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;Publius&quot; wrote:
&gt; Publius wrote:
&gt;&gt; &quot;andy-k&quot; wrote:
&gt;&gt;&gt; How would you say the acquisition of language
&gt;&gt;&gt; impacts on the idea of self?

&gt;&gt; Language allows us to tag that concept (that bundle of percepts) and
&gt;&gt; thereafter manipulate it via the tag. Just as with all other concepts.
&gt; That may be a bit misleading. The concept is not equivalent to the
&gt; bundle of percepts, but is a model of it.
">

I think I would go a little further than that. The fact that we treat
the word 'self' as a noun gives the impression that the self is
substantive --  i.e. we reify it. I don't see that as a problem in
itself (after all, we do the same with ideas like 'electron' to good
practical effect), but the self stands in a class of its own...

Within the conceptual world model the self is conceived as
an organism within its environment, which leads to the idea that
the conceptual framework itself is an internal representation of
an "external reality" (indirect realism). We say that the self is
"experiencing" an internal representation of its environment,
making the self the "experiencer" and its environment the
"experienced", but leaves the mechanism of "experiencing"
unaddressed (i.e. how the conceived boundary between internal
and external is bridged) -- what Chalmers calls the "hard problem".

Would it be fair to say, then, that Chalmers' "hard problem" is
a misconceived problem resulting from our use of language?
</POST>
<POST>
<POSTER> Sir Frederick &lt;mmcne...@fuzzysys.com&gt; </POSTER>
<POSTDATE> 2007-01-13T11:44:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
On Sat, 13 Jan 2007 09:28:37 -0500, &quot;Tim&quot; &lt;q ... @qwerty.com&gt; wrote:

&gt;You lucky bastard. The rest of us must suffer.
">

OK, I changed the pic to you.
</POST>
<POST>
<POSTER> Publius &lt;m.publ...@nospam.comcast.net&gt; </POSTER>
<POSTDATE> 2007-01-14T02:21:00 </POSTDATE>
"andy-k" &lt;spam.free@last&gt; wrote in news:mI7qh.46491$1W1.39116@newsfe4-
win.ntli.net:

<QUOTE PREVIOUSPOST="
&gt; I think I would go a little further than that. The fact that we treat
&gt; the word 'self' as a noun gives the impression that the self is
&gt; substantive --  i.e. we reify it. I don't see that as a problem in
&gt; itself (after all, we do the same with ideas like 'electron' to good
&gt; practical effect), but the self stands in a class of its own...
">

The self is "substantive" and "real" in the same sense in which anything else
is "substantive" and "real." Things are "real" if they are represented in our
world model and have predictive power (one type of which is
intersubjectivity). In other words, if the concept of the "self" contributes
to rendering experience coherent, then it is real.

It is not in a class of its own, however, provided one's model postulates
other selves. And again, one either postulates that, or doesn't, according to
which option yields the more fruitful explanations of experience.

<QUOTE PREVIOUSPOST="
&gt; Within the conceptual world model the self is conceived as
&gt; an organism within its environment, which leads to the idea that
&gt; the conceptual framework itself is an internal representation of
&gt; an &quot;external reality&quot; (indirect realism). We say that the self is
&gt; &quot;experiencing&quot; an internal representation of its environment,
&gt; making the self the &quot;experiencer&quot; and its environment the
&gt; &quot;experienced&quot;, but leaves the mechanism of &quot;experiencing&quot;
&gt; unaddressed (i.e. how the conceived boundary between internal
&gt; and external is bridged) -- what Chalmers calls the &quot;hard problem&quot;.
">

I'm sure you're referring to Chalmers' "explanatory gap." The mechanisms of
experiencing are not left unaddressed; that is what neurophysiology strives
to do. But of course for Chalmers those theories do not bridge the
"explanatory gap."

<QUOTE PREVIOUSPOST="
&gt; Would it be fair to say, then, that Chalmers' &quot;hard problem&quot; is
&gt; a misconceived problem resulting from our use of language?
">

I think it is misconceived, but not as a result of misuse of language. It
conflates two problems into one, and one of them (e.g., "Why does red look
red?") is unanswerable in principle.

I have a paper in progress on that problem. When I have a presentable draft
I'll put it somewhere with a link here. I'd enjoy hearing your comments.
Don't hold your breath, though --- it may be a couple of months.
</POST>
<POST>
<POSTER> "andy-k" &lt;spam.free@last&gt; </POSTER>
<POSTDATE> 2007-01-14T15:15:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;Publius&quot; wrote:
&gt; &quot;andy-k&quot; wrote:
&gt;&gt; I think I would go a little further than that. The fact that we treat
&gt;&gt; the word 'self' as a noun gives the impression that the self is
&gt;&gt; substantive --  i.e. we reify it. I don't see that as a problem in
&gt;&gt; itself (after all, we do the same with ideas like 'electron' to good
&gt;&gt; practical effect), but the self stands in a class of its own...

&gt; The self is &quot;substantive&quot; and &quot;real&quot; in the same sense in which
&gt; anything  else is &quot;substantive&quot; and &quot;real.&quot; Things are &quot;real&quot; if they are
&gt; represented in our world model and have predictive power (one type
&gt; of which is intersubjectivity). In other words, if the concept of the
&gt; &quot;self&quot; contributes to rendering experience coherent, then it is real.
">

I have to agree with your comment that "the self is substantive in
the same sense in which anything else is substantive", since the
philosophical idea of "substance" is a complete enigma to me.

<QUOTE PREVIOUSPOST="
&gt; It is not in a class of its own, however, provided one's model postulates
&gt; other selves. And again, one either postulates that, or doesn't, according
&gt; to which option yields the more fruitful explanations of experience.
">

Correct me if I'm wrong, but I believe there are two ways to
identify a concept -- firstly we may define boundary conditions
that give us membership criteria, and secondly we may give
paradigm cases of what does and what does not qualify.
The reason I single-out the concept of self for particular attention
is that I find both these methods to be problematic for that concept.

<QUOTE PREVIOUSPOST="
&gt;&gt; Within the conceptual world model the self is conceived as
&gt;&gt; an organism within its environment, which leads to the idea that
&gt;&gt; the conceptual framework itself is an internal representation of
&gt;&gt; an &quot;external reality&quot; (indirect realism). We say that the self is
&gt;&gt; &quot;experiencing&quot; an internal representation of its environment,
&gt;&gt; making the self the &quot;experiencer&quot; and its environment the
&gt;&gt; &quot;experienced&quot;, but leaves the mechanism of &quot;experiencing&quot;
&gt;&gt; unaddressed (i.e. how the conceived boundary between internal
&gt;&gt; and external is bridged) -- what Chalmers calls the &quot;hard problem&quot;.

&gt; I'm sure you're referring to Chalmers' &quot;explanatory gap.&quot; The mechanisms
&gt; of experiencing are not left unaddressed; that is what neurophysiology
&gt; strives to do. But of course for Chalmers those theories do not bridge the
&gt; &quot;explanatory gap.&quot;
">

I'm confident we're addressing the same issue.

<QUOTE PREVIOUSPOST="
&gt;&gt; Would it be fair to say, then, that Chalmers' &quot;hard problem&quot; is
&gt;&gt; a misconceived problem resulting from our use of language?

&gt; I think it is misconceived, but not as a result of misuse of language.
&gt; It conflates two problems into one, and one of them (e.g., &quot;Why does
&gt; red look red?&quot;) is unanswerable in principle.

&gt; I have a paper in progress on that problem. When I have a presentable
&gt; draft I'll put it somewhere with a link here. I'd enjoy hearing your
&gt; comments. Don't hold your breath, though --- it may be a couple of months.
">

I look forward to reading your views on the issue.
</POST>
<POST>
<POSTER> "Tim" &lt;q...@qwerty.com&gt; </POSTER>
<POSTDATE> 2007-01-15T08:33:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;Sir Frederick&quot; &lt;mmcne ... @fuzzysys.com&gt; wrote in message
">

news:iu2iq2539clu07757bjkphn32utj9bbd7f@4ax.com ...

<QUOTE PREVIOUSPOST="
&gt; On Sat, 13 Jan 2007 09:28:37 -0500, &quot;Tim&quot; &lt;q ... @qwerty.com&gt; wrote:

&gt;&gt;You lucky bastard. The rest of us must suffer.

&gt; OK, I changed the pic to you.
">

Much better. Fuck me I'm good looking. Alas I'll soon be extinct; but on the
good side so will that stupid species called humanity.
</POST>
<POST>
<POSTER> "Wanker" &lt;simonharp...@hotmail.co.uk&gt; </POSTER>
<POSTDATE> 2007-01-15T08:57:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
George Dance wrote:
&gt; Wanker wrote:
&gt; &gt; George Dance wrote:
&gt; &gt; &gt; Wanker wrote:
&gt; &gt; &gt; &gt; George Dance wrote:
&gt; &gt; &gt; &gt; &gt; Kan wrote:
&gt; &gt; &gt; &gt; &gt; &gt; &quot;Publius&quot; &lt;m.publ ... @nospam.comcast.net&gt; wrote in message
&gt; &gt; &gt; &gt; &gt; &gt; news:S6OdnVi1MrQm8DjYnZ2dnUVZ_ternZ2d@comcast.com ...
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &quot;George Dance&quot; &lt;georgedanc ... @yahoo.ca&gt; wrote in
&gt; &gt; &gt; &gt; &gt; &gt; &gt; news:1168467053.292037.45550
&gt; &gt; &gt; &gt; &gt; &gt; &gt; @p59g2000hsd.googlegroups.com:

&gt; &gt; &gt; &gt; &gt; &gt; &gt;&gt; Sir Frederick wrote:
&gt; &gt; &gt; &gt; &gt; &gt; &gt;&gt;&gt; Another question :
&gt; &gt; &gt; &gt; &gt; &gt; &gt;&gt;&gt; Do cockroaches experience an &quot;I&quot;?
&gt; &gt; &gt; &gt; &gt; &gt; &gt;&gt;&gt; Do they experience anything?

&gt; &gt; &gt; &gt; &gt; &gt; &gt;&gt; They appear to be able to experience light and motion; as they run away
&gt; &gt; &gt; &gt; &gt; &gt; &gt;&gt; from both.  Since they don't have much of a brain, it's unlikely that
&gt; &gt; &gt; &gt; &gt; &gt; &gt;&gt; they'd experience any deep thoughts.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; &quot;Deep&quot; is vague, of course, but we probably underestimate the data
&gt; &gt; &gt; &gt; &gt; &gt; &gt; processing
&gt; &gt; &gt; &gt; &gt; &gt; &gt; capabilities of insects. A study last year, for example, showed that
&gt; &gt; &gt; &gt; &gt; &gt; &gt; honeybees are capable of abstract reasoning. (They quickly learned that
&gt; &gt; &gt; &gt; &gt; &gt; &gt; the
&gt; &gt; &gt; &gt; &gt; &gt; &gt; correct path in a maze was the one whose marker matched the marker at the
&gt; &gt; &gt; &gt; &gt; &gt; &gt; entrance, regardless of the particular markers used.) They also have
&gt; &gt; &gt; &gt; &gt; &gt; &gt; trichromatic vision, a sophisticated visual processing system, and
&gt; &gt; &gt; &gt; &gt; &gt; &gt; sophisticated communication ability, as described by von Frisch, et al.

&gt; &gt; &gt; &gt; &gt; &gt; &gt; http://en.wikipedia.org/wiki/Karl_von_Frisch

&gt; &gt; &gt; &gt; &gt; &gt; &gt; It suggests that the basic components or features of &quot;thought&quot; might be
&gt; &gt; &gt; &gt; &gt; &gt; &gt; accomplished by fairly simple neural structures. I suspect that if
&gt; &gt; &gt; &gt; &gt; &gt; &gt; &quot;qualia&quot;
&gt; &gt; &gt; &gt; &gt; &gt; &gt; prove of value in explaining the behavior of humans, it will also be
&gt; &gt; &gt; &gt; &gt; &gt; &gt; useful
&gt; &gt; &gt; &gt; &gt; &gt; &gt; in explaining that of bees.

&gt; &gt; &gt; &gt; &gt; &gt; It is debatable that rather than an &quot;I&quot; insects may experience a &quot;we&quot; - they
&gt; &gt; &gt; &gt; &gt; &gt; seem to operate as a collective.

&gt; &gt; &gt; &gt; &gt; It's debatable whether insects experience anything.  They undoubtedly
&gt; &gt; &gt; &gt; &gt; respond to stimuli, but so do machines, and there's no reason to think
&gt; &gt; &gt; &gt; &gt; that machines experience anything; so that is no evidence.

&gt; &gt; &gt; &gt; Either that or response to stimuli isn't the whole answer.

&gt; &gt; &gt; But their responses to stimuli is the only evidence that anything or
&gt; &gt; &gt; anyone (other than oneself) does experience anything.

&gt; &gt; I have lots of experience of wandering around in a daze but I don't
&gt; &gt; have any particular stimulus-responses I could offer as evidence of
&gt; &gt; that experience.

&gt; Yes, but I ruled out personal experiences anyway.  I'll take it as a
&gt; given that I have those, and expect you to do the same.

&gt; &gt; I guess what I'm driving at here is the question: When you say it's
&gt; &gt; debatable whether insects experience anything, in what sense are you
&gt; &gt; using the word 'experience'?

&gt; That's a good question.  I think I mean what andy means by
&gt; 'P-consciousness,' but he's talking over both our heads, so I'll try to
&gt; come at it in a different way.

&gt; We do not experience everything our bodies do or everything around us -
&gt; we normally don't experience breathing, for instance, or the blood
&gt; flowing through our bodies, or the lymph glands secreting their
&gt; chemicals.  All that can be called 'automatic behavior' - experience
&gt; isn't necessary for any of that, since I do it and don't have any
&gt; experience of it.

&gt; Cockroaches run from light and motion, and are attracted to food.  When
&gt; I do things like that, I do experience them - the difference between
&gt; that and breathing being that, whenever I do run towards or away from
&gt; something, I'm aware at the time that I'm doing that.  Which gives a
&gt; first approximation at a definition of experience:  &quot;awareness of an
&gt; event.&quot;  Cockroaches could be aware of what they're doing, or their
&gt; behavior could all be automatic, like my breathing.
">

Sure, I accept what you're saying, except to say that some things would
seem to fall into either category (either of 'aware' or 'not aware'). I
can run without necessarily paying much attention to what I'm doing,
although frankly I tend to get that more when I'm walking (I'm not a
natural runner and it requires some determination on my part to get my
legs to move more swifly than a snail's pace).

But I guess the fact that I can sometimes be unaware doesn't negate the
fact that sometimes I'm aware as well.

I'd love to say that there are 'levels' of awareness at this point, but
I'm not sure what quantitative proof (or scale) would help me clarify
what I mean. It might be truer to say there are different kinds of
awareness.

Could be cockroaches have a kind of 'basic' awareness - perhaps the
kind you might get if you drink a lot of beer and then sit still / do
Zen meditation - I can feel my heartbeat, but there aren't any thoughts
associated with it. On the other hand there's a certain amount of
"learning to differentiate" in learning language - I wonder if animals
that haven't learned language can still differentiate between different
kinds of feelings like that or whether it's just one undifferentiated
experience (in which case one might wonder whether it's an experience
of any kind at all).

<QUOTE PREVIOUSPOST="
- Hide quoted text - - Show quoted text -
">

<QUOTE PREVIOUSPOST="
&gt; &gt; &gt; Either one argues that response to stimuli is all there is (as do the
&gt; &gt; &gt; behaviorists), in which case one has to conclude that machines are
&gt; &gt; &gt; conscious (as some behaviorists I've encountered do argue);
&gt; &gt; &gt; or one has the burden of defining what that something more is, and (as
&gt; &gt; &gt; importantly) how to tell whether anything has that or not; at which
&gt; &gt; &gt; point it becomes an empirical matter of discovering whether insects
&gt; &gt; &gt; have that something more or not.

&gt; &gt; I'm not convinced experience is all just a matter of stimulus/response.
&gt; &gt; For one thing 'experience' means many things - best be clear which of
&gt; &gt; those many things we're talking about.

&gt; I'm sure we can come up with a lot of different examples of experiences
&gt; - in which case it's a matter of trying to find a word that covers them
&gt; all.  Using approximations to a definition makes the process easier;
&gt; either we go with experience as awareness, or find just one example
&gt; where that definition doesn't fit.
">

No, the awareness definition is fine.

<QUOTE PREVIOUSPOST="
- Hide quoted text - - Show quoted text -
">

<QUOTE PREVIOUSPOST="
&gt; &gt; For another, even if we decide
&gt; &gt; that we'd like our analysis to encompass most everyday meanings of the
&gt; &gt; word there's more to experience than just &quot;stimulus/response&quot; unless
&gt; &gt; you're looking at this issue through behaviourist glasses (i.e. not
&gt; &gt; just trying to reduce any and all outcomes of experiments to one set of
&gt; &gt; easily classifiable data).

&gt; I think we can rejet 'stimulus/response' as a criterion of experience,
&gt; even learned stimulus/responses (like the type Pavlov conditioned into
&gt; his dogs).

&gt; &gt; I wouldn't, for example, characterise my
&gt; &gt; experiences of practicing the guitar as &quot;stimulus/response&quot;: I'd
&gt; &gt; characterise most of them as &quot;boring&quot;.

&gt; They undoubtedly involved responding to stimuli, though - repeating
&gt; chords when you got them wrong, and stuff like that.  Though I'd say
&gt; that you were aware of them, and conjecture that the fact of your
&gt; awareness made a difference in how you responded.
">

I think it depends what you want to say, really. There's a deal of
playing automatically when you're learning any instrument, and although
'awareness' (in a general sense) is something you need to have when
playing it's also something you learn to develop - I can hear bum notes
and bad tone now where I couldn't before simply in virtue of having
done so much of this stuff (and having my attention directed to the
right things by my teacher).

I think what I find curious about this topic is that for a great many
things I'm not sure 'awareness' (again in that general sense) is
necessary, or even that it happens. Guess I think humans are much more
thoughtless than they'd like themselves to believe. I've been told by a
psychology grad. that humans do in fact spend about 70%-80% of their
time doing things automagically - I've yet to find any hard numbers to
back this up, but it seems about par for the course.

<QUOTE PREVIOUSPOST="
&gt; I'd compre that with the chickens who've been taught to play piano;
&gt; they respond simply to food stimuli that gradually reinforces an ever
&gt; more complex behavior pattern.  They're not aware that they're playing
&gt; songs on the piano, and thus have no experience of that.  What they do
&gt; seem to be aware of, and therefore to experience, is that they're going
&gt; through a certain ceremony that results in the appearance of food.
">

Have you been talking to my guitar pupils?

<QUOTE PREVIOUSPOST="
- Hide quoted text - - Show quoted text -
">

<QUOTE PREVIOUSPOST="
&gt; &gt; Now, obviously, insects don't have human language. This means we can't
&gt; &gt; do some of the things we'd do with other humans in order to verify
&gt; &gt; their experiences, viz: we can't have a conversation with them and ask
&gt; &gt; them what they make of &quot;it all&quot;. But then again we can't do this with
&gt; &gt; very small children either. The difference between insects and children
&gt; &gt; in this regard is that although we have to judge our actions in regard
&gt; &gt; to babies in terms of stimulus/response eventually most children learn
&gt; &gt; language, while on the other hand insects never do. The barrier, when
&gt; &gt; looking at it this way is just that insects don't talk. But that seems
&gt; &gt; a rather facile analysis when it's put that baldly - even I want to say
&gt; &gt; that that can't be all there is to it. But other than a conviction that
&gt; &gt; it should, really, be more complicated than that I'd have a hard time
&gt; &gt; putting my finger on exactly what /the/ difference is. (Although the
&gt; &gt; fact that I've gone looking for /one/ thing rings many philosophical
&gt; &gt; alarm bells in my head - why should there be just /one/ difference -
&gt; &gt; why can't there be a whole raft of differences? Surely not just because
&gt; &gt; it's complicated that way - that would just be intellectual laziness
&gt; &gt; masquerading as
">

...
read more »
</POST>
<POST>
<POSTER> "Dianelos Georgoudis" &lt;diane...@tecapro.com&gt; </POSTER>
<POSTDATE> 2007-01-16T08:01:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
Publius wrote:
&gt; &quot;Dianelos Georgoudis&quot; &lt;diane ... @tecapro.com&gt; wrote in
&gt; news:1168643351.079827.159990@51g2000cwl.googlegroups.com:

&gt; &gt; Yes, and as all models this too is only approximate. If considered
&gt; &gt; carefully one sees that internal-external is not a binary variable but
&gt; &gt; rather a continuum. So in the external direction a wall, for example,
&gt; &gt; is very little responsive to our will and in the other direction our
&gt; &gt; thoughts are very responsive. Somewhere in between fits our body. My
&gt; &gt; fingers are quite responsive but I can't will them to move anyway I
&gt; &gt; like; my heart is less responsive than my fingers but more responsive
&gt; &gt; than a wall. I don't think there is word that describes the quantity of
&gt; &gt; responsiveness (or unresponsiveness) to our will, but it seems to me
&gt; &gt; that the word &quot;physical&quot; describes the direction of unresponsiveness.
&gt; &gt; In an experiential environment in which there is no resistance to one's
&gt; &gt; will, nothing will be seen as physical ISTM.

&gt; All models are only approximate (a fact we know, not because we can compare
&gt; them with &quot;reality,&quot; but because we always seem to find ways to improve
&gt; them). But I think the responsive-to-the-will distinction is quite sharp.
&gt; The wall is not &quot;very little responsive,&quot; but nonresponsive. Your fingers
&gt; are responsive (though, being physical objects, are constrained by physical
&gt; laws).
">

I find that a wall is a little responsive: I can scratch it with my
nails. Now you may say that in this case the wall is not directly
responding to my will but rather indirectly via my fingers. But, by the
same measure, my fingers are not directly responding to my will either,
but rather to muscle contractions and nerve signals and up to some
stuff that happens in my brain. We are used to consider "internal" what
lies inside our skin and "external" what lies outside, but I submit
that this distinction, even though practical, is in fact artificial. We
find ourselves in a mostly classical causal experiential environment in
which some patterns present in it are more or less responsive to our
will. The existents I catalogue as lying inside my skin are in general
more responsive, but the distinction is not sharp.

<QUOTE PREVIOUSPOST="
&gt; &gt; Still I believe all the talk of &quot;self&quot;, or of modeling one's own body
&gt; &gt; as present in the model of one's environment, is only used to give the
&gt; &gt; impression we understand something about consciousness, and nudge the
&gt; &gt; discussion of consciousness towards the non-hard problem of
&gt; &gt; intelligence. But we can conceive of a being of vanishingly low
&gt; &gt; intelligence that is nevertheless conscious, and also of a being that
&gt; &gt; is extremely intelligent but not conscious (a philosophical zombie).

&gt; I agree that intelligence does not equate to consciousness. But (as you
&gt; know) I suspect that being able to construct a dynamic model (of the right
&gt; kind) of a system in real time constitutes consciousness. I.e., that any
&gt; system we encounter that is able to do that, and is able to communicate,
&gt; will pass the Turing Test, and systems that cannot do it will not.
">

I agree that any system that passes the Turing Test is conscious. The
question is what to believe about systems that do not pass the Turing
Test. And some of these systems are rather complex and do have the
notion of "self".

<QUOTE PREVIOUSPOST="
&gt; &gt; The question is how to find out whether such beings are instantiated in
&gt; &gt; reality. Take the OP's question about cockroaches. Suppose it's true
&gt; &gt; that that cockroaches model themselves within their model of the
&gt; &gt; environment (actually I believe that *is* true). Then cockroaches have
&gt; &gt; the notion of &quot;self&quot;. How does this fact help us answer the OP's
&gt; &gt; question of whether cockroaches have conscious experience or not? In no
&gt; &gt; way at all. So, the talk about the self or about self-consciousness is
&gt; &gt; just blowing smoke around the problem of consciousness.

&gt; The question is unanswerable because we have (at present) no means of
&gt; communicating with roaches. But should we discover that roaches nervous
&gt; systems are constructed in the right way, then we'd probably attribute
&gt; consciousness anyway, just because theory predicts it.
">

Ah, but how would we find out what the "right way" is, without falling
for anthropocentrism?

(Incidentally when I try to kill a cockroach in my kitchen and it runs
this and that way I think I am communicating with it.)

<QUOTE PREVIOUSPOST="
&gt; &gt; In fact I find it remarkable that that same materialist can confidently
&gt; &gt; claim that conscious experience is produced by the human brain, while
&gt; &gt; at the same being unable to explain how to find out whether conscious
&gt; &gt; experience is produced anywhere else. Imagine somebody confidently
&gt; &gt; claiming that X is produced in Greece but being unable to explain how
&gt; &gt; to find out whether X is also produced in Italy or in my garage: one
&gt; &gt; would reasonably conclude that that person knows not what they are
&gt; &gt; talking about.

&gt; But we can explain &quot;how to find out&quot; --- e.g., by producing consciousness
&gt; in man-made systems. Or by discovering it in other natural, non-biological
&gt; systems. The difficulties are not conceptual but practical, like the
&gt; question of whether there is life on Mars.
">

Well, we agree one way to produce consciousness is to build a computer
that passes the Turing Test. Suppose we have succeeded in that. Where
do we go from here?

You mention the possibility of discovering consciousness in other
natural, non-biological systems. Well, should we meet beings of some
kind or other that display great intelligence (probably beings that can
be trained to pass the Turing Test anyway) we will accept that they are
conscious beings too. By studying the internal structure of all these
beings, and of us humans, and of several versions of computers that
pass the TT, we might be able to create a general theory of
intelligence, of what it takes to be at least as intelligent as we are.
But, again, where to we go from here? How do we find out whether
cockroaches experience? We know already that they are much less
intelligent than we are. We know already that there is some similarity
between the structure of their brains and ours. So how can be possibly
proceed to discover evidence that would help us answer the cockroach
question? I fail to visualize the objective methodology we might use.
</POST>
<POST>
<POSTER> "Wanker" &lt;simonharp...@hotmail.co.uk&gt; </POSTER>
<POSTDATE> 2007-01-16T10:06:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
Dianelos Georgoudis wrote:
&gt; Publius wrote:
&gt; &gt; &quot;Dianelos Georgoudis&quot; &lt;diane ... @tecapro.com&gt; wrote in
&gt; &gt; news:1168643351.079827.159990@51g2000cwl.googlegroups.com:

&gt; &gt; &gt; Yes, and as all models this too is only approximate. If considered
&gt; &gt; &gt; carefully one sees that internal-external is not a binary variable but
&gt; &gt; &gt; rather a continuum. So in the external direction a wall, for example,
&gt; &gt; &gt; is very little responsive to our will and in the other direction our
&gt; &gt; &gt; thoughts are very responsive. Somewhere in between fits our body. My
&gt; &gt; &gt; fingers are quite responsive but I can't will them to move anyway I
&gt; &gt; &gt; like; my heart is less responsive than my fingers but more responsive
&gt; &gt; &gt; than a wall. I don't think there is word that describes the quantity of
&gt; &gt; &gt; responsiveness (or unresponsiveness) to our will, but it seems to me
&gt; &gt; &gt; that the word &quot;physical&quot; describes the direction of unresponsiveness.
&gt; &gt; &gt; In an experiential environment in which there is no resistance to one's
&gt; &gt; &gt; will, nothing will be seen as physical ISTM.

&gt; &gt; All models are only approximate (a fact we know, not because we can compare
&gt; &gt; them with &quot;reality,&quot; but because we always seem to find ways to improve
&gt; &gt; them). But I think the responsive-to-the-will distinction is quite sharp.
&gt; &gt; The wall is not &quot;very little responsive,&quot; but nonresponsive. Your fingers
&gt; &gt; are responsive (though, being physical objects, are constrained by physical
&gt; &gt; laws).

&gt; I find that a wall is a little responsive: I can scratch it with my
&gt; nails. Now you may say that in this case the wall is not directly
&gt; responding to my will but rather indirectly via my fingers. But, by the
&gt; same measure, my fingers are not directly responding to my will either,
&gt; but rather to muscle contractions and nerve signals and up to some
&gt; stuff that happens in my brain. We are used to consider &quot;internal&quot; what
&gt; lies inside our skin and &quot;external&quot; what lies outside, but I submit
&gt; that this distinction, even though practical, is in fact artificial. We
&gt; find ourselves in a mostly classical causal experiential environment in
&gt; which some patterns present in it are more or less responsive to our
&gt; will. The existents I catalogue as lying inside my skin are in general
&gt; more responsive, but the distinction is not sharp.

&gt; &gt; &gt; Still I believe all the talk of &quot;self&quot;, or of modeling one's own body
&gt; &gt; &gt; as present in the model of one's environment, is only used to give the
&gt; &gt; &gt; impression we understand something about consciousness, and nudge the
&gt; &gt; &gt; discussion of consciousness towards the non-hard problem of
&gt; &gt; &gt; intelligence. But we can conceive of a being of vanishingly low
&gt; &gt; &gt; intelligence that is nevertheless conscious, and also of a being that
&gt; &gt; &gt; is extremely intelligent but not conscious (a philosophical zombie).

&gt; &gt; I agree that intelligence does not equate to consciousness. But (as you
&gt; &gt; know) I suspect that being able to construct a dynamic model (of the right
&gt; &gt; kind) of a system in real time constitutes consciousness. I.e., that any
&gt; &gt; system we encounter that is able to do that, and is able to communicate,
&gt; &gt; will pass the Turing Test, and systems that cannot do it will not.

&gt; I agree that any system that passes the Turing Test is conscious. The
&gt; question is what to believe about systems that do not pass the Turing
&gt; Test. And some of these systems are rather complex and do have the
&gt; notion of &quot;self&quot;.

&gt; &gt; &gt; The question is how to find out whether such beings are instantiated in
&gt; &gt; &gt; reality. Take the OP's question about cockroaches. Suppose it's true
&gt; &gt; &gt; that that cockroaches model themselves within their model of the
&gt; &gt; &gt; environment (actually I believe that *is* true). Then cockroaches have
&gt; &gt; &gt; the notion of &quot;self&quot;. How does this fact help us answer the OP's
&gt; &gt; &gt; question of whether cockroaches have conscious experience or not? In no
&gt; &gt; &gt; way at all. So, the talk about the self or about self-consciousness is
&gt; &gt; &gt; just blowing smoke around the problem of consciousness.

&gt; &gt; The question is unanswerable because we have (at present) no means of
&gt; &gt; communicating with roaches. But should we discover that roaches nervous
&gt; &gt; systems are constructed in the right way, then we'd probably attribute
&gt; &gt; consciousness anyway, just because theory predicts it.

&gt; Ah, but how would we find out what the &quot;right way&quot; is, without falling
&gt; for anthropocentrism?

&gt; (Incidentally when I try to kill a cockroach in my kitchen and it runs
&gt; this and that way I think I am communicating with it.)

&gt; &gt; &gt; In fact I find it remarkable that that same materialist can confidently
&gt; &gt; &gt; claim that conscious experience is produced by the human brain, while
&gt; &gt; &gt; at the same being unable to explain how to find out whether conscious
&gt; &gt; &gt; experience is produced anywhere else. Imagine somebody confidently
&gt; &gt; &gt; claiming that X is produced in Greece but being unable to explain how
&gt; &gt; &gt; to find out whether X is also produced in Italy or in my garage: one
&gt; &gt; &gt; would reasonably conclude that that person knows not what they are
&gt; &gt; &gt; talking about.

&gt; &gt; But we can explain &quot;how to find out&quot; --- e.g., by producing consciousness
&gt; &gt; in man-made systems. Or by discovering it in other natural, non-biological
&gt; &gt; systems. The difficulties are not conceptual but practical, like the
&gt; &gt; question of whether there is life on Mars.

&gt; Well, we agree one way to produce consciousness is to build a computer
&gt; that passes the Turing Test. Suppose we have succeeded in that. Where
&gt; do we go from here?

&gt; You mention the possibility of discovering consciousness in other
&gt; natural, non-biological systems. Well, should we meet beings of some
&gt; kind or other that display great intelligence (probably beings that can
&gt; be trained to pass the Turing Test anyway) we will accept that they are
&gt; conscious beings too. By studying the internal structure of all these
&gt; beings, and of us humans, and of several versions of computers that
&gt; pass the TT, we might be able to create a general theory of
&gt; intelligence, of what it takes to be at least as intelligent as we are.
&gt; But, again, where to we go from here? How do we find out whether
&gt; cockroaches experience? We know already that they are much less
&gt; intelligent than we are. We know already that there is some similarity
&gt; between the structure of their brains and ours. So how can be possibly
&gt; proceed to discover evidence that would help us answer the cockroach
&gt; question? I fail to visualize the objective methodology we might use.
">

The problem, as ever, isn't that of whether or not other beings might
experience things as we do, but of how we'd know, which from a
practical point of view boils down to how we'd be able to communicate
in such a way as to satisfy ourselves that the being we're
communicating with is experiencing life in some way that's shares at
least something with ourselves. We could, for instance, be missing out
on completely new forms of life that are (a) indistinguishable from
inert matter (or no matter at all) and (b) so inscrutible in their
communications that we have no idea that these things aren't merely
inert at all.

Despite the possibility of this sceptical position this isn't really
the case with cockroaches, which, while unable to speak, do at least
communicate with each other to some extent (e.g. for the purposes of
mating). The unfortunate thing is that these insects don't communicate
in a human-recognisable language, and the upshot of that is that we can
postulate that cockroaches experience a great many things, but seeing
as they apparently can't play the "question and answer" set of
langage-games we'll never be able to satisfactorily verify what exactly
they do experience.
</POST>
<POST>
<POSTER> "Wanker" &lt;simonharp...@hotmail.co.uk&gt; </POSTER>
<POSTDATE> 2007-01-16T10:56:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
andy-k wrote:
&gt; &quot;Wanker&quot; wrote:
&gt; &gt; andy-k wrote:
&gt; &gt;&gt; &quot;Wanker&quot; wrote:
&gt; &gt;&gt; &gt; When you say it's debatable whether insects experience
&gt; &gt;&gt; &gt; anything, in what sense are you using the word 'experience'?

&gt; &gt;&gt; In the sense that it's debatable whether insects are associated with a
&gt; &gt;&gt; qualitative phenomenal perspective upon a world that is similar to *this*
&gt; &gt;&gt; phenomenal perspective upon a world that considers itself to be &quot;me&quot;.

&gt; &gt; Do you mean: Their experiences are likely to be quite dissimilar from
&gt; &gt; ours? I agree - I don't have an exoskeleton or compound eyes. There
&gt; &gt; are likely to be other dissimilarities too. What makes you think there are
&gt; &gt; /no/ similarities, or (a little kinder) no /significant/ similarities?

&gt; That's not what I think -- what I think is that George has a point when
&gt; he says it's debatable whether insects experience anything.
&gt; This is a perhaps less controversial version of the zombie problem.

&gt; &gt;&gt; &quot;P-consciousness is experience. P-conscious properties are experiential
&gt; &gt;&gt; properties. P-conscious states are experiential states, that is, a state
&gt; &gt;&gt; is P-conscious if it has experiential properties. The totality of the
&gt; &gt;&gt; experiential properties of a state are &quot;what it is like&quot; to have it.
&gt; &gt;&gt; Moving from synonyms to examples, we have P-conscious states when we see,
&gt; &gt;&gt; hear, smell, taste and have pains. P-conscious properties include the
&gt; &gt;&gt; experiential properties of sensations, feelings and perceptions, but I
&gt; &gt;&gt; would also include thoughts, wants and emotions.&quot;

&gt; &gt;&gt; -- Block, N. (1995) &quot;On a Confusion About a Function of Consciousness,&quot;
&gt; &gt;&gt; Behavioral and Brain Sciences 18: 227-247.

&gt; &gt; Uh-huh. None of which has defined the term 'experience' except to say
&gt; &gt; &quot;Anything we'd like to count as experience - it's that&quot;. IOW: That's no
&gt; &gt; definition at all! And what, exactly is the introduction of the terms
&gt; &gt; 'P-conscious' and 'P-consciousness' supposed to achieve when from the
&gt; &gt; foregoing it seems that &quot;P-conscious' and 'P-consciousness' simply mean
&gt; &gt; 'experience' and 'experiential' - why not use the words 'experience'
&gt; &gt; and 'experiential' and have done with it? I'm all for technical terms,
&gt; &gt; but not when they're simply replacements for existing words. The above
&gt; &gt; just sounds like pseudo-technical bollocks of the worst possible kind
&gt; &gt; to me.

&gt; I'm not taking an adversarial position, but rather implying a concern about
&gt; the way these words are used. Ned Block makes the distinction between
&gt; phenomenal consciousness and access consciousness in order to clear
&gt; up some of the confusion, but I'm not sure he succeeds:
&gt; http://www.bbsonline.org/Preprints/OldArchive/bbs.block.html

&gt; My take on this is that when we use terms like &quot;experience&quot; or &quot;conscious
&gt; experience&quot; or &quot;consciousness&quot; or &quot;awareness&quot; or &quot;conscious awareness&quot;,
&gt; we're often trying to say the unsayable, but that shouldn't be taken as a
&gt; trivialization of the point. I have total conviction that when somebody else
&gt; traps their finger in the door it hurts like hell, just as it would for me
&gt; if I trapped my finger in the door. *That* is the sense in which I use these
&gt; terms.
">

I guess the problem we have with the word 'conscious' is both its
relationship to words like 'unconscious' (the connotation being that to
be 'conscious' is to be awake and moving around), to words like
'deliberate' (the connotation being that to be 'conscious' is to
consider different possible outcomes and /choose/ the best), and to
words like 'thinking' (the connotation being that to be 'conscious' is
to be a thinking thing).

The etymology of 'conscious' is quite interesting. It originally means
something like to be "knowing, aware" - so it's root is obviously
connected to the idea that a conscious being can know things (and,
presumeably can learn new knowledge), and that it's aware (although
what it's aware of - it's surroundings, itself or both - is unclear).

If we stick to just these two senses I think we can say:

A cockroach is aware in the sense that it avoids obstacles, finds its
way towards potential mates, and so forth, but it's difficult (if not
practially impossible) to say whether or not a cockroach is aware in
the sense of /deliberately/ choosing its actions (although I've no
doubt we talk of cockroaches choosing a mate).

A cockroach is knowing in the sense that it might follow a well-used
track in order to get food, but unknowing in the sense that it wouldn't
be possible for it to answer questions put to it in English about that
track.

To recap: I think you can give sense to the answer that they are
conscious, and sense to the answer that they aren't, the upshot being
that we aren't decided whether we think they are or aren't, but there
would seem to be a balance of evidence for the view that cockroaches
are largely automagic creatures which exhibit some traits we would say
(if the subjects were human) are evidence of conscious behaviour.
</POST>
<POST>
<POSTER> "andy-k" &lt;spam.free@last&gt; </POSTER>
<POSTDATE> 2007-01-16T14:15:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;Wanker&quot; wrote:
&gt; andy-k wrote:
&gt;&gt; My take on this is that when we use terms like &quot;experience&quot; or &quot;conscious
&gt;&gt; experience&quot; or &quot;consciousness&quot; or &quot;awareness&quot; or &quot;conscious awareness&quot;,
&gt;&gt; we're often trying to say the unsayable, but that shouldn't be taken as a
&gt;&gt; trivialization of the point. I have total conviction that when somebody
&gt;&gt; else traps their finger in the door it hurts like hell, just as it would
&gt;&gt; for me if I trapped my finger in the door. *That* is the sense in which
&gt;&gt; I use these terms.

&gt; I guess the problem we have with the word 'conscious' is both its
&gt; relationship to words like 'unconscious' (the connotation being that to
&gt; be 'conscious' is to be awake and moving around), to words like
&gt; 'deliberate' (the connotation being that to be 'conscious' is to
&gt; consider different possible outcomes and /choose/ the best), and to
&gt; words like 'thinking' (the connotation being that to be 'conscious' is
&gt; to be a thinking thing).
">

An interesting account of the problem we have with the word 'conscious'
is presented here:
http://www.cse.unsw.edu.au/~markpeters/laboratory/consciousness.pdf

<QUOTE PREVIOUSPOST="
&gt; The etymology of 'conscious' is quite interesting. It originally means
&gt; something like to be &quot;knowing, aware&quot; - so it's root is obviously
&gt; connected to the idea that a conscious being can know things (and,
&gt; presumeably can learn new knowledge), and that it's aware (although
&gt; what it's aware of - it's surroundings, itself or both - is unclear).
">

Wikipedia has an interesting note on the etymology of the word:
http://en.wikipedia.org/wiki/Consciousness

...but taking the word apart, it seems to consist of
an element of "togetherness" ('con') and "knowing" ('scio').

<QUOTE PREVIOUSPOST="
- Hide quoted text - - Show quoted text -
">

<QUOTE PREVIOUSPOST="
&gt; If we stick to just these two senses I think we can say:

&gt; A cockroach is aware in the sense that it avoids obstacles, finds its
&gt; way towards potential mates, and so forth, but it's difficult (if not
&gt; practially impossible) to say whether or not a cockroach is aware in
&gt; the sense of /deliberately/ choosing its actions (although I've no
&gt; doubt we talk of cockroaches choosing a mate).

&gt; A cockroach is knowing in the sense that it might follow a well-used
&gt; track in order to get food, but unknowing in the sense that it wouldn't
&gt; be possible for it to answer questions put to it in English about that
&gt; track.

&gt; To recap: I think you can give sense to the answer that they are
&gt; conscious, and sense to the answer that they aren't, the upshot being
&gt; that we aren't decided whether we think they are or aren't, but there
&gt; would seem to be a balance of evidence for the view that cockroaches
&gt; are largely automagic creatures which exhibit some traits we would say
&gt; (if the subjects were human) are evidence of conscious behaviour.
">

I do like your word 'automagic', though I suspect it was a typo :-)
There are various ways to define the word 'consciousness'
so that it becomes objective and testable (e.g. the Turing Test),
but the major obstacle lies in what Peters (referenced above)
is attempting to address when he refers to 'C1'.
</POST>
<POST>
<POSTER> "Wanker" &lt;simonharp...@hotmail.co.uk&gt; </POSTER>
<POSTDATE> 2007-01-17T07:54:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
andy-k wrote:
&gt; &quot;Wanker&quot; wrote:
&gt; &gt; andy-k wrote:
&gt; &gt;&gt; My take on this is that when we use terms like &quot;experience&quot; or &quot;conscious
&gt; &gt;&gt; experience&quot; or &quot;consciousness&quot; or &quot;awareness&quot; or &quot;conscious awareness&quot;,
&gt; &gt;&gt; we're often trying to say the unsayable, but that shouldn't be taken as a
&gt; &gt;&gt; trivialization of the point. I have total conviction that when somebody
&gt; &gt;&gt; else traps their finger in the door it hurts like hell, just as it would
&gt; &gt;&gt; for me if I trapped my finger in the door. *That* is the sense in which
&gt; &gt;&gt; I use these terms.

&gt; &gt; I guess the problem we have with the word 'conscious' is both its
&gt; &gt; relationship to words like 'unconscious' (the connotation being that to
&gt; &gt; be 'conscious' is to be awake and moving around), to words like
&gt; &gt; 'deliberate' (the connotation being that to be 'conscious' is to
&gt; &gt; consider different possible outcomes and /choose/ the best), and to
&gt; &gt; words like 'thinking' (the connotation being that to be 'conscious' is
&gt; &gt; to be a thinking thing).

&gt; An interesting account of the problem we have with the word 'conscious'
&gt; is presented here:
&gt; http://www.cse.unsw.edu.au/~markpeters/laboratory/consciousness.pdf
">

It's an interesting article, although I'm not entirely in agreement
with its conclusion that "there is too much doubt and disagreement over
what "consciousness" is meant to include for any definition not to
be premature; until we
know more about the relationship between psychological events and
neurological events, we are not in a proper position to frame the
question of consciousness".

In terms of "doubt and disagreement over what 'consciousness' is meant"
I tend to believe that when it comes to teaching the meaning of the
word to children there's not much doubt and disagreement at all. The
doubt and disagreement seems only to arise when you get scientists and
pseudo-scientists (like Dennett) trying to make the endmically unclear,
clear (cf. PI §76-§77).

<QUOTE PREVIOUSPOST="
&gt;From a practical point of view, though, I incline to the views that:
">

Further research into the relationship between the psychological and
the neurological is no bad thing, will undoubtedly have great practical
benefits, and will also help differentiate matters somewhat, but;

This won't /answer/ 'the problem of consciousness' partly because there
isn't just one problem, and partly because what will probably happen
from a practical standpoint is that we'll alter the meanings of
'consciousness' words so they're brought into line with research,
language's foundations will have moved slightly, and people in the
future looking back into the past will wonder what all the fuss was
about (because they'll have lost, or had altered, a distinction that
from this end of things looks really rather convincing and real).

<QUOTE PREVIOUSPOST="
- Hide quoted text - - Show quoted text -
">

<QUOTE PREVIOUSPOST="
&gt; &gt; The etymology of 'conscious' is quite interesting. It originally means
&gt; &gt; something like to be &quot;knowing, aware&quot; - so it's root is obviously
&gt; &gt; connected to the idea that a conscious being can know things (and,
&gt; &gt; presumeably can learn new knowledge), and that it's aware (although
&gt; &gt; what it's aware of - it's surroundings, itself or both - is unclear).

&gt; Wikipedia has an interesting note on the etymology of the word:
&gt; http://en.wikipedia.org/wiki/Consciousness

&gt; ...but taking the word apart, it seems to consist of
&gt; an element of &quot;togetherness&quot; ('con') and &quot;knowing&quot; ('scio').

&gt; &gt; If we stick to just these two senses I think we can say:

&gt; &gt; A cockroach is aware in the sense that it avoids obstacles, finds its
&gt; &gt; way towards potential mates, and so forth, but it's difficult (if not
&gt; &gt; practially impossible) to say whether or not a cockroach is aware in
&gt; &gt; the sense of /deliberately/ choosing its actions (although I've no
&gt; &gt; doubt we talk of cockroaches choosing a mate).

&gt; &gt; A cockroach is knowing in the sense that it might follow a well-used
&gt; &gt; track in order to get food, but unknowing in the sense that it wouldn't
&gt; &gt; be possible for it to answer questions put to it in English about that
&gt; &gt; track.

&gt; &gt; To recap: I think you can give sense to the answer that they are
&gt; &gt; conscious, and sense to the answer that they aren't, the upshot being
&gt; &gt; that we aren't decided whether we think they are or aren't, but there
&gt; &gt; would seem to be a balance of evidence for the view that cockroaches
&gt; &gt; are largely automagic creatures which exhibit some traits we would say
&gt; &gt; (if the subjects were human) are evidence of conscious behaviour.

&gt; I do like your word 'automagic', though I suspect it was a typo :-)
">

Programmer's term. Lots of computer users seem to be utterly hypnotized
by the bright flashing lights on their monitors and regard even minor
automatic processing as a wonder beyond wonders - as magic IOW.
Automagic is one of those slightly cynical, slightly derisory terms
programmers use to describe the rather non-magical coding work required
to get this stuff to work.

<QUOTE PREVIOUSPOST="
&gt; There are various ways to define the word 'consciousness'
&gt; so that it becomes objective and testable (e.g. the Turing Test),
&gt; but the major obstacle lies in what Peters (referenced above)
&gt; is attempting to address when he refers to 'C1'.
">

Ah yes - qualia. The 'feel' of something as distinguished from the
expression of the feeling of something. Isn't this discussion about
cockroaches predicated on something like the same idea, viz: The
cockroach could be feeling something, but we can't ask it so how do we
know?

And if I put it in those terms doesn't it start to sound like the
age-old sceptical argument: There's an black-box which is inherently
inaccessible over there - it could be this, it could be that, but we'll
never know because it's inherently inaccessible? The sceptic wants to
believe this is a problem, and it is, but it's only a problem for him
because his natural temptation is to want to peek, but he's defined
things so he can't. And if you change the definitions so he can peek he
won't feel satisfied because he won't be feeling the confusion that
results from banging your head against an inherently unsolvable
problem.

Better, I think, just to concentrate on the practicalities - do
experiments - and let the language get sorted out in the process -
it'll come naturally and thinking about it all ahead of time won't
necessarily do anything but lead us all up the garden path.
</POST>
<POST>
<POSTER> "andy-k" &lt;spam.free@last&gt; </POSTER>
<POSTDATE> 2007-01-17T12:26:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;Wanker&quot; wrote:
&gt; andy-k wrote:
&gt;&gt; An interesting account of the problem we have with the word 'conscious'
&gt;&gt; is presented here:
&gt;&gt; http://www.cse.unsw.edu.au/~markpeters/laboratory/consciousness.pdf

&gt; It's an interesting article, although I'm not entirely in agreement with
&gt; its conclusion that &quot;there is too much doubt and disagreement over what
&gt; &quot;consciousness&quot; is meant to include for any definition not to be
&gt; premature; until we know more about the relationship between psychological
&gt; events and neurological events, we are not in a proper position to frame
&gt; the question of consciousness&quot;.

&gt; In terms of &quot;doubt and disagreement over what 'consciousness' is meant&quot; I
&gt; tend to believe that when it comes to teaching the meaning of the word to
&gt; children there's not much doubt and disagreement at all. The doubt and
&gt; disagreement seems only to arise when you get scientists and
&gt; pseudo-scientists (like Dennett) trying to make the endmically unclear,
&gt; clear (cf. PI §76-§77).
">

We certainly are introduced to the word in a very common-sensical manner
(just as you say, the opposite of 'unconsciousness' -- the doctor may say
that the patient is drifting in and out of consciousness, and his meaning
will be perfectly clear). But the word takes on a different use when our
thinking gets more abstract, and I don't believe this to be a grammatical
error or fiction but rather an attempt to say something that is genuinely
unsayable.

<QUOTE PREVIOUSPOST="
&gt; From a practical point of view, though, I incline to the views that:

&gt; Further research into the relationship between the psychological and the
&gt; neurological is no bad thing, will undoubtedly have great practical
&gt; benefits, and will also help differentiate matters somewhat, but;

&gt; This won't /answer/ 'the problem of consciousness' partly because there
&gt; isn't just one problem, and partly because what will probably happen from
&gt; a practical standpoint is that we'll alter the meanings of 'consciousness'
&gt; words so they're brought into line with research, language's foundations
&gt; will have moved slightly, and people in the future looking back into the
&gt; past will wonder what all the fuss was about (because they'll have lost,
&gt; or had altered, a distinction that from this end of things looks really
&gt; rather convincing and real).
">

I'm with you up to the point where you appear to become dismissive
of the claim that we are trying to say the unsayable.

<QUOTE PREVIOUSPOST="
- Hide quoted text - - Show quoted text -
">

<QUOTE PREVIOUSPOST="
&gt;&gt; There are various ways to define the word 'consciousness'
&gt;&gt; so that it becomes objective and testable (e.g. the Turing Test),
&gt;&gt; but the major obstacle lies in what Peters (referenced above)
&gt;&gt; is attempting to address when he refers to 'C1'.

&gt; Ah yes - qualia. The 'feel' of something as distinguished from the
&gt; expression of the feeling of something. Isn't this discussion about
&gt; cockroaches predicated on something like the same idea, viz: The cockroach
&gt; could be feeling something, but we can't ask it so how do we know?

&gt; And if I put it in those terms doesn't it start to sound like the age-old
&gt; sceptical argument: There's an black-box which is inherently inaccessible
&gt; over there - it could be this, it could be that, but we'll never know
&gt; because it's inherently inaccessible? The sceptic wants to believe this is
&gt; a problem, and it is, but it's only a problem for him because his natural
&gt; temptation is to want to peek, but he's defined things so he can't. And if
&gt; you change the definitions so he can peek he won't feel satisfied because
&gt; he won't be feeling the confusion that results from banging your head
&gt; against an inherently unsolvable problem.

&gt; Better, I think, just to concentrate on the practicalities - do
&gt; experiments - and let the language get sorted out in the process - it'll
&gt; come naturally and thinking about it all ahead of time won't necessarily
&gt; do anything but lead us all up the garden path.
">

Again, I'm with you most of the way here:
"The thing in the box has no place in the language-game at all;
not even as a _something_: for the box might even be empty."
But does anybody really believe that other people are
"philosophical zombies"? (Wasn't the "absent qualia" problem
raised to indicate that the physicalist position is deficient?)
"It is not a _something_, but not a _nothing_ either!"
</POST>
<POST>
<POSTER> "Wanker" &lt;simonharp...@hotmail.co.uk&gt; </POSTER>
<POSTDATE> 2007-01-22T07:34:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
andy-k wrote:
&gt; &quot;Wanker&quot; wrote:
&gt; &gt; andy-k wrote:
&gt; &gt;&gt; An interesting account of the problem we have with the word 'conscious'
&gt; &gt;&gt; is presented here:
&gt; &gt;&gt; http://www.cse.unsw.edu.au/~markpeters/laboratory/consciousness.pdf

&gt; &gt; It's an interesting article, although I'm not entirely in agreement with
&gt; &gt; its conclusion that &quot;there is too much doubt and disagreement over what
&gt; &gt; &quot;consciousness&quot; is meant to include for any definition not to be
&gt; &gt; premature; until we know more about the relationship between psychological
&gt; &gt; events and neurological events, we are not in a proper position to frame
&gt; &gt; the question of consciousness&quot;.

&gt; &gt; In terms of &quot;doubt and disagreement over what 'consciousness' is meant&quot; I
&gt; &gt; tend to believe that when it comes to teaching the meaning of the word to
&gt; &gt; children there's not much doubt and disagreement at all. The doubt and
&gt; &gt; disagreement seems only to arise when you get scientists and
&gt; &gt; pseudo-scientists (like Dennett) trying to make the endmically unclear,
&gt; &gt; clear (cf. PI §76-§77).

&gt; We certainly are introduced to the word in a very common-sensical manner
&gt; (just as you say, the opposite of 'unconsciousness' -- the doctor may say
&gt; that the patient is drifting in and out of consciousness, and his meaning
&gt; will be perfectly clear). But the word takes on a different use when our
&gt; thinking gets more abstract, and I don't believe this to be a grammatical
&gt; error or fiction but rather an attempt to say something that is genuinely
&gt; unsayable.

&gt; &gt; From a practical point of view, though, I incline to the views that:

&gt; &gt; Further research into the relationship between the psychological and the
&gt; &gt; neurological is no bad thing, will undoubtedly have great practical
&gt; &gt; benefits, and will also help differentiate matters somewhat, but;

&gt; &gt; This won't /answer/ 'the problem of consciousness' partly because there
&gt; &gt; isn't just one problem, and partly because what will probably happen from
&gt; &gt; a practical standpoint is that we'll alter the meanings of 'consciousness'
&gt; &gt; words so they're brought into line with research, language's foundations
&gt; &gt; will have moved slightly, and people in the future looking back into the
&gt; &gt; past will wonder what all the fuss was about (because they'll have lost,
&gt; &gt; or had altered, a distinction that from this end of things looks really
&gt; &gt; rather convincing and real).

&gt; I'm with you up to the point where you appear to become dismissive
&gt; of the claim that we are trying to say the unsayable.
">

I'm dismissive of the claim because humans can say what they like if
they invent suitable concepts. To say "It's just an attempt to say the
unsayable" is too much of a cop-out for my liking.

<QUOTE PREVIOUSPOST="
- Hide quoted text - - Show quoted text -
">

<QUOTE PREVIOUSPOST="
&gt; &gt;&gt; There are various ways to define the word 'consciousness'
&gt; &gt;&gt; so that it becomes objective and testable (e.g. the Turing Test),
&gt; &gt;&gt; but the major obstacle lies in what Peters (referenced above)
&gt; &gt;&gt; is attempting to address when he refers to 'C1'.

&gt; &gt; Ah yes - qualia. The 'feel' of something as distinguished from the
&gt; &gt; expression of the feeling of something. Isn't this discussion about
&gt; &gt; cockroaches predicated on something like the same idea, viz: The cockroach
&gt; &gt; could be feeling something, but we can't ask it so how do we know?

&gt; &gt; And if I put it in those terms doesn't it start to sound like the age-old
&gt; &gt; sceptical argument: There's an black-box which is inherently inaccessible
&gt; &gt; over there - it could be this, it could be that, but we'll never know
&gt; &gt; because it's inherently inaccessible? The sceptic wants to believe this is
&gt; &gt; a problem, and it is, but it's only a problem for him because his natural
&gt; &gt; temptation is to want to peek, but he's defined things so he can't. And if
&gt; &gt; you change the definitions so he can peek he won't feel satisfied because
&gt; &gt; he won't be feeling the confusion that results from banging your head
&gt; &gt; against an inherently unsolvable problem.

&gt; &gt; Better, I think, just to concentrate on the practicalities - do
&gt; &gt; experiments - and let the language get sorted out in the process - it'll
&gt; &gt; come naturally and thinking about it all ahead of time won't necessarily
&gt; &gt; do anything but lead us all up the garden path.

&gt; Again, I'm with you most of the way here:
&gt; &quot;The thing in the box has no place in the language-game at all;
&gt; not even as a _something_: for the box might even be empty.&quot;
&gt; But does anybody really believe that other people are
&gt; &quot;philosophical zombies&quot;? (Wasn't the &quot;absent qualia&quot; problem
&gt; raised to indicate that the physicalist position is deficient?)
&gt; &quot;It is not a _something_, but not a _nothing_ either!&quot;
">

The "philosophical zombie" is (as I recall) only like that because of
the way the problem's set up - first we define an inherently unopenable
box, then we wonder what it's like inside that box, then we get in a
tangle. Change the nature of the box and it opens itself.
</POST>
<POST>
<POSTER> "andy-k" &lt;spam.free@last&gt; </POSTER>
<POSTDATE> 2007-01-22T10:48:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&quot;Wanker&quot; wrote:
&gt; andy-k wrote:
&gt;&gt; I'm with you up to the point where you appear to become
&gt;&gt; dismissive of the claim that we are trying to say the unsayable.

&gt; I'm dismissive of the claim because humans can say what they
&gt; like if they invent suitable concepts. To say &quot;It's just an attempt
&gt; to say the unsayable&quot; is too much of a cop-out for my liking.
">

You don't believe that language has intrinsic limitations?

<QUOTE PREVIOUSPOST="
&gt;&gt; Again, I'm with you most of the way here: &quot;The thing in the box has
&gt;&gt; no place in the language-game at all; not even as a _something_:
&gt;&gt; for the box might even be empty.&quot; But does anybody really believe that
&gt;&gt; other people are &quot;philosophical zombies&quot;? (Wasn't the &quot;absent qualia&quot;
&gt;&gt; problem raised to indicate that the physicalist position is deficient?)
&gt;&gt; &quot;It is not a _something_, but not a _nothing_ either!&quot;

&gt; The &quot;philosophical zombie&quot; is (as I recall) only like that because of the
&gt; way the problem's set up - first we define an inherently unopenable box,
&gt; then we wonder what it's like inside that box, then we get in a tangle.
&gt; Change the nature of the box and it opens itself.
">

When somebody else hits their thumb with the hammer,
I have an instinctive conviction that it hurts them like hell
just as it hurts me when I hit my thumb with the hammer.
"Just try -- in a real case -- to doubt someone else's fear or pain."
How can that be construed as "setting the problem up"?
</POST>
<POST>
<POSTER> "Don Stockbauer" &lt;donstockba...@hotmail.com&gt; </POSTER>
<POSTDATE> 2007-01-22T12:50:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
Kan wrote:
&gt; &quot;Publius&quot; &lt;m.publ ... @nospam.comcast.net&gt; wrote in message
&gt; news:S6OdnVi1MrQm8DjYnZ2dnUVZ_ternZ2d@comcast.com ...
&gt; &gt; &quot;George Dance&quot; &lt;georgedanc ... @yahoo.ca&gt; wrote in
&gt; &gt; news:1168467053.292037.45550
&gt; &gt; @p59g2000hsd.googlegroups.com:

&gt; &gt;&gt; Sir Frederick wrote:
&gt; &gt;&gt;&gt; Another question :
&gt; &gt;&gt;&gt; Do cockroaches experience an &quot;I&quot;?
&gt; &gt;&gt;&gt; Do they experience anything?

&gt; &gt;&gt; They appear to be able to experience light and motion; as they run away
&gt; &gt;&gt; from both.  Since they don't have much of a brain, it's unlikely that
&gt; &gt;&gt; they'd experience any deep thoughts.

&gt; &gt; &quot;Deep&quot; is vague, of course, but we probably underestimate the data
&gt; &gt; processing
&gt; &gt; capabilities of insects. A study last year, for example, showed that
&gt; &gt; honeybees are capable of abstract reasoning. (They quickly learned that
&gt; &gt; the
&gt; &gt; correct path in a maze was the one whose marker matched the marker at the
&gt; &gt; entrance, regardless of the particular markers used.) They also have
&gt; &gt; trichromatic vision, a sophisticated visual processing system, and
&gt; &gt; sophisticated communication ability, as described by von Frisch, et al.

&gt; &gt; http://en.wikipedia.org/wiki/Karl_von_Frisch

&gt; &gt; It suggests that the basic components or features of &quot;thought&quot; might be
&gt; &gt; accomplished by fairly simple neural structures. I suspect that if
&gt; &gt; &quot;qualia&quot;
&gt; &gt; prove of value in explaining the behavior of humans, it will also be
&gt; &gt; useful
&gt; &gt; in explaining that of bees.

&gt; It is debatable that rather than an &quot;I&quot; insects may experience a &quot;we&quot; - they
&gt; seem to operate as a collective.
">

No doubt about it - the social insects operate as a collective, just as
the Borg do.
</POST>
<POST>
<POSTER> "Don Stockbauer" &lt;donstockba...@hotmail.com&gt; </POSTER>
<POSTDATE> 2007-01-22T12:54:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
Sir Frederick wrote:
&gt; Another question :
&gt; Do cockroaches experience an &quot;I&quot;?
&gt; Do they experience anything?
&gt; --
">

Try to step on a cockroach.  It skitters away from you.  It could only
do this if it were experiencing your foot.

QED

- Don
</POST>
</TEXT>
</BODY>
</DOC>
