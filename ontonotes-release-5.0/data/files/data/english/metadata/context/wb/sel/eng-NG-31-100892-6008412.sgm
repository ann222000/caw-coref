<DOC>
<DOCID> eng-NG-31-100892-6008412 </DOCID>
<DOCTYPE SOURCE="usenet"> USENET TEXT </DOCTYPE>
<DATETIME> 2007-01-22T14:35:00 </DATETIME>
<BODY>
<HEADLINE>
The Neurology of Self-Awareness
</HEADLINE>
<TEXT>
<POST>
<POSTER> Sir Frederick &lt;mmcne...@fuzzysys.com&gt; </POSTER>
<POSTDATE> 2007-01-22T14:35:00 </POSTDATE>
http://www.edge.org/documents/archive/edge201.html#rama
THE NEUROLOGY OF SELF-AWARENESS
By V.S. Ramachandran

What is the self? How does the activity of neurons give rise to the sense of being a conscious human being? Even this most ancient
of philosophical problems, I believe, will yield to the methods of empirical science. It now seems increasingly likely that the self
is not a holistic property of the entire brain; it arises from the activity of specific sets of interlinked brain circuits. But we
need to know which circuits are critically involved and what their functions might be. It is the "turning inward" aspect of the self
— its recursiveness — that gives it its peculiar paradoxical quality.

It has been suggested by Horace Barlow, Nick Humphrey, David Premack and Marvin Minsky (among others) that consciousness may have
evolved primarily in a social context. Minsky speaks of a second parallel mechanism that has evolved in humans to create
representations of earlier representations and Humphrey has argued that our ability to introspect may have evolved specifically to
construct meaningful models of other peoples minds in order to predict their behavior. "I feel jealous in order to understand what
jealousy feels like in someone else" — a short cut to predicting that persons behavior.

Here I develop these arguments further. If I succeed in seeing any further it is by "standing on the shoulders of these giants".
Specifically, I suggest that "other awareness" may have evolved first and then counterintutively, as often happens in evolution, the
same ability was exploited to model ones own mind — what one calls self awareness. I will also suggest that a specific system of
neurons called mirror neurons are involved in this ability. Finally I discuss some clinical examples to illustrate these ideas and
make some testable predictions.

There are many aspects of self. It has a sense of unity despite the multitude of sense impressions and beliefs. In addition it has a
sense of continuity in time, of being in control of its actions ("free will"), of being anchored in a body, a sense of its worth,
dignity and mortality (or immortality). Each of these aspects of self may be mediated by different centers in different parts of the
brain and its only for convenience that we lump them together in a single word.

As noted earlier there is one aspect of self that seems stranger than all the others — the fact that it is aware of itself. I would
like to suggest that groups of neurons called mirror neurons are critically involved in this ability.

The discovery of mirror neurons was made G. Rizzolati, V Gallase and I Iaccoboni while recording from the brains of monkeys
performed certain goal-directed voluntary actions. For instance when the monkey reached for a peanut a certain neuron in its pre
motor cortex ( in the frontal lobes) would fire. Another neuron would fire when the monkey pushed a button, a third neuron when he
pulled a lever. The existence of such Command neurons that control voluntary movements has been known for decades. Amazingly, a
subset of these neurons had an additional peculiar property. The neuron fired not only (say) when the monkey reached for a peanut
but also when it watched another monkey reach for a peanut!

These were dubbed "mirror neurons" or "monkey-see-monkey-do" neurons. This was an extraordinary observation because it implies that
the neuron (or more accurately, the network which it is part of) was not only generating a highly specific command ("reach for the
nut") but was capable of adopting another monkey's point of view. It was doing a sort of internal virtual reality simulation of the
other monkeys action in order to figure out what he was "up to". It was, in short, a "mind-reading" neuron.

Neurons in the anterior cingulate will respond to the patient being poked with a needle; they are often referred to as sensory pain
neurons. Remarkably, researchers at the University of Toronto have found that some of them will fire equally strongly when the
patient watches someone else is poked. I call these "empathy neurons" or "Dalai Lama neurons" for they are, dissolving the barrier
between self and others. Notice that in saying this one isn't being metaphorical; the neuron in question simply doesn't know the
difference between it and others.

Primates (including humans) are highly social creatures and knowing what someone is "up to" — creating an internal simulation of
his/her mind — is crucial for survival, earning us the title "the Machiavellian primate". In an essay for Edge (2001) entitled
"Mirror Neurons and the Great Leap Forward" I suggested that in addition to providing a neural substrate for figuring out another
persons intentions (as noted by Rizzolati's group) the emergence and subsequent sophistication of mirror neurons in hominids may
have played a crucial role in many quintessentially human abilities such as empathy, learning through imitation (rather than trial
and error), and the rapid transmission of what we call "culture". (And the "great leap forward" — the rapid Lamarckian transmission
of "accidental") one-of-a kind inventions.

I turn now to the main concern of this essay — the nature of self. When you think of your own self, what comes into mind? You have
sense of "introspecting" on your own thoughts and feelings and of " watching" yourself going about your business — as if you were
looking at yourself from another persons vantage point. How does this happen ?

Evolution often takes advantage of pre-existing structures to evolve completely novel abilities. I suggest that once the ability to
engage in cross modal abstraction emerged — e.g. between visual "vertical" on the retina and photoreceptive "vertical" signaled by
muscles (for grasping trees) it set the stage for the emergence of mirror neurons in hominids. Mirror neurons are also abundant in
the inferior parietal lobule — a structure that underwent an accelerated expansion in the great apes and, later, in humans.. As the
brain evolved further the lobule split into two gyri — the supramarginal gyrus that allowed you to "reflect" on your own anticipated
actions and the angular gyrus that allowed you to "reflect" on your body (on the right) and perhaps on other more social and
linguistic aspects of your self (left hemisphere) I have argued elsewhere that mirror neurons are fundamentally performing a kind of
abstraction across activity in visual maps and motor maps. This in turn may have paved the way for more conceptual types of
abstraction; such as metaphor ("get a grip on yourself").

How does all this lead to self awareness? I suggest that self awareness is simply using mirror neurons for "looking at myself as if
someone else is look at me" (the word "me" encompassing some of my brain processes, as well). The mirror neuron mechanism — the same
algorithm — that originally evolved to help you adopt another's point of view was turned inward to look at your own self. This, in
essence, is the basis of things like "introspection". It may not be coincidental that we use phrases like "self conscious" when you
really mean that you are conscious of others being conscious of you. Or say "I am reflecting" when you mean you are aware of
yourself thinking. In other words the ability to turn inward to introspect or reflect may be a sort of metaphorical extension of the
mirror neurons ability to read others minds. It is often tacitly assumed that the uniquely human ability to construct a "theory of
other minds" or "TOM" (seeing the world from the others point of view; "mind reading", figuring out what someone is up to, etc.)
must come after an already pre- existing sense of self. I am arguing that the exact opposite is true; the TOM evolved first in
response to social needs and then later, as an unexpected bonus, came the ability to introspect on your own thoughts and intentions.
I claim no great originality for these ideas; they are part of the current zeitgeist. Any novelty derives from the manner in which I
shall marshall the evidence from physiology and from our own work in neurology. Note that I am not arguing that mirror neurons are
sufficient for the emergence of self; only that they must have played a pivotal role. (Otherwise monkeys would have self awareness
and they don't). They may have to reach a certain critical level of sophistication that allowed them to build on earlier functions
(TOM) and become linked to certain other brain circuits, especially the Wernickes ("language comprehension") area and parts of the
frontal lobes.

Does the mirror neuron theory of self make other predictions? Given our discovery that autistic children have deficient mirror
neurons and correspondingly deficient TOM, we would predict that they would have a deficient sense of self (TMM) and difficulty with
introspection. The same might be true for other neurological disorders; damage to the inferior parietal lobule/TPO junction (which
are known to contain mirror neurons) and parts of the frontal lobes should also lead to a deficiency of certain aspects self
awareness. (Incidentally, Gallup's mirror test — removing a paint splotch from your face while looking at a mirror — is not an
adequate test of self awareness, even though it is touted as such. We have seen patients who vehemently claim that their reflection
in the mirror is "someone else" yet they pass the Gallup test!)

It has recently been shown that if a conscious awake human patient has his parietal lobe stimulated during neurosurgery, he will
sometimes have an "out of body" experience — as if he was a detached entity watching his own body from up near the ceiling. I
suggest that this arises because of a dysfunction in the mirror neuron system in the parieto-occipital junction caused by the
stimulating electrode. These neurons are ordinarily activated when we temporarily "adopt" another's view of our body and mind (as
outlined earlier in
...
read more »
</POST>
<POST>
<POSTER> "Joe" &lt;PhilosophyMon...@gmail.com&gt; </POSTER>
<POSTDATE> 2007-01-22T15:02:00 </POSTDATE>
"What is the self? How does the activity of neurons give rise to the
sense of being a conscious human being?"

I think the first question here is much more interesting and
problematic than the second one. You can't assume that there is self
though, so the second question becomes important. The qay you ask it
though, the "sense of being a conscious human being" is a proxy for
this assumed self. The better way of framing and dealing with both of
these questions is: to what does the activity of the brain give rise,
and is that "self."
</POST>
<POST>
<POSTER> "alkaline" &lt;optio...@draze.com&gt; </POSTER>
<POSTDATE> 2007-01-22T15:50:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
&gt;There are many aspects of self. It has a
&gt; sense of unity despite the multitude of
&gt; sense impressions and beliefs.
">

The unity is the real mystery. Especially in any metaphysics that has
the cosmos objectively individuated into tiny bits of matter and
energy. Until someone gets large enough gonads to seriously address how
a literal "unity" of the mental is made possible under such worldviews,
the other meanderings are distraction.

.
</POST>
<POST>
<POSTER> "tooly" &lt;r...@bellsouth.net&gt; </POSTER>
<POSTDATE> 2007-01-22T22:13:00 </POSTDATE>
Your materialist viewpoint makes me want to say one thing...
Where's the friggin 'off' switch.  If we continue down this track, we must
provide an 'off' switch for those who do not wish to make this decidely
'anti-human' journey.

Otherwise, YOU [the scientific, super-rational, materialist] have become
monsters.  Just a simply off switch is all we'd ask...NO PAIN; and then you
can have without obstacle, your world of 'neurons' and your throne upon
which you sit as master of intelligencia.

<QUOTE PREVIOUSPOST="
&quot;Sir Frederick&quot; &lt;mmcne ... @fuzzysys.com&gt; wrote in message
">

news:p94ar29ifm4gmqip1f0crppilsfgjp1men@4ax.com ...

<QUOTE PREVIOUSPOST="
&gt; http://www.edge.org/documents/archive/edge201.html#rama
&gt; THE NEUROLOGY OF SELF-AWARENESS
&gt; By V.S. Ramachandran

&gt; What is the self? How does the activity of neurons give rise to the sense
&gt; of being a conscious human being? Even this most ancient
&gt; of philosophical problems, I believe, will yield to the methods of
&gt; empirical science. It now seems increasingly likely that the self
&gt; is not a holistic property of the entire brain; it arises from the
&gt; activity of specific sets of interlinked brain circuits. But we
&gt; need to know which circuits are critically involved and what their
&gt; functions might be. It is the &quot;turning inward&quot; aspect of the self
&gt; - its recursiveness - that gives it its peculiar paradoxical quality.

&gt; It has been suggested by Horace Barlow, Nick Humphrey, David Premack and
&gt; Marvin Minsky (among others) that consciousness may have
&gt; evolved primarily in a social context. Minsky speaks of a second parallel
&gt; mechanism that has evolved in humans to create
&gt; representations of earlier representations and Humphrey has argued that
&gt; our ability to introspect may have evolved specifically to
&gt; construct meaningful models of other peoples minds in order to predict
&gt; their behavior. &quot;I feel jealous in order to understand what
&gt; jealousy feels like in someone else&quot; - a short cut to predicting that
&gt; persons behavior.

&gt; Here I develop these arguments further. If I succeed in seeing any further
&gt; it is by &quot;standing on the shoulders of these giants&quot;.
&gt; Specifically, I suggest that &quot;other awareness&quot; may have evolved first and
&gt; then counterintutively, as often happens in evolution, the
&gt; same ability was exploited to model ones own mind - what one calls self
&gt; awareness. I will also suggest that a specific system of
&gt; neurons called mirror neurons are involved in this ability. Finally I
&gt; discuss some clinical examples to illustrate these ideas and
&gt; make some testable predictions.

&gt; There are many aspects of self. It has a sense of unity despite the
&gt; multitude of sense impressions and beliefs. In addition it has a
&gt; sense of continuity in time, of being in control of its actions (&quot;free
&gt; will&quot;), of being anchored in a body, a sense of its worth,
&gt; dignity and mortality (or immortality). Each of these aspects of self may
&gt; be mediated by different centers in different parts of the
&gt; brain and its only for convenience that we lump them together in a single
&gt; word.

&gt; As noted earlier there is one aspect of self that seems stranger than all
&gt; the others - the fact that it is aware of itself. I would
&gt; like to suggest that groups of neurons called mirror neurons are
&gt; critically involved in this ability.

&gt; The discovery of mirror neurons was made G. Rizzolati, V Gallase and I
&gt; Iaccoboni while recording from the brains of monkeys
&gt; performed certain goal-directed voluntary actions. For instance when the
&gt; monkey reached for a peanut a certain neuron in its pre
&gt; motor cortex ( in the frontal lobes) would fire. Another neuron would fire
&gt; when the monkey pushed a button, a third neuron when he
&gt; pulled a lever. The existence of such Command neurons that control
&gt; voluntary movements has been known for decades. Amazingly, a
&gt; subset of these neurons had an additional peculiar property. The neuron
&gt; fired not only (say) when the monkey reached for a peanut
&gt; but also when it watched another monkey reach for a peanut!

&gt; These were dubbed &quot;mirror neurons&quot; or &quot;monkey-see-monkey-do&quot; neurons. This
&gt; was an extraordinary observation because it implies that
&gt; the neuron (or more accurately, the network which it is part of) was not
&gt; only generating a highly specific command (&quot;reach for the
&gt; nut&quot;) but was capable of adopting another monkey's point of view. It was
&gt; doing a sort of internal virtual reality simulation of the
&gt; other monkeys action in order to figure out what he was &quot;up to&quot;. It was,
&gt; in short, a &quot;mind-reading&quot; neuron.

&gt; Neurons in the anterior cingulate will respond to the patient being poked
&gt; with a needle; they are often referred to as sensory pain
&gt; neurons. Remarkably, researchers at the University of Toronto have found
&gt; that some of them will fire equally strongly when the
&gt; patient watches someone else is poked. I call these &quot;empathy neurons&quot; or
&gt; &quot;Dalai Lama neurons&quot; for they are, dissolving the barrier
&gt; between self and others. Notice that in saying this one isn't being
&gt; metaphorical; the neuron in question simply doesn't know the
&gt; difference between it and others.

&gt; Primates (including humans) are highly social creatures and knowing what
&gt; someone is &quot;up to&quot; - creating an internal simulation of
&gt; his/her mind - is crucial for survival, earning us the title &quot;the
&gt; Machiavellian primate&quot;. In an essay for Edge (2001) entitled
&gt; &quot;Mirror Neurons and the Great Leap Forward&quot; I suggested that in addition
&gt; to providing a neural substrate for figuring out another
&gt; persons intentions (as noted by Rizzolati's group) the emergence and
&gt; subsequent sophistication of mirror neurons in hominids may
&gt; have played a crucial role in many quintessentially human abilities such
&gt; as empathy, learning through imitation (rather than trial
&gt; and error), and the rapid transmission of what we call &quot;culture&quot;. (And the
&gt; &quot;great leap forward&quot; - the rapid Lamarckian transmission
&gt; of &quot;accidental&quot;) one-of-a kind inventions.

&gt; I turn now to the main concern of this essay - the nature of self. When
&gt; you think of your own self, what comes into mind? You have
&gt; sense of &quot;introspecting&quot; on your own thoughts and feelings and of &quot;
&gt; watching&quot; yourself going about your business - as if you were
&gt; looking at yourself from another persons vantage point. How does this
&gt; happen ?

&gt; Evolution often takes advantage of pre-existing structures to evolve
&gt; completely novel abilities. I suggest that once the ability to
&gt; engage in cross modal abstraction emerged - e.g. between visual &quot;vertical&quot;
&gt; on the retina and photoreceptive &quot;vertical&quot; signaled by
&gt; muscles (for grasping trees) it set the stage for the emergence of mirror
&gt; neurons in hominids. Mirror neurons are also abundant in
&gt; the inferior parietal lobule - a structure that underwent an accelerated
&gt; expansion in the great apes and, later, in humans.. As the
&gt; brain evolved further the lobule split into two gyri - the supramarginal
&gt; gyrus that allowed you to &quot;reflect&quot; on your own anticipated
&gt; actions and the angular gyrus that allowed you to &quot;reflect&quot; on your body
&gt; (on the right) and perhaps on other more social and
&gt; linguistic aspects of your self (left hemisphere) I have argued elsewhere
&gt; that mirror neurons are fundamentally performing a kind of
&gt; abstraction across activity in visual maps and motor maps. This in turn
&gt; may have paved the way for more conceptual types of
&gt; abstraction; such as metaphor (&quot;get a grip on yourself&quot;).

&gt; How does all this lead to self awareness? I suggest that self awareness is
&gt; simply using mirror neurons for &quot;looking at myself as if
&gt; someone else is look at me&quot; (the word &quot;me&quot; encompassing some of my brain
&gt; processes, as well). The mirror neuron mechanism - the same
&gt; algorithm - that originally evolved to help you adopt another's point of
&gt; view was turned inward to look at your own self. This, in
&gt; essence, is the basis of things like &quot;introspection&quot;. It may not be
&gt; coincidental that we use phrases like &quot;self conscious&quot; when you
&gt; really mean that you are conscious of others being conscious of you. Or
&gt; say &quot;I am reflecting&quot; when you mean you are aware of
&gt; yourself thinking. In other words the ability to turn inward to introspect
&gt; or reflect may be a sort of metaphorical extension of the
&gt; mirror neurons ability to read others minds. It is often tacitly assumed
&gt; that the uniquely human ability to construct a &quot;theory of
&gt; other minds&quot; or &quot;TOM&quot; (seeing the world from the others point of view;
&gt; &quot;mind reading&quot;, figuring out what someone is up to, etc.)
&gt; must come after an already pre- existing sense of self. I am arguing that
&gt; the exact opposite is true; the TOM evolved first in
&gt; response to social needs and then later, as an unexpected bonus, came the
&gt; ability to introspect on your own thoughts and intentions.
&gt; I claim no great originality for these ideas; they are part of the current
&gt; zeitgeist. Any novelty derives from the manner in which I
&gt; shall marshall the evidence from physiology and from our own work in
&gt; neurology. Note that I am not arguing that mirror neurons are
&gt; sufficient for the emergence of self; only that they must have played a
&gt; pivotal role. (Otherwise monkeys would have self awareness
&gt; and they don't). They may have to reach a certain critical level of
&gt; sophistication that allowed them to build on earlier functions
&gt; (TOM) and become linked to certain other brain circuits, especially the
&gt; Wernickes (&quot;language comprehension&quot;) area and parts of the
&gt; frontal lobes.

&gt; Does the mirror neuron theory of self make other predictions? Given our
&gt; discovery that autistic children have deficient mirror
&gt; neurons and correspondingly deficient TOM, we would predict that they
&gt; would have a deficient sense of self (TMM) and difficulty with
&gt; introspection. The same might be true for other neurological disorders;
&gt; damage to the inferior parietal lobule/TPO junction (which
&gt; are known to contain mirror neurons) and parts of
">

...
read more »
</POST>
<POST>
<POSTER> Sir Frederick &lt;mmcne...@fuzzysys.com&gt; </POSTER>
<POSTDATE> 2007-01-22T23:06:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
On Mon, 22 Jan 2007 22:13:50 -0500, &quot;tooly&quot; &lt;r ... @bellsouth.net&gt; wrote:
&gt;Your materialist viewpoint makes me want to say one thing...
&gt;Where's the friggin 'off' switch.  If we continue down this track, we must
&gt;provide an 'off' switch for those who do not wish to make this decidely
&gt;'anti-human' journey.

&gt;Otherwise, YOU [the scientific, super-rational, materialist] have become
&gt;monsters.  Just a simply off switch is all we'd ask...NO PAIN; and then you
&gt;can have without obstacle, your world of 'neurons' and your throne upon
&gt;which you sit as master of intelligencia.
">

I don't mean to frustrate you but apparently the situation,
simply, is not simple. Thus your requested "simply off switch",
is not available. What is available, is not simple, it is structural
deterioration, also known as death.
On the other hand, the investigation of holistic "organizing
principles", continues. At this point the proven reductionistic
paradigm holds, but may not be sufficient, though by definition
it portends to be sufficient, as in the article.
</POST>
<POST>
<POSTER> "someone2" &lt;glenn.spig...@btinternet.com&gt; </POSTER>
<POSTDATE> 2007-01-23T00:33:00 </POSTDATE>
<QUOTE PREVIOUSPOST="
Sir Frederick wrote:
&gt; On Mon, 22 Jan 2007 22:13:50 -0500, &quot;tooly&quot; &lt;r ... @bellsouth.net&gt; wrote:

&gt; &gt;Your materialist viewpoint makes me want to say one thing...
&gt; &gt;Where's the friggin 'off' switch.  If we continue down this track, we must
&gt; &gt;provide an 'off' switch for those who do not wish to make this decidely
&gt; &gt;'anti-human' journey.

&gt; &gt;Otherwise, YOU [the scientific, super-rational, materialist] have become
&gt; &gt;monsters.  Just a simply off switch is all we'd ask...NO PAIN; and then you
&gt; &gt;can have without obstacle, your world of 'neurons' and your throne upon
&gt; &gt;which you sit as master of intelligencia.

&gt; I don't mean to frustrate you but apparently the situation,
&gt; simply, is not simple. Thus your requested &quot;simply off switch&quot;,
&gt; is not available. What is available, is not simple, it is structural
&gt; deterioration, also known as death.
&gt; On the other hand, the investigation of holistic &quot;organizing
&gt; principles&quot;, continues. At this point the proven reductionistic
&gt; paradigm holds, but may not be sufficient, though by definition
&gt; it portends to be sufficient, as in the article.
">

If, human behaviour could be explained purely in terms of the physical
organism following the laws of physics (i.e. without reference to
consciousness, or the conscious experiences hemselves) as you seem to
be suggesting, then how can the consciousness or the conscious
experiences themselves be causally active if not required in the
explanation? Consider that the first explanation (physical organism
following the laws of physics) could have had the added assumption that
there was no consciousness or conscious experiences, yet from your
perspective it would still explain the behaviour.

If they are not causally active in themselves, they cannot be an
evolutionary advantage, and therefore Humphrey's has argument "that our
ability to introspect may have evolved specifically to construct
meaningful models of other peoples minds in order to predict their
behavior. 'I feel jealous in order to understand what
jealousy feels like in someone else' - a short cut to predicting that
persons behavior" falls down.

You can't have your feet in both camps (that your conscious experiences
have any influence on your behaviour, and that the behaviour of the
human could be explained purely in terms of the physical organism
following the laws of physics), other than by holding the idea that
coincidentally the universe just happened to be such that the neural
activity which evolved uninfluenced by any conscious experiences, just
happened to correlate to the
appropriate conscious experiences such that the illusion that we
consciously influenced our behaviour was created.
</POST>
<POST>
<POSTER> Publius &lt;m.publ...@nospam.comcast.net&gt; </POSTER>
<POSTDATE> 2007-01-24T02:17:00 </POSTDATE>
"someone2" &lt;glenn.spig ... @btinternet.com&gt; wrote in
news:1169530405.928282.161000@11g2000cwr.googlegroups.com:

<QUOTE PREVIOUSPOST="
&gt; If, human behaviour could be explained purely in terms of the physical
&gt; organism following the laws of physics (i.e. without reference to
&gt; consciousness, or the conscious experiences hemselves) as you seem to
&gt; be suggesting, then how can the consciousness or the conscious
&gt; experiences themselves be causally active if not required in the
&gt; explanation?
">

Your argument is a good one.

Consciousness as a process can be explained by the laws of physics. What
cannot be explained is the "subjective feel" of primary phenomena, e.g., why
red looks like red. Those cannot be explained because they cannot be
described --- descriptive propositions characterizing them cannot be
formulated.

Explanation consists in providing a set of propositions (the *explanans*)
from which another descriptive proposition (the *explanadum*) can be derived.
But since the *explanandum* statement cannot be formulated, it cannot be
derived from any theory, physical or otherwise. Hence, the "subjective feel"
of things is *intrinsically* subjective. Which is perfectly consistent with
the laws of physics.
</POST>
<POST>
<POSTER> "someone2" &lt;glenn.spig...@btinternet.com&gt; </POSTER>
<POSTDATE> 2007-01-24T04:56:00 </POSTDATE>
On 24 Jan, 07:17, Publius &lt;m.publ ... @nospam.comcast.net&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; &quot;someone2&quot; &lt;glenn.spig ... @btinternet.com&gt; wrote in news:1169530405.928282.161000@11g2000cwr.googlegroups.com:

&gt; &gt; If, human behaviour could be explained purely in terms of the physical
&gt; &gt; organism following the laws of physics (i.e. without reference to
&gt; &gt; consciousness, or the conscious experiences hemselves) as you seem to
&gt; &gt; be suggesting, then how can the consciousness or the conscious
&gt; &gt; experiences themselves be causally active if not required in the
&gt; &gt; explanation?

&gt; Your argument is a good one.

&gt; Consciousness as a process can be explained by the laws of physics. What
&gt; cannot be explained is the &quot;subjective feel&quot; of primary phenomena, e.g., why
&gt; red looks like red. Those cannot be explained because they cannot be
&gt; described --- descriptive propositions characterizing them cannot be
&gt; formulated.

&gt; Explanation consists in providing a set of propositions (the *explanans*)
&gt; from which another descriptive proposition (the *explanadum*) can be derived.
&gt; But since the *explanandum* statement cannot be formulated, it cannot be
&gt; derived from any theory, physical or otherwise. Hence, the &quot;subjective feel&quot;
&gt; of things is *intrinsically* subjective. Which is perfectly consistent with
&gt; the laws of physics.
">

Why is a description of the conscious experiences so important in
giving an explanation for them. We know what consciousness and
conscious experiences are, as we are, and we have them, any description
of the experience could never elucidate more than the actual experience
itself.

Our experience though isn't consistent with the materialist perspective
though. As we experience the sensation of 'will', and that our
conscious experiences are influential in how the human we experience
being behaves.

Though, from the materialist perspective, it would have to be an
illusion that our conscious experiences themselves were influential in
the behaviour. This could not be the case though from their
perspective, for if they were right the human behaviour could be
explained without reference to it, and with the assumption that there
was no consciousness and no conscious experiences.

The problem with that perspective is that it is implausible, as it
would have to rely on the coincidence that the universe just happened
to be such that the neural activity which evolved uninfluenced by any
conscious experiences, just happened to correlate to the appropriate
conscious experiences such that the illusion that we consciously
influenced our behaviour was created.
</POST>
<POST>
<POSTER> "someone2" &lt;glenn.spig...@btinternet.com&gt; </POSTER>
<POSTDATE> 2007-01-24T08:14:00 </POSTDATE>
On 24 Jan, 07:17, Publius &lt;m.publ ... @nospam.comcast.net&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; &quot;someone2&quot; &lt;glenn.spig ... @btinternet.com&gt; wrote in news:1169530405.928282.161000@11g2000cwr.googlegroups.com:

&gt; &gt; If, human behaviour could be explained purely in terms of the physical
&gt; &gt; organism following the laws of physics (i.e. without reference to
&gt; &gt; consciousness, or the conscious experiences hemselves) as you seem to
&gt; &gt; be suggesting, then how can the consciousness or the conscious
&gt; &gt; experiences themselves be causally active if not required in the
&gt; &gt; explanation?Your argument is a good one.

&gt; Consciousness as a process can be explained by the laws of physics. What
&gt; cannot be explained is the &quot;subjective feel&quot; of primary phenomena, e.g., why
&gt; red looks like red. Those cannot be explained because they cannot be
&gt; described --- descriptive propositions characterizing them cannot be
&gt; formulated.

&gt; Explanation consists in providing a set of propositions (the *explanans*)
&gt; from which another descriptive proposition (the *explanadum*) can be derived.
&gt; But since the *explanandum* statement cannot be formulated, it cannot be
&gt; derived from any theory, physical or otherwise. Hence, the &quot;subjective feel&quot;
&gt; of things is *intrinsically* subjective. Which is perfectly consistent with
&gt; the laws of physics.
">
</POST>
<POST>
<POSTER> "someone2" &lt;glenn.spig...@btinternet.com&gt; </POSTER>
<POSTDATE> 2007-01-24T08:20:00 </POSTDATE>
On 24 Jan, 07:17, Publius &lt;m.publ ... @nospam.comcast.net&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; &quot;someone2&quot; &lt;glenn.spig ... @btinternet.com&gt; wrote in news:1169530405.928282.161000@11g2000cwr.googlegroups.com:

&gt; &gt; If, human behaviour could be explained purely in terms of the physical
&gt; &gt; organism following the laws of physics (i.e. without reference to
&gt; &gt; consciousness, or the conscious experiences hemselves) as you seem to
&gt; &gt; be suggesting, then how can the consciousness or the conscious
&gt; &gt; experiences themselves be causally active if not required in the
&gt; &gt; explanation?Your argument is a good one.

&gt; Consciousness as a process can be explained by the laws of physics. What
&gt; cannot be explained is the &quot;subjective feel&quot; of primary phenomena, e.g., why
&gt; red looks like red. Those cannot be explained because they cannot be
&gt; described --- descriptive propositions characterizing them cannot be
&gt; formulated.

&gt; Explanation consists in providing a set of propositions (the *explanans*)
&gt; from which another descriptive proposition (the *explanadum*) can be derived.
&gt; But since the *explanandum* statement cannot be formulated, it cannot be
&gt; derived from any theory, physical or otherwise. Hence, the &quot;subjective feel&quot;
&gt; of things is *intrinsically* subjective. Which is perfectly consistent with
&gt; the laws of physics.
">

(Just reposting with a tidied up response)

Why is a description of the conscious experiences so important in
giving an explanation for them. We know what consciousness and
conscious experiences are, as we are, and we have them, any description
of the experience could never elucidate more than the actual experience
itself.

Our experience though isn't consistent with the materialist perspective
though. As we experience the sensation of 'will', and that our
conscious experiences are influential in how the human we experience
being behaves.

<QUOTE PREVIOUSPOST="
&gt;From the materialist perspective, it would have to be an illusion that
">

our conscious experiences themselves were influential in the behaviour.
As from their perspective, the human behaviour could be explained
without reference to it (i.e. in terms of the biological organism
following the laws of physics), and the explaination would not change
if the assumption that there was no consciousness and no conscious
experiences were to be added.

Therefore while some argue of the evolutionary advantages of
consciousness, and conscious experiences, there could be none from the
materialist perspective, they just don't fully understand the
perspective the claim to hold.

The problem with the materialist perspective is that it is implausible,
as it would have to rely on the coincidence that the universe just
happened to be such that the neural activity which evolved uninfluenced
by any conscious experiences, just happened to correlate to the
appropriate conscious experiences such that the illusion that we
consciously influenced our behaviour was created.
</POST>
<POST>
<POSTER> Publius &lt;m.publ...@nospam.comcast.net&gt; </POSTER>
<POSTDATE> 2007-01-24T22:26:00 </POSTDATE>
"someone2" &lt;glenn.spig ... @btinternet.com&gt; wrote in
news:1169644825.480954.233700@s48g2000cws.googlegroups.com:

<QUOTE PREVIOUSPOST="
&gt; Why is a description of the conscious experiences so important in
&gt; giving an explanation for them. We know what consciousness and
&gt; conscious experiences are, as we are, and we have them, any description
&gt; of the experience could never elucidate more than the actual experience
&gt; itself.
">

Because an explanation must be predictive. It says, "D happens because A,B,
and C have happened. Whenever A, B, and C happen, D will happen." It may go
on to describe further connections between A, B, C, and D.

But if D is a perception of color, a description of that color is not
possible. So we cannot tell someone (predict) what any color will "look
like" via any theory.

An explanation of why red looks like it does would go, "Red looks so-and-so
because of A, B, and C." But we can't fill in the so-and-so, hence cannot
relate it to A, B, and C.

<QUOTE PREVIOUSPOST="
&gt; Our experience though isn't consistent with the materialist perspective
&gt; though. As we experience the sensation of 'will', and that our
&gt; conscious experiences are influential in how the human we experience
&gt; being behaves.
">

All that is necessary is to explain how and why a system can have subjective
experiences. It is not necessary to describe the experiences (if that could
be done, they would not be subjective).

<QUOTE PREVIOUSPOST="
&gt; The problem with the materialist perspective is that it is implausible,
&gt; as it would have to rely on the coincidence that the universe just
&gt; happened to be such that the neural activity which evolved uninfluenced
&gt; by any conscious experiences, just happened to correlate to the
&gt; appropriate conscious experiences such that the illusion that we
&gt; consciously influenced our behaviour was created.
">

I'd agree, except that it is not a coincidence. Certain kinds of system will
have subjective experiences. But the reasons they have them are consistent
with physical laws.
</POST>
<POST>
<POSTER> "someone2" &lt;glenn.spig...@btinternet.com&gt; </POSTER>
<POSTDATE> 2007-01-25T07:23:00 </POSTDATE>
On 25 Jan, 03:26, Publius &lt;m.publ ... @nospam.comcast.net&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; &quot;someone2&quot; &lt;glenn.spig ... @btinternet.com&gt; wrote in news:1169644825.480954.233700@s48g2000cws.googlegroups.com:

&gt; &gt; Why is a description of the conscious experiences so important in
&gt; &gt; giving an explanation for them. We know what consciousness and
&gt; &gt; conscious experiences are, as we are, and we have them, any description
&gt; &gt; of the experience could never elucidate more than the actual experience
&gt; &gt; itself.

&gt; Because an explanation must be predictive. It says, &quot;D happens because A,B,
&gt; and C have happened. Whenever A, B, and C happen, D will happen.&quot; It may go
&gt; on to describe further connections between A, B, C, and D.

&gt; But if D is a perception of color, a description of that color is not
&gt; possible. So we cannot tell someone (predict) what any color will &quot;look
&gt; like&quot; via any theory.

&gt; An explanation of why red looks like it does would go, &quot;Red looks so-and-so
&gt; because of A, B, and C.&quot; But we can't fill in the so-and-so, hence cannot
&gt; relate it to A, B, and C.

&gt; &gt; Our experience though isn't consistent with the materialist perspective
&gt; &gt; though. As we experience the sensation of 'will', and that our
&gt; &gt; conscious experiences are influential in how the human we experience
&gt; &gt; being behaves.

&gt; All that is necessary is to explain how and why a system can have subjective
&gt; experiences. It is not necessary to describe the experiences (if that could
&gt; be done, they would not be subjective).

&gt; &gt; The problem with the materialist perspective is that it is implausible,
&gt; &gt; as it would have to rely on the coincidence that the universe just
&gt; &gt; happened to be such that the neural activity which evolved uninfluenced
&gt; &gt; by any conscious experiences, just happened to correlate to the
&gt; &gt; appropriate conscious experiences such that the illusion that we
&gt; &gt; consciously influenced our behaviour was created.

&gt; I'd agree, except that it is not a coincidence. Certain kinds of system will
&gt; have subjective experiences. But the reasons they have them are consistent
&gt; with physical laws.
">

Well a non-materialist perspective could give the prediction that the
conscious experience will be such that it appears that you have 'free
will' and can make conscious choices. Though how that prediction added
to the explanation I'm not sure.

Whether it can be said to be scientifically provable could be the
subject of a debate. As the answer would seem to rely on being the
conscious subject of the experiment in order to know whether the
response given about conscious preferability actually matched the
conscious experience. Though each of us would know it to be true.

How can materialism lay claim to such a prediction? If it couldn't then
it would be a prediction which distinguishes between them.
</POST>
<POST>
<POSTER> Publius &lt;m.publ...@nospam.comcast.net&gt; </POSTER>
<POSTDATE> 2007-01-25T23:52:00 </POSTDATE>
"someone2" &lt;glenn.spig ... @btinternet.com&gt; wrote in
news:1169727800.474622.6520@s48g2000cws.googlegroups.com:

<QUOTE PREVIOUSPOST="
&gt; Well a non-materialist perspective could give the prediction that the
&gt; conscious experience will be such that it appears that you have 'free
&gt; will' and can make conscious choices. Though how that prediction added
&gt; to the explanation I'm not sure.

&gt; Whether it can be said to be scientifically provable could be the
&gt; subject of a debate. As the answer would seem to rely on being the
&gt; conscious subject of the experiment in order to know whether the
&gt; response given about conscious preferability actually matched the
&gt; conscious experience. Though each of us would know it to be true.

&gt; How can materialism lay claim to such a prediction? If it couldn't then
&gt; it would be a prediction which distinguishes between them.
">

You can predict subjective experiences if you have an objective means of
identifying them. That is, if you can have an objective basis for saying,
"Alfie is having (or had) a subjective experience," or, "Alfie just had
subjective experience B." It is not necessary to describe what that
subjective experience "was like." (Indeed, if you could describe what
experience B "was like" it would not be a subjective experience, but an
objective one.)
</POST>
<POST>
<POSTER> "someone2" &lt;glenn.spig...@btinternet.com&gt; </POSTER>
<POSTDATE> 2007-01-26T04:58:00 </POSTDATE>
On 26 Jan, 04:52, Publius &lt;m.publ ... @nospam.comcast.net&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; &quot;someone2&quot; &lt;glenn.spig ... @btinternet.com&gt; wrote in news:1169727800.474622.6520@s48g2000cws.googlegroups.com:

&gt; &gt; Well a non-materialist perspective could give the prediction that the
&gt; &gt; conscious experience will be such that it appears that you have 'free
&gt; &gt; will' and can make conscious choices. Though how that prediction added
&gt; &gt; to the explanation I'm not sure.

&gt; &gt; Whether it can be said to be scientifically provable could be the
&gt; &gt; subject of a debate. As the answer would seem to rely on being the
&gt; &gt; conscious subject of the experiment in order to know whether the
&gt; &gt; response given about conscious preferability actually matched the
&gt; &gt; conscious experience. Though each of us would know it to be true.

&gt; &gt; How can materialism lay claim to such a prediction? If it couldn't then
&gt; &gt; it would be a prediction which distinguishes between them.

&gt; You can predict subjective experiences if you have an objective means of
&gt; identifying them. That is, if you can have an objective basis for saying,
&gt; &quot;Alfie is having (or had) a subjective experience,&quot; or, &quot;Alfie just had
&gt; subjective experience B.&quot; It is not necessary to describe what that
&gt; subjective experience &quot;was like.&quot; (Indeed, if you could describe what
&gt; experience B &quot;was like&quot; it would not be a subjective experience, but an
&gt; objective one.)
">

I agree, you could predict subjective experiences, and have an
objective basis for predicting them, your own experience, and the basis
that there is no reason for thinking other people to be experiencing in
essence anything different to yourself, and any rules you have found
out about how various neural activity effects subjective experiences.

The experience you are having is an objective one, in regards to what
you are experiencing, though I fail to see how materialism predicts it.

You could try to add on explanation to materialism, it would seem to
need to explain why there would be an expectation of a correlation
between what is consciously preferable and the way the human you
experience being behaves, and an explanation of the sensation of 'free
will', in order to be able to predict them.
</POST>
<POST>
<POSTER> Publius &lt;m.publ...@nospam.comcast.net&gt; </POSTER>
<POSTDATE> 2007-01-27T00:56:00 </POSTDATE>
"someone2" &lt;glenn.spig ... @btinternet.com&gt; wrote in
news:1169805488.046483.327300@q2g2000cwa.googlegroups.com:

<QUOTE PREVIOUSPOST="
&gt;&gt; You can predict subjective experiences if you have an objective means
&gt;&gt; of identifying them. That is, if you can have an objective basis for
&gt;&gt; saying, &quot;Alfie is having (or had) a subjective experience,&quot; or, &quot;Alfie
&gt;&gt; just had subjective experience B.&quot; It is not necessary to describe what
&gt;&gt; that subjective experience &quot;was like.&quot; (Indeed, if you could describe
&gt;&gt; what experience B &quot;was like&quot; it would not be a subjective experience,
&gt;&gt; but an objective one.)
&gt; I agree, you could predict subjective experiences, and have an
&gt; objective basis for predicting them, your own experience, and the basis
&gt; that there is no reason for thinking other people to be experiencing in
&gt; essence anything different to yourself, and any rules you have found
&gt; out about how various neural activity effects subjective experiences.
">

No, the basis for imputing subjective states to others is those others'
inability to describe those states in an informative way. We can also account
theoretically for why they are unable to do that, and thus predict that
inability.

<QUOTE PREVIOUSPOST="
&gt; The experience you are having is an objective one, in regards to what
&gt; you are experiencing, though I fail to see how materialism predicts it.
">

The experience is objective. The internal state to which it gives rise is
subjective.

<QUOTE PREVIOUSPOST="
&gt; You could try to add on explanation to materialism, it would seem to
&gt; need to explain why there would be an expectation of a correlation
&gt; between what is consciously preferable and the way the human you
&gt; experience being behaves, and an explanation of the sensation of 'free
&gt; will', in order to be able to predict them.
">

Preferences are also subjective states. We impute them in order to explain
why a given person, say P, chooses X rather than Y. P also *experiences* that
preference as a subjective state. And like other subjective states, P cannot
explain that state in an informative way. That is, P cannot explain why he
prefers chocolate to vanilla, just as he cannot explain what red "looks
like." And for the same reason.
</POST>
<POST>
<POSTER> "someone2" &lt;glenn.spig...@btinternet.com&gt; </POSTER>
<POSTDATE> 2007-01-27T13:07:00 </POSTDATE>
On 27 Jan, 05:56, Publius &lt;m.publ ... @nospam.comcast.net&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; &quot;someone2&quot; &lt;glenn.spig ... @btinternet.com&gt; wrote in news:1169805488.046483.327300@q2g2000cwa.googlegroups.com:

&gt; &gt;&gt; You can predict subjective experiences if you have an objective means
&gt; &gt;&gt; of identifying them. That is, if you can have an objective basis for
&gt; &gt;&gt; saying, &quot;Alfie is having (or had) a subjective experience,&quot; or, &quot;Alfie
&gt; &gt;&gt; just had subjective experience B.&quot; It is not necessary to describe what
&gt; &gt;&gt; that subjective experience &quot;was like.&quot; (Indeed, if you could describe
&gt; &gt;&gt; what experience B &quot;was like&quot; it would not be a subjective experience,
&gt; &gt;&gt; but an objective one.)
&gt; &gt; I agree, you could predict subjective experiences, and have an
&gt; &gt; objective basis for predicting them, your own experience, and the basis
&gt; &gt; that there is no reason for thinking other people to be experiencing in
&gt; &gt; essence anything different to yourself, and any rules you have found
&gt; &gt; out about how various neural activity effects subjective experiences.No, the basis for imputing subjective states to others is those others'
&gt; inability to describe those states in an informative way. We can also account
&gt; theoretically for why they are unable to do that, and thus predict that
&gt; inability.

&gt; &gt; The experience you are having is an objective one, in regards to what
&gt; &gt; you are experiencing, though I fail to see how materialism predicts it.The experience is objective. The internal state to which it gives rise is
&gt; subjective.

&gt; &gt; You could try to add on explanation to materialism, it would seem to
&gt; &gt; need to explain why there would be an expectation of a correlation
&gt; &gt; between what is consciously preferable and the way the human you
&gt; &gt; experience being behaves, and an explanation of the sensation of 'free
&gt; &gt; will', in order to be able to predict them.Preferences are also subjective states. We impute them in order to explain
&gt; why a given person, say P, chooses X rather than Y. P also *experiences* that
&gt; preference as a subjective state. And like other subjective states, P cannot
&gt; explain that state in an informative way. That is, P cannot explain why he
&gt; prefers chocolate to vanilla, just as he cannot explain what red &quot;looks
&gt; like.&quot; And for the same reason.
">

You say:
---------
No, the basis for imputing subjective states to others is those
others' inability to describe those states in an informative way. We
can also count theoretically for why they are unable to do that, and
thus predict that inability.
---------

<QUOTE PREVIOUSPOST="
&gt;From a materialist perspective though, the account wouldn't differ
">

regardless of whether they were having conscious experiences or not,
as from the materialist perspective, anything that is conscious and
experiencing the sensation of free will, will act as though it isn't
conscious.

I disagree that preferences are subjective states in the sense that
someone putting their hand in a fire, can objectively state from their
experience that putting their hand into a fire is not consciously
preferable for them.

In the sense that you seem to mean it, where you are regarding imputed
consciousness (i.e. it doesn't matter whether the thing is actually
conscious or not), then your imputed preference explanations are a
nonsense. As the conscious preferences themselves would have no effect
on the behaviour of the organism (from a materialist perspective), and
therefore can add no explanation, thus any explanation of behaviour
regarding preference would be a nonsense.

Consciousness itself is not imputed, nor are conscious prefences, they
are real. Try putting your hand into a flame, and you will soon see
that it is a very real conscious preference to will it out of the
flame again.
</POST>
<POST>
<POSTER> "someone2" &lt;glenn.spig...@btinternet.com&gt; </POSTER>
<POSTDATE> 2007-01-27T17:38:00 </POSTDATE>
On 27 Jan, 18:07, "someone2" &lt;glenn.spig ... @btinternet.com&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; On 27 Jan, 05:56, Publius &lt;m.publ ... @nospam.comcast.net&gt; wrote:

&gt; &gt; &quot;someone2&quot; &lt;glenn.spig ... @btinternet.com&gt; wrote in news:1169805488.046483.327300@q2g2000cwa.googlegroups.com:

&gt; &gt; &gt;&gt; You can predict subjective experiences if you have an objective means
&gt; &gt; &gt;&gt; of identifying them. That is, if you can have an objective basis for
&gt; &gt; &gt;&gt; saying, &quot;Alfie is having (or had) a subjective experience,&quot; or, &quot;Alfie
&gt; &gt; &gt;&gt; just had subjective experience B.&quot; It is not necessary to describe what
&gt; &gt; &gt;&gt; that subjective experience &quot;was like.&quot; (Indeed, if you could describe
&gt; &gt; &gt;&gt; what experience B &quot;was like&quot; it would not be a subjective experience,
&gt; &gt; &gt;&gt; but an objective one.)
&gt; &gt; &gt; I agree, you could predict subjective experiences, and have an
&gt; &gt; &gt; objective basis for predicting them, your own experience, and the basis
&gt; &gt; &gt; that there is no reason for thinking other people to be experiencing in
&gt; &gt; &gt; essence anything different to yourself, and any rules you have found
&gt; &gt; &gt; out about how various neural activity effects subjective experiences.No, the basis for imputing subjective states to others is those others'
&gt; &gt; inability to describe those states in an informative way. We can also account
&gt; &gt; theoretically for why they are unable to do that, and thus predict that
&gt; &gt; inability.

&gt; &gt; &gt; The experience you are having is an objective one, in regards to what
&gt; &gt; &gt; you are experiencing, though I fail to see how materialism predicts it.The experience is objective. The internal state to which it gives rise is
&gt; &gt; subjective.

&gt; &gt; &gt; You could try to add on explanation to materialism, it would seem to
&gt; &gt; &gt; need to explain why there would be an expectation of a correlation
&gt; &gt; &gt; between what is consciously preferable and the way the human you
&gt; &gt; &gt; experience being behaves, and an explanation of the sensation of 'free
&gt; &gt; &gt; will', in order to be able to predict them.Preferences are also subjective states. We impute them in order to explain
&gt; &gt; why a given person, say P, chooses X rather than Y. P also *experiences* that
&gt; &gt; preference as a subjective state. And like other subjective states, P cannot
&gt; &gt; explain that state in an informative way. That is, P cannot explain why he
&gt; &gt; prefers chocolate to vanilla, just as he cannot explain what red &quot;looks
&gt; &gt; like.&quot; And for the same reason.You say:
&gt; ---------
&gt; No, the basis for imputing subjective states to others is those
&gt; others' inability to describe those states in an informative way. We
&gt; can also count theoretically for why they are unable to do that, and
&gt; thus predict that inability.
&gt; ---------

&gt; &gt;From a materialist perspective though, the account wouldn't differregardless of whether they were having conscious experiences or not,
&gt; as from the materialist perspective, anything that is conscious and
&gt; experiencing the sensation of free will, will act as though it isn't
&gt; conscious.

&gt; I disagree that preferences are subjective states in the sense that
&gt; someone putting their hand in a fire, can objectively state from their
&gt; experience that putting their hand into a fire is not consciously
&gt; preferable for them.

&gt; In the sense that you seem to mean it, where you are regarding imputed
&gt; consciousness (i.e. it doesn't matter whether the thing is actually
&gt; conscious or not), then your imputed preference explanations are a
&gt; nonsense. As the conscious preferences themselves would have no effect
&gt; on the behaviour of the organism (from a materialist perspective), and
&gt; therefore can add no explanation, thus any explanation of behaviour
&gt; regarding preference would be a nonsense.

&gt; Consciousness itself is not imputed, nor are conscious prefences, they
&gt; are real. Try putting your hand into a flame, and you will soon see
&gt; that it is a very real conscious preference to will it out of the
&gt; flame again.- Hide quoted text -- Show quoted text -
">

Can I just repost the last paragraph to read:
-------------------
Consciousness itself is not imputed, nor are conscious prefences, they
are real.
-------------------
</POST>
<POST>
<POSTER> Publius &lt;m.publ...@nospam.comcast.net&gt; </POSTER>
<POSTDATE> 2007-01-27T22:06:00 </POSTDATE>
"someone2" &lt;glenn.spig ... @btinternet.com&gt; wrote in
news:1169921268.517208.159980@j27g2000cwj.googlegroups.com:

<QUOTE PREVIOUSPOST="
&gt; You say:
&gt; ---------
&gt; No, the basis for imputing subjective states to others is those
&gt; others' inability to describe those states in an informative way. We
&gt; can also count theoretically for why they are unable to do that, and
&gt; thus predict that inability.
&gt; ---------

&gt;&gt;From a materialist perspective though, the account wouldn't differ
&gt; regardless of whether they were having conscious experiences or not,
&gt; as from the materialist perspective, anything that is conscious and
&gt; experiencing the sensation of free will, will act as though it isn't
&gt; conscious.
">

We impute "free will" in order to explain (some aspects of) behavior,
namely, the fact that specific behavior is not consistently predictable
from physical laws. BTW, we could have "free will" without consciousness.

"Consciousness" means the capacity to have subjective states --- tastes,
preferences, moods, sensations, etc. We impute those states because, unlike
the laws of physics, they help us explain and predict behavior. But we have
objective grounds for imputing those states, and even a physical
explanation for why those states are subjective.

<QUOTE PREVIOUSPOST="
&gt; In the sense that you seem to mean it, where you are regarding imputed
&gt; consciousness (i.e. it doesn't matter whether the thing is actually
&gt; conscious or not), then your imputed preference explanations are a
&gt; nonsense. As the conscious preferences themselves would have no effect
&gt; on the behaviour of the organism (from a materialist perspective), and
&gt; therefore can add no explanation, thus any explanation of behaviour
&gt; regarding preference would be a nonsense.
">

There is no sense to the phrase, "the thing is actually conscious or not."
You are assuming that consciousness must be a manifest property, like the
redness of a rose --- it either is, or it isn't. But that is not the sort
of concept "consciousness" is -- if postulating that property helps us
explain the behavior of an organism, then it "actually is" conscious. If it
does not, then it "actually isn't."

<QUOTE PREVIOUSPOST="
&gt; Consciousness itself is not imputed, nor are conscious prefences, they
&gt; are real. Try putting your hand into a flame, and you will soon see
&gt; that it is a very real conscious preference to will it out of the
&gt; flame again.
">

What I will see is that I removed my hand from the flame. I will not see
consciousness, nor preferences. However, I may postulate those to help
*explain* that observable behavior.
</POST>
<POST>
<POSTER> "someone2" &lt;glenn.spig...@btinternet.com&gt; </POSTER>
<POSTDATE> 2007-01-28T08:12:00 </POSTDATE>
On 28 Jan, 03:06, Publius &lt;m.publ ... @nospam.comcast.net&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; &quot;someone2&quot; &lt;glenn.spig ... @btinternet.com&gt; wrote in news:1169921268.517208.159980@j27g2000cwj.googlegroups.com:

&gt; &gt; You say:
&gt; &gt; ---------
&gt; &gt; No, the basis for imputing subjective states to others is those
&gt; &gt; others' inability to describe those states in an informative way. We
&gt; &gt; can also count theoretically for why they are unable to do that, and
&gt; &gt; thus predict that inability.
&gt; &gt; ---------

&gt; &gt;&gt;From a materialist perspective though, the account wouldn't differ
&gt; &gt; regardless of whether they were having conscious experiences or not,
&gt; &gt; as from the materialist perspective, anything that is conscious and
&gt; &gt; experiencing the sensation of free will, will act as though it isn't
&gt; &gt; conscious.We impute &quot;free will&quot; in order to explain (some aspects of) behavior,
&gt; namely, the fact that specific behavior is not consistently predictable
&gt; from physical laws. BTW, we could have &quot;free will&quot; without consciousness.

&gt; &quot;Consciousness&quot; means the capacity to have subjective states --- tastes,
&gt; preferences, moods, sensations, etc. We impute those states because, unlike
&gt; the laws of physics, they help us explain and predict behavior. But we have
&gt; objective grounds for imputing those states, and even a physical
&gt; explanation for why those states are subjective.

&gt; &gt; In the sense that you seem to mean it, where you are regarding imputed
&gt; &gt; consciousness (i.e. it doesn't matter whether the thing is actually
&gt; &gt; conscious or not), then your imputed preference explanations are a
&gt; &gt; nonsense. As the conscious preferences themselves would have no effect
&gt; &gt; on the behaviour of the organism (from a materialist perspective), and
&gt; &gt; therefore can add no explanation, thus any explanation of behaviour
&gt; &gt; regarding preference would be a nonsense.There is no sense to the phrase, &quot;the thing is actually conscious or not.&quot;
&gt; You are assuming that consciousness must be a manifest property, like the
&gt; redness of a rose --- it either is, or it isn't. But that is not the sort
&gt; of concept &quot;consciousness&quot; is -- if postulating that property helps us
&gt; explain the behavior of an organism, then it &quot;actually is&quot; conscious. If it
&gt; does not, then it &quot;actually isn't.&quot;

&gt; &gt; Consciousness itself is not imputed, nor are conscious prefences, they
&gt; &gt; are real. Try putting your hand into a flame, and you will soon see
&gt; &gt; that it is a very real conscious preference to will it out of the
&gt; &gt; flame again.What I will see is that I removed my hand from the flame. I will not see
&gt; consciousness, nor preferences. However, I may postulate those to help
&gt; *explain* that observable behavior.
">

How can you see that you removed your hand through the flame without
being conscious? How can you say that you think that there is no
conscious preferable difference between having your hand in a flame in
or out of a flame. You don't postulate pain to 'help *explain* that
observable behaviour', you naturally no longer will your hand into the
flame, because it is a conscious preference for it not to be there,
i.e. you switch your will, and if you imagine pushing your hand
against the conscious preference gradient, as soon as you stop pushing
it and let go, it comes back again with the change in your will. Even
if actually there might be a reflex action built in safety mechanism,
I'm not sure it would kick in when willing your hand into a flame, for
if it always did, it would seem to be impossible to put your hand into
a flame.

Regarding what you said about consciousness:

------------------
You are assuming that consciousness must be a manifest property, like
the redness of a rose --- it either is, or it isn't.But that is not
the sort of concept "consciousness" is -- if postulating that property
helps us explain the behavior of an organism, then it "actually is"
conscious. If it does not, then it "actually isn't."
------------------

Well given the colour red only exists as a conscious experience, yes I
do regard consciousness as real, and the colour red that was seen to
be a real experience. You would seem to like to redefine the very real
experience of consciousness and the conscious experience of the
physical world that we have, and replace it with the idea that
consciousness is just a concept, not real in itself. What I did get a
bit confused about was where you were imputing conscious, and then
saying that if you did it actually would be conscious. I presume you
just mean to the extent that to be conscious just means that the
object in question had been imputed to be conscious. Presumably from
the materialistic perspective, given whether or not the object
actually had what would formally be known as consciousness and
conscious experiences, wouldn't be expected to make any difference to
behaviour, so that if it could be imputed to a robot, it could be
imputed to a mobile phone. Given then the story of imputed conscious
experiences which can never effect behaviour, and therefore are not in
the realms of explanation for it, these models of behaviour in terms
of conscious experiences, would have to be false, as from the
materialist perspective they could not possibly provide explanation.
Did you have any kind of qualification restriction in mind about you
is allowed to officially impute consciousness?
</POST>
<POST>
<POSTER> Publius &lt;m.publ...@nospam.comcast.net&gt; </POSTER>
<POSTDATE> 2007-01-29T03:30:00 </POSTDATE>
"someone2" &lt;glenn.spig ... @btinternet.com&gt; wrote in
news:1169989944.132175.103610@p10g2000cwp.googlegroups.com:

<QUOTE PREVIOUSPOST="
&gt; How can you see that you removed your hand through the flame without
&gt; being conscious?
">

The same way a furnace can "see" that a thermostat has been triggered, and
shuts itself off. We do not assume the furnace is conscious.

<QUOTE PREVIOUSPOST="
&gt; How can you say that you think that there is no
&gt; conscious preferable difference between having your hand in a flame in
&gt; or out of a flame.
">

I didn't say there is no conscious preference. I said we can't *see* that
conscious preference. So we impute one.

<QUOTE PREVIOUSPOST="
&gt; Well given the colour red only exists as a conscious experience, yes I
&gt; do regard consciousness as real, and the colour red that was seen to
&gt; be a real experience. You would seem to like to redefine the very real
&gt; experience of consciousness and the conscious experience of the
&gt; physical world that we have, and replace it with the idea that
&gt; consciousness is just a concept, not real in itself.
">

You shall have to explain what you mean by "real in itself." What is real is
whatever our best theories declare to be real. Atoms are "real" if they help
us explain chemical reactions. Preferences and "qualia" are "real" if they
help us explain human behavior. Trees are "real" if they help us explain
certain patterns in sensory data.

<QUOTE PREVIOUSPOST="
&gt; What I did get a
&gt; bit confused about was where you were imputing conscious, and then
&gt; saying that if you did it actually would be conscious. I presume you
&gt; just mean to the extent that to be conscious just means that the
&gt; object in question had been imputed to be conscious. Presumably from
&gt; the materialistic perspective, given whether or not the object
&gt; actually had what would formally be known as consciousness and
&gt; conscious experiences, wouldn't be expected to make any difference to
&gt; behaviour, so that if it could be imputed to a robot, it could be
&gt; imputed to a mobile phone.
">

Yes, it could --- and might well be if imputing it to those devices helped us
explain their behavior. But if they were so imputed, then it would be because
they *do* have an explanatory role. It would "make a difference" (in our
ability to predict the behavior of those systems).
</POST>
<POST>
<POSTER> "someone2" &lt;glenn.spig...@btinternet.com&gt; </POSTER>
<POSTDATE> 2007-01-29T04:14:00 </POSTDATE>
On 29 Jan, 08:30, Publius &lt;m.publ ... @nospam.comcast.net&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; &quot;someone2&quot; &lt;glenn.spig ... @btinternet.com&gt; wrote in news:1169989944.132175.103610@p10g2000cwp.googlegroups.com:

&gt; &gt; How can you see that you removed your hand through the flame without
&gt; &gt; being conscious?

&gt; The same way a furnace can &quot;see&quot; that a thermostat has been triggered, and
&gt; shuts itself off. We do not assume the furnace is conscious.

&gt; &gt; How can you say that you think that there is no
&gt; &gt; conscious preferable difference between having your hand in a flame in
&gt; &gt; or out of a flame.

&gt; I didn't say there is no conscious preference. I said we can't *see* that
&gt; conscious preference. So we impute one.

&gt; &gt; Well given the colour red only exists as a conscious experience, yes I
&gt; &gt; do regard consciousness as real, and the colour red that was seen to
&gt; &gt; be a real experience. You would seem to like to redefine the very real
&gt; &gt; experience of consciousness and the conscious experience of the
&gt; &gt; physical world that we have, and replace it with the idea that
&gt; &gt; consciousness is just a concept, not real in itself.

&gt; You shall have to explain what you mean by &quot;real in itself.&quot; What is real is
&gt; whatever our best theories declare to be real. Atoms are &quot;real&quot; if they help
&gt; us explain chemical reactions. Preferences and &quot;qualia&quot; are &quot;real&quot; if they
&gt; help us explain human behavior. Trees are &quot;real&quot; if they help us explain
&gt; certain patterns in sensory data.

&gt; &gt; What I did get a
&gt; &gt; bit confused about was where you were imputing conscious, and then
&gt; &gt; saying that if you did it actually would be conscious. I presume you
&gt; &gt; just mean to the extent that to be conscious just means that the
&gt; &gt; object in question had been imputed to be conscious. Presumably from
&gt; &gt; the materialistic perspective, given whether or not the object
&gt; &gt; actually had what would formally be known as consciousness and
&gt; &gt; conscious experiences, wouldn't be expected to make any difference to
&gt; &gt; behaviour, so that if it could be imputed to a robot, it could be
&gt; &gt; imputed to a mobile phone.

&gt; Yes, it could --- and might well be if imputing it to those devices helped us
&gt; explain their behavior. But if they were so imputed, then it would be because
&gt; they *do* have an explanatory role. It would &quot;make a difference&quot; (in our
&gt; ability to predict the behavior of those systems).
">

In response to where I said:
-----------
How can you see that you removed your hand through the flame without
being conscious?
-----------

You replied:
-----------
The same way a furnace can "see" that a thermostat has been triggered,
and
shuts itself off. We do not assume the furnace is conscious.
-----------

which I presume is the same "see" as in your response:
-----------
I didn't say there is no conscious preference. I said we can't *see*
that conscious preference. So we impute one.
-----------

Yet I find it confusing, because the first reply doesn't seem to be
suggesting that "see" refers to the visual senstation, instead "see"
in a more of a, the thermostat broke the electrical current to the
furnace, not something that was experienced, type of a way. Whereas
the second reply indicates that you meant it in a way that was
experienced, but as a specific visual sensation type "see", not as
conscious preference.

You have a strange way of looking at reality. You seem to lay claim
that your theories created it.

As for your last point:
----------------
Yes, it could --- and might well be if imputing it to those devices
helped us explain their behavior. But if they were so imputed, then it
would be because they *do* have an explanatory role. It would "make a
difference" (in our ability to predict the behavior of those systems).
----------------

So no robot could ever be conscious because it would never be
necessary to impute it.
</POST>
<POST>
<POSTER> "Sammybaby" &lt;roastfreest...@yahoo.com&gt; </POSTER>
<POSTDATE> 2007-01-29T05:46:00 </POSTDATE>
I think the problem comes in because we are between paradigms.  When
they come up with 'physical' explanations for subjective experiences,
all the old Newtonian notions of what matters is and how it behaves
are dragged in also.  This means it sounds more upsetting than we need
to believe it is.  It also means that sometimes in their assumptions
about what must be like and limited to are also false, because they
are guided by old notions of matter. QM has not really trickled down,
let alone more recent physics, where distinctions between matter and
energy, here and far away and so on are not clear and things do not
simply relate like billiard balls.

For example they assume that as they come to understand the nature of
consciousness in humans and other vertabrates they reassure themselves
that other things do not have consciousness because they do not have
these 'physical' attributes.  My experience of finding subjectivity
outside this small realm contradicts this assumption.  For me other
very complicated self-interacting systems also have consciousness.
They have confused a specific type with the whole set.

It was not that long ago when scientists did not consider animals
conscious or as having emotions.  Rather, they, unlike us, were
machines.  The ironic thing is that two trends have taken place.  Some
see animals as like humans: conscious subjects and other scientists
see us both as complicated machines with the illusion of selfhood.

The off switch is to not buy it.  Adn to not get sucked into a
satellite viewpoint on own's expereince as the real perspective.  In
other words, what is life.  It is not this map but a hazy changing
mysterious realm. Examine what a 'physical' object is IN REALITY.
Like a table.  Examine this notion of SOLIDITY.  It is not so solid.
The funny thing is scientists have needed particle accelerators, at
the extreme end, to explore these kinds of things.

If you don't buy their system as THE MOST REAL it is often stated or
implied that this is emotional and or determined by your physical
nature.  What a mammal or a primate is willing to believe.  But leaves
open the question in response.  How do their beliefs about the non-
existance of the self, determinism, a primarily dead universe and so
on fit their emotional and physical needs.  What need does it satisfy
to overvalue mental calculation vs. intuition, for example.  Control
of emotions with occasional outbursts of anger vs. a flexible and
steadily expressive emotional response.  Is it simply a cooincidence
that the new religion values certain psychological traits that are
held by believers?

Is fear the root here?
On 23 Jan, 04:13, "tooly" &lt;r ... @bellsouth.net&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; Your materialist viewpoint makes me want to say one thing...
&gt; Where's the friggin 'off' switch.  If we continue down this track, we must
&gt; provide an 'off' switch for those who do not wish to make this decidely
&gt; 'anti-human' journey.

&gt; Otherwise, YOU [the scientific, super-rational, materialist] have become
&gt; monsters.  Just a simply off switch is all we'd ask...NO PAIN; and then you
&gt; can have without obstacle, your world of 'neurons' and your throne upon
&gt; which you sit as master of intelligencia.

&gt; &quot;Sir Frederick&quot; &lt;mmcne ... @fuzzysys.com&gt; wrote in message news:p94ar29ifm4gmqip1f0crppilsfgjp1men@4ax.com ...

&gt; &gt; http://www.edge.org/documents/archive/edge201.html#rama
&gt; &gt; THE NEUROLOGY OF SELF-AWARENESS
&gt; &gt; By V.S. Ramachandran

&gt; &gt; What is the self? How does the activity of neurons give rise to the sense
&gt; &gt; of being a conscious human being? Even this most ancient
&gt; &gt; of philosophical problems, I believe, will yield to the methods of
&gt; &gt; empirical science. It now seems increasingly likely that the self
&gt; &gt; is not a holistic property of the entire brain; it arises from the
&gt; &gt; activity of specific sets of interlinked brain circuits. But we
&gt; &gt; need to know which circuits are critically involved and what their
&gt; &gt; functions might be. It is the &quot;turning inward&quot; aspect of the self
&gt; &gt; - its recursiveness - that gives it its peculiar paradoxical quality.

&gt; &gt; It has been suggested by Horace Barlow, Nick Humphrey, David Premack and
&gt; &gt; Marvin Minsky (among others) thatconsciousnessmay have
&gt; &gt; evolved primarily in a social context. Minsky speaks of a second parallel
&gt; &gt; mechanism that has evolved in humans to create
&gt; &gt; representations of earlier representations and Humphrey has argued that
&gt; &gt; our ability to introspect may have evolved specifically to
&gt; &gt; construct meaningful models of other peoples minds in order to predict
&gt; &gt; their behavior. &quot;I feel jealous in order to understand what
&gt; &gt; jealousy feels like in someone else&quot; - a short cut to predicting that
&gt; &gt; persons behavior.

&gt; &gt; Here I develop these arguments further. If I succeed in seeing any further
&gt; &gt; it is by &quot;standing on the shoulders of these giants&quot;.
&gt; &gt; Specifically, I suggest that &quot;other awareness&quot; may have evolved first and
&gt; &gt; then counterintutively, as often happens in evolution, the
&gt; &gt; same ability was exploited to model ones own mind - what one calls self
&gt; &gt; awareness. I will also suggest that a specific system of
&gt; &gt; neurons called mirror neurons are involved in this ability. Finally I
&gt; &gt; discuss some clinical examples to illustrate these ideas and
&gt; &gt; make some testable predictions.

&gt; &gt; There are many aspects of self. It has a sense of unity despite the
&gt; &gt; multitude of sense impressions and beliefs. In addition it has a
&gt; &gt; sense of continuity in time, of being in control of its actions (&quot;free
&gt; &gt; will&quot;), of being anchored in a body, a sense of its worth,
&gt; &gt; dignity and mortality (or immortality). Each of these aspects of self may
&gt; &gt; be mediated by different centers in different parts of the
&gt; &gt; brain and its only for convenience that we lump them together in a single
&gt; &gt; word.

&gt; &gt; As noted earlier there is one aspect of self that seems stranger than all
&gt; &gt; the others - the fact that it is aware of itself. I would
&gt; &gt; like to suggest that groups of neurons called mirror neurons are
&gt; &gt; critically involved in this ability.

&gt; &gt; The discovery of mirror neurons was made G. Rizzolati, V Gallase and I
&gt; &gt; Iaccoboni while recording from the brains of monkeys
&gt; &gt; performed certain goal-directed voluntary actions. For instance when the
&gt; &gt; monkey reached for a peanut a certain neuron in its pre
&gt; &gt; motor cortex ( in the frontal lobes) would fire. Another neuron would fire
&gt; &gt; when the monkey pushed a button, a third neuron when he
&gt; &gt; pulled a lever. The existence of such Command neurons that control
&gt; &gt; voluntary movements has been known for decades. Amazingly, a
&gt; &gt; subset of these neurons had an additional peculiar property. The neuron
&gt; &gt; fired not only (say) when the monkey reached for a peanut
&gt; &gt; but also when it watched another monkey reach for a peanut!

&gt; &gt; These were dubbed &quot;mirror neurons&quot; or &quot;monkey-see-monkey-do&quot; neurons. This
&gt; &gt; was an extraordinary observation because it implies that
&gt; &gt; the neuron (or more accurately, the network which it is part of) was not
&gt; &gt; only generating a highly specific command (&quot;reach for the
&gt; &gt; nut&quot;) but was capable of adopting another monkey's point of view. It was
&gt; &gt; doing a sort of internal virtual reality simulation of the
&gt; &gt; other monkeys action in order to figure out what he was &quot;up to&quot;. It was,
&gt; &gt; in short, a &quot;mind-reading&quot; neuron.

&gt; &gt; Neurons in the anterior cingulate will respond to the patient being poked
&gt; &gt; with a needle; they are often referred to as sensory pain
&gt; &gt; neurons. Remarkably, researchers at the University of Toronto have found
&gt; &gt; that some of them will fire equally strongly when the
&gt; &gt; patient watches someone else is poked. I call these &quot;empathy neurons&quot; or
&gt; &gt; &quot;Dalai Lama neurons&quot; for they are, dissolving the barrier
&gt; &gt; between self and others. Notice that in saying this one isn't being
&gt; &gt; metaphorical; the neuron in question simply doesn't know the
&gt; &gt; difference between it and others.

&gt; &gt; Primates (including humans) are highly social creatures and knowing what
&gt; &gt; someone is &quot;up to&quot; - creating an internal simulation of
&gt; &gt; his/her mind - is crucial for survival, earning us the title &quot;the
&gt; &gt; Machiavellian primate&quot;. In an essay for Edge (2001) entitled
&gt; &gt; &quot;Mirror Neurons and the Great Leap Forward&quot; I suggested that in addition
&gt; &gt; to providing a neural substrate for figuring out another
&gt; &gt; persons intentions (as noted by Rizzolati's group) the emergence and
&gt; &gt; subsequent sophistication of mirror neurons in hominids may
&gt; &gt; have played a crucial role in many quintessentially human abilities such
&gt; &gt; as empathy, learning through imitation (rather than trial
&gt; &gt; and error), and the rapid transmission of what we call &quot;culture&quot;. (And the
&gt; &gt; &quot;great leap forward&quot; - the rapid Lamarckian transmission
&gt; &gt; of &quot;accidental&quot;) one-of-a kind inventions.

&gt; &gt; I turn now to the main concern of this essay - the nature of self. When
&gt; &gt; you think of your own self, what comes into mind? You have
&gt; &gt; sense of &quot;introspecting&quot; on your own thoughts and feelings and of &quot;
&gt; &gt; watching&quot; yourself going about your business - as if you were
&gt; &gt; looking at yourself from another persons vantage point. How does this
&gt; &gt; happen ?

&gt; &gt; Evolution often takes advantage of pre-existing structures to evolve
&gt; &gt; completely novel abilities. I suggest that once the ability to
&gt; &gt; engage in cross modal abstraction emerged - e.g. between visual &quot;vertical&quot;
&gt; &gt; on the retina and photoreceptive &quot;vertical&quot; signaled by
&gt; &gt; muscles (for grasping trees) it set the stage for the emergence of mirror
&gt; &gt; neurons in hominids. Mirror neurons are also abundant in
&gt; &gt; the inferior parietal lobule - a structure that underwent an accelerated
&gt; &gt; expansion in the great apes and, later, in humans.. As the
&gt; &gt; brain evolved further the lobule split into two gyri - the supramarginal
&gt; &gt; gyrus that allowed you to &quot;reflect&quot; on your own anticipated
&gt; &gt; actions and the angular gyrus that allowed you to &quot;reflect&quot; on
">

...
read more »
</POST>
<POST>
<POSTER> Publius &lt;m.publ...@nospam.comcast.net&gt; </POSTER>
<POSTDATE> 2007-01-29T16:49:00 </POSTDATE>
"someone2" &lt;glenn.spig ... @btinternet.com&gt; wrote in
news:1170062071.049860.114070@a75g2000cwd.googlegroups.com:

<QUOTE PREVIOUSPOST="
&gt; In response to where I said:
&gt; -----------
&gt; How can you see that you removed your hand through the flame without
&gt; being conscious?
&gt; -----------

&gt; You replied:
&gt; -----------
&gt; The same way a furnace can &quot;see&quot; that a thermostat has been triggered,
&gt; and
&gt; shuts itself off. We do not assume the furnace is conscious.
&gt; -----------

&gt; which I presume is the same &quot;see&quot; as in your response:
&gt; -----------
&gt; I didn't say there is no conscious preference. I said we can't *see*
&gt; that conscious preference. So we impute one.
">

Yes, they are the same. "See" means "perceive via the senses" in both cases
(not necessarily with the eyes). The furnace "sees" the temperature via the
thermostat. A thermostat is a type of *sensor*. We don't detect consciousness
via any kind of sensor. We detect behaviors, and then impute consciousness to
explain those behaviors, just as we impute "talent" to explain why someone
plays the piano well (see post in the "Subject and Object" thread).

<QUOTE PREVIOUSPOST="
&gt; You have a strange way of looking at reality. You seem to lay claim
&gt; that your theories created it.
">

Part of it, yes. :-)

<QUOTE PREVIOUSPOST="
&gt; So no robot could ever be conscious because it would never be
&gt; necessary to impute it.
">

Not so. The fact that we built the robot would not necessarily allow us to
predict what it would do. So to predict that behavior we might resort to
conscious states.
</POST>
<POST>
<POSTER> "someone2" &lt;glenn.spig...@btinternet.com&gt; </POSTER>
<POSTDATE> 2007-01-29T19:10:00 </POSTDATE>
On 29 Jan, 21:49, Publius &lt;m.publ ... @nospam.comcast.net&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; &quot;someone2&quot; &lt;glenn.spig ... @btinternet.com&gt; wrote in news:1170062071.049860.114070@a75g2000cwd.googlegroups.com:

&gt; &gt; In response to where I said:
&gt; &gt; -----------
&gt; &gt; How can you see that you removed your hand through the flame without
&gt; &gt; being conscious?
&gt; &gt; -----------

&gt; &gt; You replied:
&gt; &gt; -----------
&gt; &gt; The same way a furnace can &quot;see&quot; that a thermostat has been triggered,
&gt; &gt; and
&gt; &gt; shuts itself off. We do not assume the furnace is conscious.
&gt; &gt; -----------

&gt; &gt; which I presume is the same &quot;see&quot; as in your response:
&gt; &gt; -----------
&gt; &gt; I didn't say there is no conscious preference. I said we can't *see*
&gt; &gt; that conscious preference. So we impute one.Yes, they are the same. &quot;See&quot; means &quot;perceive via the senses&quot; in both cases
&gt; (not necessarily with the eyes). The furnace &quot;sees&quot; the temperature via the
&gt; thermostat. A thermostat is a type of *sensor*. We don't detect consciousness
&gt; via any kind of sensor. We detect behaviors, and then impute consciousness to
&gt; explain those behaviors, just as we impute &quot;talent&quot; to explain why someone
&gt; plays the piano well (see post in the &quot;Subject and Object&quot; thread).

&gt; &gt; You have a strange way of looking at reality. You seem to lay claim
&gt; &gt; that your theories created it.Part of it, yes. :-)

&gt; &gt; So no robot could ever be conscious because it would never be
&gt; &gt; necessary to impute it.Not so. The fact that we built the robot would not necessarily allow us to
&gt; predict what it would do. So to predict that behavior we might resort to
&gt; conscious states.- Hide quoted text -- Show quoted text -
">

Ok, so if you didn't know how the robot was built and how it functions
it could be imbued with conscious, yet once you knew how it worked, it
wouldn't be imbued with conscious. In neither of these cases, have you
any evidence to whether the robot was actually conscious, because
there could be no behavioural evidence either way from a materialist
persective given they also hold the perspective that anything that is
actually conscious and experiencing 'free will', will act as though it
isn't. Anything you would disagree with there?

It would seem from what you said:
------------
What is real is whatever our best theories declare to be real. Atoms
are "real" if they help us explain chemical reactions. Preferences and
"qualia" are "real" if they help us explain human behavior. Trees are
"real" if they help us explain certain patterns in sensory data.
------------

There could be no reality without theories to describe it, so it
wouldn't just be part of reality you lay claim to, and I presume by
that part, you mean manipulation of the material world you experience,
according to the rules it is found to operate by.

Out of interest, when you said:
-------------
"See" means "perceive via the senses"
-------------

And then when on to talk about the furnace "seeing" the temperature
via the thermostat. Which bit of the furnace is perceiving the
temperature, and what is the experience of the sense? Or does the use
of language such as perception and the senses now belong only to
discussion of imbued consciousness.
</POST>
<POST>
<POSTER> Publius &lt;m.publ...@nospam.comcast.net&gt; </POSTER>
<POSTDATE> 2007-01-30T01:44:00 </POSTDATE>
"someone2" &lt;glenn.spig ... @btinternet.com&gt; wrote in
news:1170115832.325944.33970@l53g2000cwa.googlegroups.com:

<QUOTE PREVIOUSPOST="
&gt; Ok, so if you didn't know how the robot was built and how it functions
&gt; it could be imbued with conscious, yet once you knew how it worked, it
&gt; wouldn't be imbued with conscious.
">

Knowing how it worked would not necessarily allow us to predict how it would
behave, in some or all cases. We might impute consciousness if that yielded
better predictions.

<QUOTE PREVIOUSPOST="
&gt; In neither of these cases, have you
&gt; any evidence to whether the robot was actually conscious, because
&gt; there could be no behavioural evidence either way from a materialist
&gt; persective given they also hold the perspective that anything that is
&gt; actually conscious and experiencing 'free will', will act as though it
&gt; isn't. Anything you would disagree with there?
">

You are still using "actually conscious" as though consciousness is a
manifest property, the presence or absence of which could (eventually) be
ascertained empirically. Reconsider the comparison with "talent." We don't
ask whether a person who plays the piano skillfully and artfully is "really"
talented or "actually" talented. That she plays skillfully and artfully is
*sufficient* to attribute talent.

<QUOTE PREVIOUSPOST="
&gt; There could be no reality without theories to describe it, so it
&gt; wouldn't just be part of reality you lay claim to, and I presume by
&gt; that part, you mean manipulation of the material world you experience,
&gt; according to the rules it is found to operate by.
">

We do have data delivered by our senses. We do not invent that. What we
invent is the conceptual structure into which we fit that data.

<QUOTE PREVIOUSPOST="
&gt; And then when on to talk about the furnace &quot;seeing&quot; the temperature
&gt; via the thermostat. Which bit of the furnace is perceiving the
&gt; temperature, and what is the experience of the sense?
">

We do not assume the furnace has any experience when seeing the temperature
via the thermostat. That would be to attribute consciousness to it. And there
is no need to do that, because we can explain and predict the behavior of the
furnace without that hypothesis.
</POST>
<POST>
<POSTER> "someone2" &lt;glenn.spig...@btinternet.com&gt; </POSTER>
<POSTDATE> 2007-01-30T10:52:00 </POSTDATE>
On 30 Jan, 06:44, Publius &lt;m.publ ... @nospam.comcast.net&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; &quot;someone2&quot; &lt;glenn.spig ... @btinternet.com&gt; wrote in news:1170115832.325944.33970@l53g2000cwa.googlegroups.com:

&gt; &gt; Ok, so if you didn't know how the robot was built and how it functions
&gt; &gt; it could be imbued with conscious, yet once you knew how it worked, it
&gt; &gt; wouldn't be imbued with conscious.Knowing how it worked would not necessarily allow us to predict how it would
&gt; behave, in some or all cases. We might impute consciousness if that yielded
&gt; better predictions.

&gt; &gt; In neither of these cases, have you
&gt; &gt; any evidence to whether the robot was actually conscious, because
&gt; &gt; there could be no behavioural evidence either way from a materialist
&gt; &gt; persective given they also hold the perspective that anything that is
&gt; &gt; actually conscious and experiencing 'free will', will act as though it
&gt; &gt; isn't. Anything you would disagree with there?You are still using &quot;actually conscious&quot; as though consciousness is a
&gt; manifest property, the presence or absence of which could (eventually) be
&gt; ascertained empirically. Reconsider the comparison with &quot;talent.&quot; We don't
&gt; ask whether a person who plays the piano skillfully and artfully is &quot;really&quot;
&gt; talented or &quot;actually&quot; talented. That she plays skillfully and artfully is
&gt; *sufficient* to attribute talent.

&gt; &gt; There could be no reality without theories to describe it, so it
&gt; &gt; wouldn't just be part of reality you lay claim to, and I presume by
&gt; &gt; that part, you mean manipulation of the material world you experience,
&gt; &gt; according to the rules it is found to operate by.We do have data delivered by our senses. We do not invent that. What we
&gt; invent is the conceptual structure into which we fit that data.

&gt; &gt; And then when on to talk about the furnace &quot;seeing&quot; the temperature
&gt; &gt; via the thermostat. Which bit of the furnace is perceiving the
&gt; &gt; temperature, and what is the experience of the sense?We do not assume the furnace has any experience when seeing the temperature
&gt; via the thermostat. That would be to attribute consciousness to it. And there
&gt; is no need to do that, because we can explain and predict the behavior of the
&gt; furnace without that hypothesis.
">

When you say:
-------------
Knowing how it worked would not necessarily allow us to predict how it
would behave, in some or all cases. We might impute consciousness if
that yielded better predictions.
-------------

Supposing consciousness did yield better predictions? How would you
explain it given that from a materialist perspective whatever is
conscious and experiencing 'free will' will behave as though it
didn't, and therefore consciousness could not be influential.

How if it wasn't influential would the predictions of behaviour be
better if it was assumed that it is? If they were, then what should we
make of it, should we assume that consciousness is influential and
that materialism is wrong?

Regarding when you said:
-----------------
You are still using "actually conscious" as though consciousness is a
manifest property, the presence or absence of which could (eventually)
be ascertained empirically. Reconsider the comparison with "talent."
We don't ask whether a person who plays the piano skillfully and
artfully is "really" talented or "actually" talented. That she plays
skillfully and artfully is *sufficient* to attribute talent.
-----------------

Are you saying that we aren't really conscious, and that we aren't
really experiencing being a human in a physical world? Or is that you
are agreeing that you really are conscious, it was just a question of
consciousness being a manifest property, that it might be possible to
ascertain it empirically, though that would seem to be dependent on
what the rules are, the Uncertainty principle for example highlights
an example of an experimental restriction being reached.

I can see the concept of the consciousness actually being influential
to behaviour being mutually exclusive to the materialist perspective
where behaviour is the same regardless of whether the object is
conscious or not.

Though how do materialists explain that people manage to interact with
each other on the assumption that the other person they are
interacting with is a conscious being, that has influence over their
behaviour, an yet without knowledge of the chemical reactions or the
laws of physics, it works.

How do they explain these predictive stories of conscious preference?
</POST>
<POST>
<POSTER> Publius &lt;m.publ...@nospam.comcast.net&gt; </POSTER>
<POSTDATE> 2007-02-01T03:34:00 </POSTDATE>
"someone2" &lt;glenn.spig ... @btinternet.com&gt; wrote in
news:1170172328.758040.256870@m58g2000cwm.googlegroups.com:

<QUOTE PREVIOUSPOST="
&gt; When you say:
&gt; -------------
&gt; Knowing how it worked would not necessarily allow us to predict how it
&gt; would behave, in some or all cases. We might impute consciousness if
&gt; that yielded better predictions.
&gt; -------------

&gt; Supposing consciousness did yield better predictions? How would you
&gt; explain it given that from a materialist perspective whatever is
&gt; conscious and experiencing 'free will' will behave as though it
&gt; didn't, and therefore consciousness could not be influential.
">

If there are differences in (accurate) predictions, then the behavior will
not be the same per the two models.

<QUOTE PREVIOUSPOST="
&gt; How if it wasn't influential would the predictions of behaviour be
&gt; better if it was assumed that it is? If they were, then what should we
&gt; make of it, should we assume that consciousness is influential and
&gt; that materialism is wrong?
">

Materialism (some versions of it) may not be wrong. They may only be
incomplete.

<QUOTE PREVIOUSPOST="
&gt; Are you saying that we aren't really conscious, and that we aren't
&gt; really experiencing being a human in a physical world?
">

We do experience our own subjective states. We don't experience anyone
else's, however. We impute those states to them, based on their observable
behavior. We impute those states if they satisfy the two tests I mentioned
earlier.

<QUOTE PREVIOUSPOST="
&gt; Though how do materialists explain that people manage to interact with
&gt; each other on the assumption that the other person they are
&gt; interacting with is a conscious being, that has influence over their
&gt; behaviour, an yet without knowledge of the chemical reactions or the
&gt; laws of physics, it works.
">

That is a good point. The fact is that the "naive materialist" theory is not
nearly as good a predictor of behavior as the "consciousness theory." But the
two can be reconciled.
</POST>
<POST>
<POSTER> "someone2" &lt;glenn.spig...@btinternet.com&gt; </POSTER>
<POSTDATE> 2007-02-01T04:30:00 </POSTDATE>
On 1 Feb, 08:34, Publius &lt;m.publ ... @nospam.comcast.net&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; &quot;someone2&quot; &lt;glenn.spig ... @btinternet.com&gt; wrote in news:1170172328.758040.256870@m58g2000cwm.googlegroups.com:

&gt; &gt; When you say:
&gt; &gt; -------------
&gt; &gt; Knowing how it worked would not necessarily allow us to predict how it
&gt; &gt; would behave, in some or all cases. We might impute consciousness if
&gt; &gt; that yielded better predictions.
&gt; &gt; -------------

&gt; &gt; Supposing consciousness did yield better predictions? How would you
&gt; &gt; explain it given that from a materialist perspective whatever is
&gt; &gt; conscious and experiencing 'free will' will behave as though it
&gt; &gt; didn't, and therefore consciousness could not be influential.

&gt; If there are differences in (accurate) predictions, then the behavior will
&gt; not be the same per the two models.

&gt; &gt; How if it wasn't influential would the predictions of behaviour be
&gt; &gt; better if it was assumed that it is? If they were, then what should we
&gt; &gt; make of it, should we assume that consciousness is influential and
&gt; &gt; that materialism is wrong?

&gt; Materialism (some versions of it) may not be wrong. They may only be
&gt; incomplete.

&gt; &gt; Are you saying that we aren't really conscious, and that we aren't
&gt; &gt; really experiencing being a human in a physical world?

&gt; We do experience our own subjective states. We don't experience anyone
&gt; else's, however. We impute those states to them, based on their observable
&gt; behavior. We impute those states if they satisfy the two tests I mentioned
&gt; earlier.

&gt; &gt; Though how do materialists explain that people manage to interact with
&gt; &gt; each other on the assumption that the other person they are
&gt; &gt; interacting with is a conscious being, that has influence over their
&gt; &gt; behaviour, an yet without knowledge of the chemical reactions or the
&gt; &gt; laws of physics, it works.

&gt; That is a good point. The fact is that the &quot;naive materialist&quot; theory is not
&gt; nearly as good a predictor of behavior as the &quot;consciousness theory.&quot; But the
&gt; two can be reconciled.
">

When you say reconciled, I presume you refer to the issue of humans
claiming to be conscious beings, and that their being/consciousness
influences their behaviour, when materialism clearly states that there
could be no being influencing behaviour, and that we experience being
such a being and influencing the behaviour? What would the
reconciliation be, the human claim of consciousness influencing their
behaviour a falsehood, and the experience of being the consciousness a
yet unexplained coincidence, and the experience of influence a
deception?
</POST>
<POST>
<POSTER> "Justintruth" &lt;truth.jus...@gmail.com&gt; </POSTER>
<POSTDATE> 2007-02-01T09:10:00 </POSTDATE>
The author of this post posits that there is a "problem of the self"
that "needs to be solved". He dismisses the 3000 year history of
philosophy as basically a failed effort to "solve" this problem and
refers to a series of relationships between an extremely poor and
underdeveloped phenomenology of self with a probably excellent
understanding of certain aspects of electrochemical brain activity.

He completely misses the meaning of formal causality using phrases
like "is based on" "is critically involved in" "is simply using" to
obscure the real problem that of formulating the question of how the
brain activity causes any consciousness at all.

If using a lens I focus sunlight on a cup of cold coffee it heats up.
We say that the light "causes the cup of coffee to heat up". I can
understand that easily because once I understand the nature of
electricity and magnetism and the nature of the absorption of energy
by electro-magnetic force exerted on charged particles and the nature
of heat being atomic motion then I can see why (in a formal sense)
"the light causes the cup of coffee to heat up". It is, in fact,
necessary that it would. It is the nature of electricity and magnetism
and its interaction with atoms. This is formal cause only, but it is
formal cause!

What about "the self"? The author basically claims that the "firing of
mirror neurons" causes "the self". His tracing which neurons fire
when, presumably, a monkey is experiencing "self" is interesting and
worthwhile. However, his claim that this tracing solves the problem of
the self or even contributes to the solving of it evidences such a
total lack of understanding of the problem that it can only be
explained by a complete ignorance of the history of philosophy caused
by the indifference of someone who presumes he already knows it, and
that it is worthless, and therefore not worth studying. He is very
wrong and it is a pity because he is because he is in the very
enviable position of being someone able to describe one half of "the
problem". He has access, professionally or as a student, I do not know
which, to the research on brain science. It is a valuable slot wasted
on him and he will surely spend many wasted hours with inadequate
phenomenological models of self "explaining" and tracing brain
activity against what can only be described as "casual" and "naïve"
descriptions of self in a meaningless attempt to "solve the problem".
Perhaps, in the end he will make a complete fool of himself when he
completes his program and then declares the "problem solved" (or will
he use the phrase "mission accomplished"?).

Simple put, when I say that "the light causes the cup of coffee to
heat up" I can say exactly what happens to cause that. An oscillating
electric field will, *by definition*, accelerate a charged particle,
it is what an electric field is. Its presence is detected by measuring
the acceleration of charged particles. Can the author say how "the
firing of a neuron" causes any "consciousness" let alone the
"consciousness of self"? Will he ever be able to proceeding as he is?

Before a problem is "solved" it at least must be well posed. Try
reading the works of philosophy to better pose your problem. This is
sophomoric.

Perhaps a course or two in philosophy could cause the author to spare
us baseless - even meaningless - phrases like:

"I call these "empathy neurons" or "Dalai Lama neurons" for they are,
dissolving the barrier between self and others. Notice that in saying
this one isn't being metaphorical; the neuron in question simply
doesn't know the difference between it and others."

Yes. He really said that.

Well glad that's solved. It's the "Daliai Lama neurons". They are
literally dissolving the barrier- not metaphorically - literally
between myself and others. Great title though "the Daliai Lama
neurons" I mean.. Yea. Right. OK.

Plllleeeasssee....

Guess again...

Enough wasted time.
</POST>
<POST>
<POSTER> Publius &lt;m.publ...@nospam.comcast.net&gt; </POSTER>
<POSTDATE> 2007-02-07T22:23:00 </POSTDATE>
"someone2" &lt;glenn.spig ... @btinternet.com&gt; wrote in
news:1170322209.634126.32880@p10g2000cwp.googlegroups.com:

<QUOTE PREVIOUSPOST="
&gt; When you say reconciled, I presume you refer to the issue of humans
&gt; claiming to be conscious beings, and that their being/consciousness
&gt; influences their behaviour, when materialism clearly states that there
&gt; could be no being influencing behaviour, and that we experience being
&gt; such a being and influencing the behaviour?
">

You continue to collapse several different "materialist" view into one. Many
materialists do not claim that consciousness has no role in behavior.

<QUOTE PREVIOUSPOST="
&gt; What would the
&gt; reconciliation be, the human claim of consciousness influencing their
&gt; behaviour a falsehood, and the experience of being the consciousness a
&gt; yet unexplained coincidence, and the experience of influence a
&gt; deception?
">

The reconciliation would consist in explaining consciousness in materialist
terms, e.g., how a physical system may come to have subjective states.
</POST>
<POST>
<POSTER> "someone2" &lt;glenn.spig...@btinternet.com&gt; </POSTER>
<POSTDATE> 2007-02-08T05:43:00 </POSTDATE>
On 8 Feb, 03:23, Publius &lt;m.publ ... @nospam.comcast.net&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; &quot;someone2&quot; &lt;glenn.spig ... @btinternet.com&gt; wrote in news:1170322209.634126.32880@p10g2000cwp.googlegroups.com:

&gt; &gt; When you say reconciled, I presume you refer to the issue of humans
&gt; &gt; claiming to be conscious beings, and that their being/consciousness
&gt; &gt; influences their behaviour, when materialism clearly states that there
&gt; &gt; could be no being influencing behaviour, and that we experience being
&gt; &gt; such a being and influencing the behaviour?

&gt; You continue to collapse several different &quot;materialist&quot; view into one. Many
&gt; materialists do not claim that consciousness has no role in behavior.

&gt; &gt; What would the
&gt; &gt; reconciliation be, the human claim of consciousness influencing their
&gt; &gt; behaviour a falsehood, and the experience of being the consciousness a
&gt; &gt; yet unexplained coincidence, and the experience of influence a
&gt; &gt; deception?

&gt; The reconciliation would consist in explaining consciousness in materialist
&gt; terms, e.g., how a physical system may come to have subjective states.
">

It is easy to say, well neural activity and consciousness are just the
same and therefore consciousness has the same advantages as neural
activity when referring to us as you know we have consciousness. How
though does the materialist perspective hold when referring to a
robot. Does it consciously experience or not, and whether it does or
doesn't, what discernable difference would it make to behaviour. If
none, then how can it be an influence?
</POST>
<POST>
<POSTER> "Aaron" &lt;anod...@hotmail.com&gt; </POSTER>
<POSTDATE> 2007-02-08T07:16:00 </POSTDATE>
On Jan 22, 11:35 am, Sir Frederick &lt;mmcne ... @fuzzysys.com&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; http://www.edge.org/documents/archive/edge201.html#rama
&gt; THE NEUROLOGY OF SELF-AWARENESS
&gt; By V.S. Ramachandran

&gt; What is the self? How does the activity of neurons give rise to the sense of being a conscious human being? Even this most ancient
">

I think the things we call life forms are biological machines.
Complexity simply gives rise to this thing we call self awareness.  It
is not something that is possible to describe.  I just "am aware".

Say you look at a simple organism like a fruitfly.  It is a machine
like us.  It does it's thing.  From our point of view, it probably
does not have consiousness or emotion.

But now think about a lifeform that is as much more complex than a
human than a human is to a fuitfly.  They might look at us and just
see triviality, or a tiny inkling of the thing they consider it to be
"aware".

It's all relative, I think.

<QUOTE PREVIOUSPOST="
&gt; of philosophical problems, I believe, will yield to the methods of empirical science. It now seems increasingly likely that the self
&gt; is not a holistic property of the entire brain; it arises from the activity of specific sets of interlinked brain circuits. But we
&gt; need to know which circuits are critically involved and what their functions might be. It is the &quot;turning inward&quot; aspect of the self
&gt; - its recursiveness - that gives it its peculiar paradoxical quality.

&gt; It has been suggested by Horace Barlow, Nick Humphrey, David Premack and Marvin Minsky (among others) that consciousness may have
&gt; evolved primarily in a social context. Minsky speaks of a second parallel mechanism that has evolved in humans to create
&gt; representations of earlier representations and Humphrey has argued that our ability to introspect may have evolved specifically to
&gt; construct meaningful models of other peoples minds in order to predict their behavior. &quot;I feel jealous in order to understand what
&gt; jealousy feels like in someone else&quot; - a short cut to predicting that persons behavior.

&gt; Here I develop these arguments further. If I succeed in seeing any further it is by &quot;standing on the shoulders of these giants&quot;.
&gt; Specifically, I suggest that &quot;other awareness&quot; may have evolved first and then counterintutively, as often happens in evolution, the
&gt; same ability was exploited to model ones own mind - what one calls self awareness. I will also suggest that a specific system of
&gt; neurons called mirror neurons are involved in this ability. Finally I discuss some clinical examples to illustrate these ideas and
&gt; make some testable predictions.

&gt; There are many aspects of self. It has a sense of unity despite the multitude of sense impressions and beliefs. In addition it has a
&gt; sense of continuity in time, of being in control of its actions (&quot;free will&quot;), of being anchored in a body, a sense of its worth,
&gt; dignity and mortality (or immortality). Each of these aspects of self may be mediated by different centers in different parts of the
&gt; brain and its only for convenience that we lump them together in a single word.

&gt; As noted earlier there is one aspect of self that seems stranger than all the others - the fact that it is aware of itself. I would
&gt; like to suggest that groups of neurons called mirror neurons are critically involved in this ability.

&gt; The discovery of mirror neurons was made G. Rizzolati, V Gallase and I Iaccoboni while recording from the brains of monkeys
&gt; performed certain goal-directed voluntary actions. For instance when the monkey reached for a peanut a certain neuron in its pre
&gt; motor cortex ( in the frontal lobes) would fire. Another neuron would fire when the monkey pushed a button, a third neuron when he
&gt; pulled a lever. The existence of such Command neurons that control voluntary movements has been known for decades. Amazingly, a
&gt; subset of these neurons had an additional peculiar property. The neuron fired not only (say) when the monkey reached for a peanut
&gt; but also when it watched another monkey reach for a peanut!

&gt; These were dubbed &quot;mirror neurons&quot; or &quot;monkey-see-monkey-do&quot; neurons. This was an extraordinary observation because it implies that
&gt; the neuron (or more accurately, the network which it is part of) was not only generating a highly specific command (&quot;reach for the
&gt; nut&quot;) but was capable of adopting another monkey's point of view. It was doing a sort of internal virtual reality simulation of the
&gt; other monkeys action in order to figure out what he was &quot;up to&quot;. It was, in short, a &quot;mind-reading&quot; neuron.

&gt; Neurons in the anterior cingulate will respond to the patient being poked with a needle; they are often referred to as sensory pain
&gt; neurons. Remarkably, researchers at the University of Toronto have found that some of them will fire equally strongly when the
&gt; patient watches someone else is poked. I call these &quot;empathy neurons&quot; or &quot;Dalai Lama neurons&quot; for they are, dissolving the barrier
&gt; between self and others. Notice that in saying this one isn't being metaphorical; the neuron in question simply doesn't know the
&gt; difference between it and others.

&gt; Primates (including humans) are highly social creatures and knowing what someone is &quot;up to&quot; - creating an internal simulation of
&gt; his/her mind - is crucial for survival, earning us the title &quot;the Machiavellian primate&quot;. In an essay for Edge (2001) entitled
&gt; &quot;Mirror Neurons and the Great Leap Forward&quot; I suggested that in addition to providing a neural substrate for figuring out another
&gt; persons intentions (as noted by Rizzolati's group) the emergence and subsequent sophistication of mirror neurons in hominids may
&gt; have played a crucial role in many quintessentially human abilities such as empathy, learning through imitation (rather than trial
&gt; and error), and the rapid transmission of what we call &quot;culture&quot;. (And the &quot;great leap forward&quot; - the rapid Lamarckian transmission
&gt; of &quot;accidental&quot;) one-of-a kind inventions.

&gt; I turn now to the main concern of this essay - the nature of self. When you think of your own self, what comes into mind? You have
&gt; sense of &quot;introspecting&quot; on your own thoughts and feelings and of &quot; watching&quot; yourself going about your business - as if you were
&gt; looking at yourself from another persons vantage point. How does this happen ?

&gt; Evolution often takes advantage of pre-existing structures to evolve completely novel abilities. I suggest that once the ability to
&gt; engage in cross modal abstraction emerged - e.g. between visual &quot;vertical&quot; on the retina and photoreceptive &quot;vertical&quot; signaled by
&gt; muscles (for grasping trees) it set the stage for the emergence of mirror neurons in hominids. Mirror neurons are also abundant in
&gt; the inferior parietal lobule - a structure that underwent an accelerated expansion in the great apes and, later, in humans.. As the
&gt; brain evolved further the lobule split into two gyri - the supramarginal gyrus that allowed you to &quot;reflect&quot; on your own anticipated
&gt; actions and the angular gyrus that allowed you to &quot;reflect&quot; on your body (on the right) and perhaps on other more social and
&gt; linguistic aspects of your self (left hemisphere) I have argued elsewhere that mirror neurons are fundamentally performing a kind of
&gt; abstraction across activity in visual maps and motor maps. This in turn may have paved the way for more conceptual types of
&gt; abstraction; such as metaphor (&quot;get a grip on yourself&quot;).

&gt; How does all this lead to self awareness? I suggest that self awareness is simply using mirror neurons for &quot;looking at myself as if
&gt; someone else is look at me&quot; (the word &quot;me&quot; encompassing some of my brain processes, as well). The mirror neuron mechanism - the same
&gt; algorithm - that originally evolved to help you adopt another's point of view was turned inward to look at your own self. This, in
&gt; essence, is the basis of things like &quot;introspection&quot;. It may not be coincidental that we use phrases like &quot;self conscious&quot; when you
&gt; really mean that you are conscious of others being conscious of you. Or say &quot;I am reflecting&quot; when you mean you are aware of
&gt; yourself thinking. In other words the ability to turn inward to introspect or reflect may be a sort of metaphorical extension of the
&gt; mirror neurons ability to read others minds. It is often tacitly assumed that the uniquely human ability to construct a &quot;theory of
&gt; other minds&quot; or &quot;TOM&quot; (seeing the world from the others point of view; &quot;mind reading&quot;, figuring out what someone is up to, etc.)
&gt; must come after an already pre- existing sense of self. I am arguing that the exact opposite is true; the TOM evolved first in
&gt; response to social needs and then later, as an unexpected bonus, came the ability to introspect on your own thoughts and intentions.
&gt; I claim no great originality for these ideas; they are part of the current zeitgeist. Any novelty derives from the manner in which I
&gt; shall marshall the evidence from physiology and from our own work in neurology. Note that I am not arguing that mirror neurons are
&gt; sufficient for the emergence of self; only that they must have played a pivotal role. (Otherwise monkeys would have self awareness
&gt; and they don't). They may have to reach a certain critical level of sophistication that allowed them to build on earlier functions
&gt; (TOM) and become linked to certain other brain circuits, especially the Wernickes (&quot;language comprehension&quot;) area and parts of the
&gt; frontal lobes.

&gt; Does the mirror neuron theory of self make other predictions? Given our discovery that autistic children have deficient mirror
&gt; neurons and correspondingly deficient TOM, we would predict that they would have a deficient sense of self (TMM) and difficulty with
&gt; introspection. The same might be true for other neurological disorders; damage to the inferior parietal lobule/TPO junction (which
&gt; are known to contain mirror neurons) and parts of the frontal lobes should also lead to a deficiency of certain aspects self
&gt; awareness. (Incidentally, Gallup's mirror
">

...
read more »
</POST>
<POST>
<POSTER> Publius &lt;m.publ...@nospam.comcast.net&gt; </POSTER>
<POSTDATE> 2007-02-09T17:51:00 </POSTDATE>
"someone2" &lt;glenn.spig ... @btinternet.com&gt; wrote in
news:1170931389.669413.37250@v33g2000cwv.googlegroups.com:

<QUOTE PREVIOUSPOST="
&gt; It is easy to say, well neural activity and consciousness are just the
&gt; same and therefore consciousness has the same advantages as neural
&gt; activity when referring to us as you know we have consciousness. How
&gt; though does the materialist perspective hold when referring to a
&gt; robot. Does it consciously experience or not, and whether it does or
&gt; doesn't, what discernable difference would it make to behaviour. If
&gt; none, then how can it be an influence?
">

We would impute consciousness to a robot if imputing that capacity would help
us explain its behavior. That is the same reason we have for imputing it to
humans other than ourselves.
</POST>
<POST>
<POSTER> "someone2" &lt;glenn.spig...@btinternet.com&gt; </POSTER>
<POSTDATE> 2007-02-10T12:30:00 </POSTDATE>
On 9 Feb, 22:51, Publius &lt;m.publ ... @nospam.comcast.net&gt; wrote:

<QUOTE PREVIOUSPOST="
&gt; &quot;someone2&quot; &lt;glenn.spig ... @btinternet.com&gt; wrote in news:1170931389.669413.37250@v33g2000cwv.googlegroups.com:

&gt; &gt; It is easy to say, well neural activity and consciousness are just the
&gt; &gt; same and therefore consciousness has the same advantages as neural
&gt; &gt; activity when referring to us as you know we have consciousness. How
&gt; &gt; though does the materialist perspective hold when referring to a
&gt; &gt; robot. Does it consciously experience or not, and whether it does or
&gt; &gt; doesn't, what discernable difference would it make to behaviour. If
&gt; &gt; none, then how can it be an influence?

&gt; We would impute consciousness to a robot if imputing that capacity would help
&gt; us explain its behavior. That is the same reason we have for imputing it to
&gt; humans other than ourselves.
">

Given the robot scenario, whether it did have an experience similar to
our own (as in the Terminator movie), or no experience, as we see in
the factory robots, the behaviourist would expect it to act the same.
Do you agree?

[Redefining experience to behaviour, isn't an answer to the question.
It isn't a question about a terminator robot vs a factory robot. It is
about a robot whose appearance and behavioural limitations are left up
to you, though it would be known how it works].
</POST>
</TEXT>
</BODY>
</DOC>
